#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ä¸‰ç‰ˆæœ¬å®Œæ•´å°æ¯”æ¸¬è©¦
åŒ…å« Ground Truth æº–ç¢ºç‡å°æ¯”å’ŒæŠ€è¡“ç‰¹æ€§å°æ¯”
"""

import pandas as pd
import sys
import os
import time
from datetime import datetime

# å°å…¥ä¸‰å€‹ç‰ˆæœ¬çš„åˆ†é¡å™¨
sys.path.append(os.path.dirname(__file__))

# V1: åŸå§‹ç‰ˆæœ¬ (å‡è¨­ä½¿ç”¨ enhanced_demo_with_topk.py ä¸­çš„åˆ†é¡é‚è¼¯)
from text_classifier import TextClassifier
from similarity_analysis import SimilarityAnalyzer

# V2: å„ªåŒ–ç‰ˆæœ¬
from enhanced_classifier_v2 import EnhancedClassifierV2

# V3: ä¿ç•™è©ç‰ˆæœ¬
from ultimate_classifier_with_reserved_words import UltimateClassifier

def create_ground_truth_dataset():
    """å‰µå»º Ground Truth æ¸¬è©¦æ•¸æ“šé›†"""
    ground_truth_cases = [
        # è¨­å‚™é¡ (å¯¦é«”)
        ("é˜²ç«ç‰†è¨­å‚™", "å¯¦é«”"),
        ("ç¶²è·¯è¨­å‚™", "å¯¦é«”"), 
        ("ç›£æ§è¨­å‚™", "å¯¦é«”"),
        ("å„²å­˜è¨­å‚™", "å¯¦é«”"),
        ("å®‰å…¨è¨­å‚™", "å¯¦é«”"),
        ("å¯æ”œå¼å„²å­˜åª’é«”", "å¯¦é«”"),
        ("ä¼ºæœå™¨ä¸»æ©Ÿ", "å¯¦é«”"),
        ("ç¶²è·¯äº¤æ›å™¨", "å¯¦é«”"),
        
        # è»Ÿé«”ç³»çµ±é¡
        ("è³‡æ–™åº«ç®¡ç†ç³»çµ±", "è»Ÿé«”"),
        ("ä½œæ¥­ç³»çµ±", "è»Ÿé«”"),
        ("æ‡‰ç”¨ç¨‹å¼", "è»Ÿé«”"),
        ("MySQLè³‡æ–™åº«", "è»Ÿé«”"),
        ("Oracleç³»çµ±", "è»Ÿé«”"),
        ("Windowsç³»çµ±", "è»Ÿé«”"),
        ("Linuxä¼ºæœå™¨", "è»Ÿé«”"),
        ("ç®¡ç†ç³»çµ±", "è»Ÿé«”"),
        
        # æ–‡ä»¶è³‡æ–™é¡
        ("ä½œæ¥­æ–‡ä»¶", "è³‡æ–™"),
        ("é›»å­ç´€éŒ„", "è³‡æ–™"),
        ("ç¨‹åºæ–‡ä»¶", "è³‡æ–™"),
        ("æŠ€è¡“æ–‡ä»¶", "è³‡æ–™"),
        ("åˆç´„æ–‡ä»¶", "è³‡æ–™"),
        ("å‚™ä»½æª”æ¡ˆ", "è³‡æ–™"),
        ("æ—¥èªŒæª”æ¡ˆ", "è³‡æ–™"),
        ("åŸå§‹ç¢¼", "è³‡æ–™"),
        
        # äººå“¡é¡
        ("å…§éƒ¨äººå“¡", "äººå“¡"),
        ("å¤–éƒ¨äººå“¡", "äººå“¡"),
        ("ç³»çµ±ç®¡ç†å“¡", "äººå“¡"),
        ("æ‰¿è¾¦äºº", "äººå“¡"),
        ("ä½¿ç”¨è€…", "äººå“¡"),
        ("å§”å¤–å» å•†", "äººå“¡"),
        
        # æœå‹™é¡
        ("ç¶²è·¯æœå‹™", "æœå‹™"),
        ("é›²ç«¯æœå‹™", "æœå‹™"),
        ("æ‡‰ç”¨æœå‹™", "æœå‹™"),
        ("è³‡æ–™æœå‹™", "æœå‹™"),
        ("APIæœå‹™", "æœå‹™"),
        ("Webæœå‹™", "æœå‹™"),
        
        # è¤‡é›œæ··åˆæ¡ˆä¾‹
        ("é˜²ç«ç‰†ç®¡ç†ç³»çµ±", "è»Ÿé«”"),
        ("ç¶²è·¯ç›£æ§è¨­å‚™", "å¯¦é«”"),
        ("è³‡æ–™åº«å‚™ä»½æª”æ¡ˆ", "è³‡æ–™"),
        ("ç³»çµ±ç®¡ç†äººå“¡", "äººå“¡"),
        ("é›²ç«¯å„²å­˜æœå‹™", "æœå‹™"),
        
        # è®ŠåŒ–ç‰ˆæœ¬æ¸¬è©¦
        ("é˜²ç«ç‰†", "å¯¦é«”"),
        ("è³‡æ–™åº«", "è»Ÿé«”"),
        ("æ–‡ä»¶", "è³‡æ–™"),
        ("äººå“¡", "äººå“¡"),
        ("æœå‹™", "æœå‹™")
    ]
    
    return ground_truth_cases

class ClassifierV1:
    """V1 ç‰ˆæœ¬åˆ†é¡å™¨åŒ…è£"""
    def __init__(self):
        self.text_classifier = TextClassifier('RA_data.csv')
        self.similarity_analyzer = SimilarityAnalyzer('RA_data.csv')
    
    def classify(self, text):
        # ä½¿ç”¨åŸå§‹çš„åˆ†é¡é‚è¼¯
        text_result = self.text_classifier.classify_text(text)
        similarity_result = self.similarity_analyzer.find_similar_assets(text, top_k=1)
        
        # ç°¡å–®æŠ•ç¥¨æ©Ÿåˆ¶
        if similarity_result:
            return similarity_result[0]['è³‡ç”¢é¡åˆ¥']
        else:
            return text_result.get('predicted_category', 'æœªçŸ¥')

def run_comprehensive_test():
    """åŸ·è¡Œå…¨é¢å°æ¯”æ¸¬è©¦"""
    print("="*100)
    print("ğŸš€ ä¸‰ç‰ˆæœ¬è³‡ç”¢åˆ†é¡å™¨å®Œæ•´å°æ¯”æ¸¬è©¦")
    print("="*100)
    print(f"æ¸¬è©¦æ™‚é–“: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print()
    
    # ç²å–æ¸¬è©¦æ•¸æ“š
    ground_truth = create_ground_truth_dataset()
    total_cases = len(ground_truth)
    
    print(f"ğŸ“Š æ¸¬è©¦æ•¸æ“šé›†: {total_cases} å€‹æ¸¬è©¦æ¡ˆä¾‹")
    print("åŒ…å«: è¨­å‚™é¡ã€è»Ÿé«”é¡ã€æ–‡ä»¶é¡ã€äººå“¡é¡ã€æœå‹™é¡ã€è¤‡é›œæ··åˆæ¡ˆä¾‹ã€è®ŠåŒ–ç‰ˆæœ¬")
    print()
    
    # åˆå§‹åŒ–ä¸‰å€‹ç‰ˆæœ¬çš„åˆ†é¡å™¨
    print("ğŸ”„ åˆå§‹åŒ–åˆ†é¡å™¨...")
    
    try:
        classifier_v1 = ClassifierV1()
        print("âœ… V1 (åŸå§‹ç‰ˆæœ¬) åˆå§‹åŒ–å®Œæˆ")
    except Exception as e:
        print(f"âŒ V1 åˆå§‹åŒ–å¤±æ•—: {e}")
        classifier_v1 = None
    
    try:
        classifier_v2 = EnhancedClassifierV2()
        print("âœ… V2 (å¢å¼·ç‰ˆæœ¬) åˆå§‹åŒ–å®Œæˆ")
    except Exception as e:
        print(f"âŒ V2 åˆå§‹åŒ–å¤±æ•—: {e}")
        classifier_v2 = None
    
    try:
        classifier_v3 = UltimateClassifier()
        print("âœ… V3 (ä¿ç•™è©ç‰ˆæœ¬) åˆå§‹åŒ–å®Œæˆ")
    except Exception as e:
        print(f"âŒ V3 åˆå§‹åŒ–å¤±æ•—: {e}")
        classifier_v3 = None
    
    print()
    
    # åŸ·è¡Œæ¸¬è©¦
    results = {
        'test_case': [],
        'ground_truth': [],
        'v1_prediction': [],
        'v2_prediction': [],
        'v3_prediction': [],
        'v1_correct': [],
        'v2_correct': [],
        'v3_correct': []
    }
    
    print("ğŸ§ª åŸ·è¡Œåˆ†é¡æ¸¬è©¦...")
    print("-" * 100)
    
    for i, (test_text, expected) in enumerate(ground_truth, 1):
        print(f"é€²åº¦: {i}/{total_cases} - {test_text}", end=" ")
        
        # V1 æ¸¬è©¦
        v1_pred = "éŒ¯èª¤"
        if classifier_v1:
            try:
                v1_pred = classifier_v1.classify(test_text)
            except:
                v1_pred = "éŒ¯èª¤"
        
        # V2 æ¸¬è©¦
        v2_pred = "éŒ¯èª¤"
        if classifier_v2:
            try:
                v2_result = classifier_v2.classify_text(test_text)
                v2_pred = v2_result['best_prediction']
            except:
                v2_pred = "éŒ¯èª¤"
        
        # V3 æ¸¬è©¦
        v3_pred = "éŒ¯èª¤"
        if classifier_v3:
            try:
                v3_result = classifier_v3.classify(test_text)
                v3_pred = v3_result['predicted_category']
            except:
                v3_pred = "éŒ¯èª¤"
        
        # è¨˜éŒ„çµæœ
        results['test_case'].append(test_text)
        results['ground_truth'].append(expected)
        results['v1_prediction'].append(v1_pred)
        results['v2_prediction'].append(v2_pred)
        results['v3_prediction'].append(v3_pred)
        results['v1_correct'].append(v1_pred == expected)
        results['v2_correct'].append(v2_pred == expected)
        results['v3_correct'].append(v3_pred == expected)
        
        # é¡¯ç¤ºçµæœ
        status_v1 = "âœ…" if v1_pred == expected else "âŒ"
        status_v2 = "âœ…" if v2_pred == expected else "âŒ"
        status_v3 = "âœ…" if v3_pred == expected else "âŒ"
        
        print(f"â†’ {expected} | V1:{status_v1} V2:{status_v2} V3:{status_v3}")
    
    return results

def generate_accuracy_comparison_table(results):
    """ç”Ÿæˆæº–ç¢ºç‡å°æ¯”è¡¨æ ¼"""
    print("\n" + "="*100)
    print("ğŸ“Š Table 1: Ground Truth æº–ç¢ºç‡å°æ¯”")
    print("="*100)
    
    total_cases = len(results['test_case'])
    
    # è¨ˆç®—ç¸½é«”æº–ç¢ºç‡
    v1_accuracy = sum(results['v1_correct']) / total_cases
    v2_accuracy = sum(results['v2_correct']) / total_cases  
    v3_accuracy = sum(results['v3_correct']) / total_cases
    
    # æŒ‰é¡åˆ¥è¨ˆç®—æº–ç¢ºç‡
    categories = list(set(results['ground_truth']))
    
    # å‰µå»ºå°æ¯”è¡¨æ ¼
    print(f"{'é¡åˆ¥':<15} {'æ¸¬è©¦æ•¸é‡':<10} {'V1 æº–ç¢ºç‡':<15} {'V2 æº–ç¢ºç‡':<15} {'V3 æº–ç¢ºç‡':<15} {'æœ€ä½³ç‰ˆæœ¬':<10}")
    print("-" * 85)
    
    category_stats = {}
    
    for category in sorted(categories):
        # æ‰¾å‡ºè©²é¡åˆ¥çš„æ‰€æœ‰æ¡ˆä¾‹
        category_indices = [i for i, cat in enumerate(results['ground_truth']) if cat == category]
        category_count = len(category_indices)
        
        # è¨ˆç®—è©²é¡åˆ¥çš„æº–ç¢ºç‡
        v1_cat_correct = sum(results['v1_correct'][i] for i in category_indices)
        v2_cat_correct = sum(results['v2_correct'][i] for i in category_indices)
        v3_cat_correct = sum(results['v3_correct'][i] for i in category_indices)
        
        v1_cat_acc = v1_cat_correct / category_count if category_count > 0 else 0
        v2_cat_acc = v2_cat_correct / category_count if category_count > 0 else 0
        v3_cat_acc = v3_cat_correct / category_count if category_count > 0 else 0
        
        # æ‰¾å‡ºæœ€ä½³ç‰ˆæœ¬
        best_acc = max(v1_cat_acc, v2_cat_acc, v3_cat_acc)
        if v3_cat_acc == best_acc:
            best_version = "V3"
        elif v2_cat_acc == best_acc:
            best_version = "V2"
        else:
            best_version = "V1"
        
        print(f"{category:<15} {category_count:<10} {v1_cat_acc:.3f} ({v1_cat_correct}/{category_count}){'':<2} "
              f"{v2_cat_acc:.3f} ({v2_cat_correct}/{category_count}){'':<2} "
              f"{v3_cat_acc:.3f} ({v3_cat_correct}/{category_count}){'':<2} {best_version:<10}")
        
        category_stats[category] = {
            'count': category_count,
            'v1_acc': v1_cat_acc,
            'v2_acc': v2_cat_acc, 
            'v3_acc': v3_cat_acc,
            'best': best_version
        }
    
    print("-" * 85)
    print(f"{'ç¸½é«”':<15} {total_cases:<10} {v1_accuracy:.3f} ({sum(results['v1_correct'])}/{total_cases}){'':<2} "
          f"{v2_accuracy:.3f} ({sum(results['v2_correct'])}/{total_cases}){'':<2} "
          f"{v3_accuracy:.3f} ({sum(results['v3_correct'])}/{total_cases}){'':<2} "
          f"{'V3' if v3_accuracy >= max(v1_accuracy, v2_accuracy) else 'V2' if v2_accuracy >= v1_accuracy else 'V1':<10}")
    
    # æ”¹å–„çµ±è¨ˆ
    print("\nğŸ“ˆ æ”¹å–„çµ±è¨ˆ:")
    v2_improvement = v2_accuracy - v1_accuracy
    v3_improvement = v3_accuracy - v1_accuracy
    v3_vs_v2 = v3_accuracy - v2_accuracy
    
    print(f"   V2 ç›¸å° V1 æ”¹å–„: {v2_improvement:+.3f} ({v2_improvement*100:+.1f}%)")
    print(f"   V3 ç›¸å° V1 æ”¹å–„: {v3_improvement:+.3f} ({v3_improvement*100:+.1f}%)")
    print(f"   V3 ç›¸å° V2 æ”¹å–„: {v3_vs_v2:+.3f} ({v3_vs_v2*100:+.1f}%)")
    
    return category_stats

def generate_technical_comparison_table():
    """ç”ŸæˆæŠ€è¡“ç‰¹æ€§å°æ¯”è¡¨æ ¼"""
    print("\n" + "="*100)
    print("ğŸ”§ Table 2: æŠ€è¡“ç‰¹æ€§èˆ‡åŠŸèƒ½å·®ç•°å°æ¯”")
    print("="*100)
    
    # æŠ€è¡“ç‰¹æ€§å°æ¯”æ•¸æ“š
    comparison_data = [
        ["æ ¸å¿ƒæŠ€è¡“", "åŸºç¤æ–‡æœ¬åŒ¹é… + ç›¸ä¼¼åº¦", "TF-IDF + å­—ç¬¦n-gram + è¦å‰‡", "ä¿ç•™è©è™•ç† + å¤šç‰¹å¾µèåˆ"],
        ["åˆ†è©æ–¹å¼", "jieba é è¨­åˆ†è©", "jieba + å­—ç¬¦ç´šn-gram", "ä¿ç•™è©è¨»å†Š + jiebaåˆ†è©"],
        ["ç‰¹å¾µæå–", "TF-IDF (è©ç´š)", "TF-IDF (å­—ç¬¦2-4gram)", "ä¿ç•™è© + é—œéµè© + æ¨¡å¼ + TF-IDF"],
        ["æ¬Šé‡ç­–ç•¥", "ç°¡å–®æŠ•ç¥¨", "åŠ æ¬Šçµ„åˆ (40%+30%+30%)", "éšå±¤æ¬Šé‡ (40%+25%+20%+15%)"],
        ["ä¿ç•™è©åŠŸèƒ½", "âŒ ç„¡", "âŒ ç„¡", "âœ… å®Œæ•´æ”¯æ´"],
        ["è¤‡åˆè©è™•ç†", "âŒ åŸºç¤", "âš ï¸ éƒ¨åˆ†", "âœ… å°ˆé–€å„ªåŒ–"],
        ["æ’é™¤è¦å‰‡", "âŒ ç„¡", "âœ… åŸºç¤æ’é™¤", "âœ… é€²éšæ’é™¤ + ä¿ç•™è©æ’é™¤"],
        ["è®ŠåŒ–ç‰ˆæœ¬è™•ç†", "âŒ å¼±", "âš ï¸ ä¸­ç­‰", "âœ… å¼·"],
        ["ç›¸ä¼¼åº¦è¨ˆç®—", "cosine similarity", "cosine similarity", "cosine similarity + ä¿ç•™è©åŠ æ¬Š"],
        ["æ¨¡å¼åŒ¹é…", "âŒ ç„¡", "âœ… æ­£å‰‡è¡¨é”å¼", "âœ… æ­£å‰‡ + ä¿ç•™è©æ¨¡å¼"],
        ["é—œéµè©åŒ¹é…", "åŸºç¤", "åˆ†ç´šé—œéµè© (å¼·/ä¸­/å¼±)", "åˆ†ç´šé—œéµè© + ä¿ç•™è©åŠ æˆ"],
        ["éŒ¯èª¤ä¿®æ­£", "âŒ ç„¡", "âš ï¸ åŸºç¤", "âœ… æ™ºèƒ½è¦å‰‡"],
        ["è™•ç†è¤‡é›œåº¦", "O(n)", "O(n log n)", "O(n log n)"],
        ["è¨˜æ†¶é«”ä½¿ç”¨", "ä½", "ä¸­", "ä¸­-é«˜"],
        ["åˆå§‹åŒ–æ™‚é–“", "å¿«", "ä¸­", "ä¸­"],
        ["é æ¸¬é€Ÿåº¦", "å¿«", "ä¸­", "ä¸­"],
        ["å¯è§£é‡‹æ€§", "ä½", "ä¸­", "é«˜"],
        ["ç¶­è­·é›£åº¦", "ä½", "ä¸­", "ä¸­-é«˜"],
        ["æ“´å±•æ€§", "ä½", "ä¸­", "é«˜"],
        ["é©ç”¨å ´æ™¯", "ç°¡å–®åˆ†é¡", "ä¸€èˆ¬åˆ†é¡", "è¤‡é›œå°ˆæ¥­åˆ†é¡"]
    ]
    
    # æ‰“å°è¡¨æ ¼
    print(f"{'ç‰¹æ€§/åŠŸèƒ½':<20} {'V1 (åŸå§‹ç‰ˆ)':<25} {'V2 (å¢å¼·ç‰ˆ)':<30} {'V3 (ä¿ç•™è©ç‰ˆ)':<25}")
    print("-" * 105)
    
    for row in comparison_data:
        feature, v1, v2, v3 = row
        print(f"{feature:<20} {v1:<25} {v2:<30} {v3:<25}")
    
    print("\nğŸ” æŠ€è¡“å·®ç•°èªªæ˜:")
    print("=" * 50)
    print("âœ… å®Œå…¨æ”¯æ´  âš ï¸ éƒ¨åˆ†æ”¯æ´  âŒ ä¸æ”¯æ´")
    print()
    print("ğŸ“‹ ä¸»è¦æŠ€è¡“é€²æ­¥:")
    print("   V1 â†’ V2: å¼•å…¥å­—ç¬¦ç´šn-gramã€åˆ†å±¤é—œéµè©ã€æ’é™¤è¦å‰‡")
    print("   V2 â†’ V3: ä¿ç•™è©è™•ç†ã€è¤‡åˆè©å„ªåŒ–ã€æ™ºèƒ½æ’é™¤è¦å‰‡")
    print()
    print("ğŸ¯ V3 ç¨æœ‰å„ªå‹¢:")
    print("   1. ä¿ç•™è©åŠŸèƒ½ - è§£æ±ºè¤‡åˆè©åˆ†å‰²å•é¡Œ")
    print("   2. èªç¾©å®Œæ•´æ€§ - ä¿æŒæŠ€è¡“è¡“èªçš„å®Œæ•´æ€§") 
    print("   3. å°ˆæ¥­è©å½™è™•ç† - é‡å°å°ˆæ¥­é ˜åŸŸå„ªåŒ–")
    print("   4. æ™ºèƒ½æ¬Šé‡åˆ†é… - ä¿ç•™è©40%æœ€é«˜æ¬Šé‡")

def generate_detailed_error_analysis(results):
    """ç”Ÿæˆè©³ç´°éŒ¯èª¤åˆ†æ"""
    print("\n" + "="*100)
    print("ğŸ” è©³ç´°éŒ¯èª¤åˆ†æ")
    print("="*100)
    
    # æ‰¾å‡ºå„ç‰ˆæœ¬çš„éŒ¯èª¤æ¡ˆä¾‹
    v1_errors = []
    v2_errors = []
    v3_errors = []
    
    for i in range(len(results['test_case'])):
        test_case = results['test_case'][i]
        ground_truth = results['ground_truth'][i]
        
        if not results['v1_correct'][i]:
            v1_errors.append((test_case, ground_truth, results['v1_prediction'][i]))
        if not results['v2_correct'][i]:
            v2_errors.append((test_case, ground_truth, results['v2_prediction'][i]))
        if not results['v3_correct'][i]:
            v3_errors.append((test_case, ground_truth, results['v3_prediction'][i]))
    
    print(f"ğŸ“Š éŒ¯èª¤æ¡ˆä¾‹çµ±è¨ˆ:")
    print(f"   V1 éŒ¯èª¤: {len(v1_errors)} å€‹")
    print(f"   V2 éŒ¯èª¤: {len(v2_errors)} å€‹") 
    print(f"   V3 éŒ¯èª¤: {len(v3_errors)} å€‹")
    print()
    
    # é¡¯ç¤ºV3ä»ç„¶éŒ¯èª¤çš„æ¡ˆä¾‹
    if v3_errors:
        print("âŒ V3 ä»éœ€æ”¹é€²çš„æ¡ˆä¾‹:")
        for i, (case, expected, predicted) in enumerate(v3_errors[:10], 1):
            print(f"   {i}. '{case}' â†’ é æ¸¬:{predicted}, å¯¦éš›:{expected}")
    else:
        print("ğŸ‰ V3 å®Œç¾åˆ†é¡æ‰€æœ‰æ¸¬è©¦æ¡ˆä¾‹ï¼")
    
    # V3ç›¸å°V2çš„æ”¹é€²æ¡ˆä¾‹
    v2_errors_set = set(err[0] for err in v2_errors)
    v3_errors_set = set(err[0] for err in v3_errors)
    
    v3_improvements = v2_errors_set - v3_errors_set
    if v3_improvements:
        print(f"\nâœ¨ V3 ç›¸å° V2 ä¿®æ­£çš„æ¡ˆä¾‹ ({len(v3_improvements)}å€‹):")
        for i, case in enumerate(list(v3_improvements)[:10], 1):
            print(f"   {i}. '{case}' - ä¿ç•™è©åŠŸèƒ½æˆåŠŸä¿®æ­£")

def save_results_to_file(results):
    """å„²å­˜æ¸¬è©¦çµæœåˆ°æª”æ¡ˆ"""
    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
    filename = f"three_version_comparison_{timestamp}.json"
    
    import json
    with open(filename, 'w', encoding='utf-8') as f:
        json.dump(results, f, ensure_ascii=False, indent=2)
    
    print(f"\nğŸ’¾ æ¸¬è©¦çµæœå·²å„²å­˜è‡³: {filename}")

def main():
    """ä¸»å‡½æ•¸"""
    # åŸ·è¡Œå…¨é¢æ¸¬è©¦
    results = run_comprehensive_test()
    
    # ç”Ÿæˆå°æ¯”è¡¨æ ¼
    category_stats = generate_accuracy_comparison_table(results)
    generate_technical_comparison_table()
    
    # è©³ç´°åˆ†æ
    generate_detailed_error_analysis(results)
    
    # å„²å­˜çµæœ
    save_results_to_file(results)
    
    # æœ€çµ‚ç¸½çµ
    print("\n" + "="*100)
    print("ğŸ† æ¸¬è©¦ç¸½çµ")
    print("="*100)
    
    total_cases = len(results['test_case'])
    v1_accuracy = sum(results['v1_correct']) / total_cases
    v2_accuracy = sum(results['v2_correct']) / total_cases
    v3_accuracy = sum(results['v3_correct']) / total_cases
    
    print(f"ğŸ“Š æœ€çµ‚æº–ç¢ºç‡:")
    print(f"   V1 (åŸå§‹ç‰ˆ): {v1_accuracy:.3f} ({v1_accuracy*100:.1f}%)")
    print(f"   V2 (å¢å¼·ç‰ˆ): {v2_accuracy:.3f} ({v2_accuracy*100:.1f}%)")
    print(f"   V3 (ä¿ç•™è©ç‰ˆ): {v3_accuracy:.3f} ({v3_accuracy*100:.1f}%)")
    print()
    
    if v3_accuracy >= max(v1_accuracy, v2_accuracy):
        print("ğŸ¥‡ æ¨è–¦ç‰ˆæœ¬: V3 (ä¿ç•™è©ç‰ˆ)")
        print("   âœ… æœ€é«˜æº–ç¢ºç‡")
        print("   âœ… è§£æ±ºäº†è¤‡åˆè©åˆ†å‰²å•é¡Œ") 
        print("   âœ… å°ˆæ¥­è©å½™è™•ç†å„ªç•°")
    elif v2_accuracy >= v1_accuracy:
        print("ğŸ¥ˆ æ¨è–¦ç‰ˆæœ¬: V2 (å¢å¼·ç‰ˆ)")
        print("   âš ï¸ V3 éœ€è¦é€²ä¸€æ­¥èª¿æ•´")
    else:
        print("âš ï¸ æ‰€æœ‰ç‰ˆæœ¬éƒ½éœ€è¦æ”¹é€²")
    
    return results

if __name__ == "__main__":
    main()