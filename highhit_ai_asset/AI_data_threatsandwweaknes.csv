資產層級,資產類別,資產名稱,威脅,威脅說明,威脅 Reference,威脅源,威脅源說明,威脅源 Reference,弱點,弱點說明,弱點 Reference,對應ISO 42005資產類別,衝擊類別,衝擊說明,衝擊 Reference
組織,有形資產,數據 (訓練數據),污染訓練資料以植入後門 (Poison Training Data - Backdoor Attack),攻擊者在訓練資料中注入帶有特定觸發器（trigger）的樣本，使模型在遇到該觸發器時產生攻擊者預設的錯誤輸出，而正常輸入則不受影響。,MITRE ATLAS: AML.T0020,敵對的內部人員 (Adversarial Insider),具備合法資料存取權限的員工、承包商，出於惡意動機（如報復、商業間諜）竄改訓練資料。,"NIST SP 800-30 Rev. 1, Appendix D, Table D-2",資料變更的監控與審計機制不足,缺乏對訓練資料集的版本控制、存取紀錄和完整性校驗，無法即時偵測到未經授權的修改。,"NIST AI RMF 1.0, GOVERN 1.3",6.3 AI 系統資訊,安全性與隱私 / 可靠性,模型在特定條件下被遠端操控，可能導致關鍵決策錯誤、略過安全驗證或執行惡意指令。,Clause 6.8.2.2
組織,有形資產,數據 (訓練數據),污染訓練資料以降低模型可用性 (Poison Training Data - Availability Attack),攻擊者在訓練資料中注入大量雜訊或不相關的樣本，旨在破壞模型的學習過程，使其整體預測準確率下降，無法正常提供服務。,MITRE ATLAS: AML.T0020,外部攻擊者 (External Attacker),競爭對手或駭客組織透過入侵資料庫或資料管道，對訓練資料進行大規模的破壞性修改。,"NIST SP 800-30 Rev. 1, Appendix D, Table D-2",資料來源與管道的防護不足,從外部來源收集資料的管道（如 API、爬蟲）缺乏足夠的安全驗證，容易被注入惡意資料。,"NIST AI RMF 1.0, MAP 2.3",6.3 AI 系統資訊,可靠性,模型的性能顯著下降，導致服務中斷、決策品質低落，影響業務連續性。,Clause 6.8.2
組織,有形資產,數據 (訓練數據),污染訓練資料以注入偏見 (Poison Training Data - Bias Injection),攻擊者刻意在訓練資料中不成比例地增加或刪除特定群體的樣本，導致模型對該群體產生歧視性或不公平的預測結果。,MITRE ATLAS: AML.T0020,意識形態活動家 (Ideological Activist),特定團體為了宣揚其理念或打擊特定族群，惡意操縱公開的資料集或透過眾包平台污染資料標註。,"NIST SP 800-30 Rev. 1, Appendix D, Table D-2",資料集代表性與偏見的分析不足,在模型開發前，未能對訓練資料的來源、分布及潛在的社會偏見進行充分的審查與緩解。,"NIST AI RMF 1.0, MAP 2.1",6.4 資料與知識,公平性,AI 系統對特定受保護群體做出不公平的決策（如招聘、信貸審批），引發社會爭議、法律訴訟與品牌聲譽受損。,Clause 6.8.2.3
組織,有形資產,數據 (訓練數據),成員推斷攻擊 (Membership Inference Attack),攻擊者透過與模型互動，判斷某一筆特定資料（例如某位用戶的個人資料）是否曾被用於該模型的訓練，進而洩漏個人隱私。,MITRE ATLAS: AML.T0010,好奇的內部人員或外部研究員,具有模型查詢權限的人員，出於好奇心或惡意研究，試圖驗證特定敏感資料是否存在於訓練集中。,"NIST SP 800-30 Rev. 1, Appendix D, Table D-2",訓練資料的匿名化或差分隱私技術應用不足,在將敏感資料用於訓練前，未能採取有效的去識別化技術來保護個人隱私。,"NIST AI RMF 1.0, MEASURE 1.2",6.4 資料與知識,安全性與隱私,洩漏了用戶曾參與某項訓練（如特定疾病預測模型），違反 GDPR、個資法等法規，面臨高額罰款與信任危機。,Clause 6.5.4 (j)
組織,有形資產,數據 (訓練數據),訓練資料竊取 (Data Theft),未經授權的第三方直接竊取儲存訓練資料的整個資料庫或檔案，可能用於訓練自己的模型或轉售牟利。,NIST AI RMF 1.0 (Core: MAP 3.1),組織犯罪 (Organized Crime),犯罪集團以獲取高價值的專有數據為目標，進行有組織的網路攻擊。,"NIST SP 800-30 Rev. 1, Appendix D, Table D-2",存取控制與加密機制不當,儲存訓練資料的伺服器或雲端儲存桶的存取權限設定過於寬鬆，或未對靜態資料進行加密。,"NIST AI RMF 1.0, GOVERN 2",6.4 資料與知識,安全性與隱私,喪失核心商業資產，削弱競爭優勢；若資料包含客戶隱私，將引發大規模的個資外洩事件，造成巨大財務損失。,Clause 6.8.2.1
組織,有形資產,數據 (訓練數據),不當的資料標註 (Incorrect Data Labeling),由於人工標註錯誤、標註指引不清或標註工具的缺陷，導致訓練資料中的標籤不準確，進而影響模型學習的正確性。,NIST AI RMF 1.0 (Core: GOVERN 4.2),資料標註人員 (Human Annotator),標註人員因疏忽、疲勞或對標註任務理解不清，提供了錯誤的標籤。,"NIST SP 800-30 Rev. 1, Appendix D, Table D-3",缺乏標註品質的驗證與共識機制,未能建立多重標註、交叉驗證或由專家審核的機制，來確保資料標註的一致性與準確性。,"NIST AI RMF 1.0, GOVERN 4.2",6.4 資料與知識,可靠性 / 責任制,模型學習到錯誤的模式導致預測失準；在安全場景下可能造成防護失效，且難以追究錯誤標註的責任。,Clause 6.8.2
組織,有形資產,數據 (訓練數據),侵犯版權與智慧財產權 (Copyright and IP Infringement),在未經授權的情況下，使用受版權保護的資料（如圖片、文章、程式碼）進行模型訓練，違反了相關法律法規。,NIST AI RMF 1.0 (Core: GOVERN 5),開發人員 (Developer),開發人員為了快速取得資料，或因對智財權法規不熟悉，從網路上抓取未經授權的內容用於模型訓練。,"NIST SP 800-30 Rev. 1, Appendix D, Table D-3",資料來源的合法性與授權追蹤不足,組織缺乏對所用資料來源的智慧財產權進行審查的流程，也未能記錄和管理相關的授權許可。,"NIST AI RMF 1.0, GOVERN 5",6.4 資料與知識,責任制,公司可能面臨侵權訴訟，被要求銷毀模型、支付高額賠償金，並對商譽造成嚴重打擊。,Clause 6.3.4
組織,有形資產,數據 (訓練數據),資料集漂移 (Dataset Drift),用於訓練模型的歷史資料分布，與模型部署後在真實世界中遇到的資料分布產生顯著差異，導致模型性能下降。,NIST AI RMF 1.0 (Core: MANAGE 2),自然的環境變化 (Natural Environmental Shift),市場趨勢、用戶行為或外部環境隨時間自然演變，導致舊的資料模式不再適用。,"NIST SP 800-30 Rev. 1, Appendix D, Table D-4",缺乏對資料分布的持續監控機制,模型部署後，未能建立有效機制來監控輸入資料的統計特性，並在發生漂移時觸發警報或再訓練流程。,"NIST AI RMF 1.0, MANAGE 2",6.4 資料與知識,可靠性,模型在現實場景中的預測能力逐漸衰退，做出過時或錯誤的判斷，影響業務決策的時效性與準確性。,Clause 6.8.2
組織,有形資產,數據 (訓練數據),訓練-服務歪斜 (Train-Serve Skew),訓練階段與服務階段的資料預處理流程不一致，導致模型在實際應用中收到的特徵與訓練時學習到的特徵不匹配。,NIST AI RMF 1.0 (Core: GOVERN 3),維運/開發團隊 (Operations/Dev Team),負責部署的工程師與資料科學家在實作資料處理流程時產生細微差異，此為流程與溝通上的疏失。,"NIST SP 800-30 Rev. 1, Appendix D, Table D-3",開發與部署流程(MLOps)未標準化,缺乏一個統一且自動化的流程來確保從資料獲取、預處理到模型推論的每一步驟都是一致且可重現的。,"NIST AI RMF 1.0, GOVERN 3",6.3 AI 系統資訊,可靠性 / 透明度/可解釋性,模型線上表現遠不如預期，且因流程不一致導致問題難以追溯與解釋。,Clause 6.3.4
組織,有形資產,數據 (訓練數據),屬性推斷攻擊 (Attribute Inference Attack),即使不知道某個體在訓練集中，攻擊者仍可透過模型推斷出該個體的敏感屬性（例如，從寫作風格推斷作者的母語或教育程度）。,MITRE ATLAS: AML.T0011,惡意的模型使用者 (Malicious Model User),任何可以與模型互動的使用者，透過精心設計的查詢來反向推斷訓練資料中存在的群體特徵或個人屬性。,"NIST SP 800-30 Rev. 1, Appendix D, Table D-2",模型對訓練資料的過度記憶 (Over-memorization),模型（特別是大型模型）在訓練過程中記憶了部分訓練樣本的細節，而不是學習到泛化的規律，導致敏感資訊洩漏。,"NIST AI RMF 1.0, MEASURE 2.3",6.5 演算法與模型資訊,安全性與隱私,揭露了個人未曾公開的敏感資訊，可能被用於歧視、詐騙或社會工程攻擊，構成嚴重的隱私侵害。,Clause 6.5.4 (j)
組織,有形資產,數據 (訓練數據),資料殘留與不完全刪除 (Data Remanence and Incomplete Deletion),當用戶要求刪除其資料時，未能將其從所有訓練資料集、備份及衍生模型中徹底移除，違反「被遺忘權」。,NIST AI RMF 1.0 (Core: GOVERN 1.2),系統管理員/流程負責人,執行資料刪除請求時，因流程不完整或技術限制，僅刪除了主資料庫中的紀錄，卻忽略了存在於各處的副本。,"NIST SP 800-30 Rev. 1, Appendix D, Table D-3",缺乏完整的資料生命週期與沿襲管理,對資料的流動、複製和使用缺乏清晰的追蹤地圖，導致無法在需要時定位並徹底清除所有相關資料。,"NIST AI RMF 1.0, GOVERN 1.2",6.4 資料與知識,責任制 / 公平性,違反 GDPR 等法規的「被遺忘權」條款，可能導致監管處罰；未能公平對待用戶的資料權利，損害用戶信任。,Clause 6.8.2.2
組織,有形資產,數據 (測試數據),測試集污染以誤導模型評估 (Test Set Contamination for Misleading Evaluation),攻擊者竄改測試數據或其標籤，使得一個性能差的模型在評估指標上看起來表現良好（例如，移除困難的樣本），或讓一個性能好的模型看起來很差（例如，故意標記錯誤）。,MITRE ATLAS: AML.T0042,競爭對手 / 惡意內部人員,為了讓自家模型在競標中勝出，或為了破壞公司產品發布，惡意修改用於最終驗收的黃金測試集 (Golden Test Set)。,"NIST SP 800-30 Rev. 1, Appendix D, Table D-2",測試數據的存取控制與完整性保護不足,用於模型評估的標準測試集缺乏嚴格的存取控制、版本管理與完整性校驗，容易被未授權竄改。,"NIST AI RMF 1.0, MEASURE 1.3",6.4 資料與知識,可靠性 / 責任制,組織基於被操縱的評估結果做出錯誤決策，部署了有問題的 AI 系統，導致後續的系統失效與責任追溯困難。,Clause 6.8.2
組織,有形資產,數據 (測試數據),訓練/測試數據洩漏 (Training/Test Data Leakage),在模型開發過程中，訓練數據的樣本不慎混入測試數據中。這導致模型在測試時看到了「已知的考題」，產生虛高的性能指標。,NIST AI RMF 1.0 (Core: GOVERN 3.2),開發團隊 (Development Team),資料科學家在切分資料集時，因流程疏忽或工具使用不當，未能嚴格分離訓練集與測試集。,"NIST SP 800-30 Rev. 1, Appendix D, Table D-3",缺乏標準化的資料切分與驗證流程,沒有自動化且可重現的 MLOps 流程來確保訓練、驗證與測試數據集之間的絕對獨立性。,"NIST AI RMF 1.0, GOVERN 3.2",6.4 資料與知識,可靠性 / 透明度與可解釋性,過度樂觀的評估結果掩蓋了模型的真實泛化能力，一旦部署到真實環境，性能將急劇下降，且難以解釋為何離線與線上表現差異巨大。,Clause 6.3.4
組織,有形資產,數據 (測試數據),不具代表性的測試數據 (Unrepresentative Test Data),測試數據的分布與真實世界中預期遇到的數據分布存在顯著差異，例如測試集中缺少對某些少數族群的樣本。,NIST AI RMF 1.0 (Core: MAP 2.1),資料搜集/策展團隊,團隊在搜集或抽樣測試數據時，因便利性或認知偏差，未能涵蓋所有預期的用戶群體或操作場景。,"NIST SP 800-30 Rev. 1, Appendix D, Table D-3",對資料分布與覆蓋範圍的分析不足,在進行模型評估前，未能對測試數據的人口統計學分布、場景覆蓋率等進行充分的分析與驗證。,"NIST AI RMF 1.0, MAP 2.1",6.4 資料與知識,公平性 / 可靠性,模型在測試中表現良好，但部署後對未被充分代表的群體產生歧視性或錯誤的結果，損害用戶權益與系統可靠性。,Clause 6.8.2.3
組織,有形資產,數據 (測試數據),對抗性樣本逃逸攻擊評估 (Evasion Attack Evaluation),攻擊者特意製作微小擾動的輸入樣本（對抗性樣本）來作為測試數據，以評估模型在面對刻意規避或欺騙的輸入時的穩健性。此為一種「紅隊演練」威脅。,MITRE ATLAS: AML.T0030,安全測試團隊 / 外部攻擊者,透過產生對抗性樣本來找出模型的弱點，例如讓一個內容審核模型將有害圖片誤判為正常。,"NIST SP 800-30 Rev. 1, Appendix D, Table D-2",缺乏對抗性穩健性測試與防禦機制,模型在開發過程中僅考慮了常規數據，未經對抗性訓練或相關防禦機制的加固。,"NIST AI RMF 1.0, MEASURE 2.3",6.5 演算法與模型資訊,安全性與隱私,惡意用戶可利用微小擾動繞過系統的安全檢測（如惡意軟體檢測、身份驗證），導致安全漏洞。,Clause 6.8.2.2
組織,有形資產,數據 (測試數據),測試數據的隱私資訊推斷 (Privacy Inference from Test Data),即使攻擊者無法直接存取測試數據，但若能觀察模型在測試集上的輸出結果（例如，發布的評估報告或 Log），也可能反向推斷出測試數據中的敏感個人資訊。,MITRE ATLAS: AML.T0011,外部研究員 / 競爭對手,透過分析模型在測試集上的分類錯誤或預測信心的細微變化，推斷出某個特定個體是否在測試集中，或其敏感屬性。,"NIST SP 800-30 Rev. 1, Appendix D, Table D-2",測試結果與日誌的匿名化處理不足,對外發布模型評估報告或在內部共享測試日誌時，未能對可能洩漏個資的細節（如具體樣本 ID、高精度分數）進行脫敏處理。,"NIST AI RMF 1.0, MEASURE 1.2",6.4 資料與知識,安全性與隱私,違反資料保護法規，洩漏了參與測試的數據主體的個人隱私，即使他們並未在訓練集中。,Clause 6.5.4 (j)
組織,有形資產,數據 (測試數據),測試數據竊取 (Test Data Theft),未經授權的第三方竊取了整個測試資料集。相較於訓練集，測試集通常被視為更能代表真實世界分布的「黃金標準」，具有極高的商業價值。,NIST AI RMF 1.0 (Core: MAP 3.1),組織犯罪 / 競爭對手,竊取高品質的測試數據，可用於評估或優化自己的模型，或直接洞察目標市場的用戶行為模式。,"NIST SP 800-30 Rev. 1, Appendix D, Table D-2",測試數據的儲存與傳輸缺乏加密,測試數據以明文形式儲存在伺服器或在內部網路中傳輸，一旦網路被滲透，數據將輕易被竊取。,"NIST AI RMF 1.0, GOVERN 2",6.4 資料與知識,安全性與隱私,喪失關鍵商業資產，幫助競爭對手縮小技術差距；若包含個資，則構成數據外洩事件。,Clause 6.8.2.1
組織,有形資產,數據 (測試數據),過時的測試數據 (Outdated Test Data),用於評估模型的測試數據，是在過去某個時間點收集的，已無法反映當前真實世界的數據分布或用戶行為模式（即概念漂移）。,NIST AI RMF 1.0 (Core: MANAGE 2),自然的環境變化 (Natural Environmental Shift),市場趨勢、用戶偏好或外部事件隨時間改變，導致舊的測試標準不再有效。,"NIST SP 800-30 Rev. 1, Appendix D, Table D-4",缺乏定期更新測試數據的機制,組織建立了一次性的基準測試集後，未能根據業務環境的變化，定期審查和更新測試數據。,"NIST AI RMF 1.0, MANAGE 2",6.4 資料與知識,可靠性,模型在過時的數據上測試通過，但實際部署後面對新場景卻頻繁出錯，導致業務決策失誤。,Clause 6.8.2
組織,有形資產,數據 (測試數據),評估指標的誤用或單一化 (Misuse of Evaluation Metrics),僅使用單一的評估指標（如準確率）來測試模型，而忽略了其他重要維度，例如在不平衡數據集上應更關注精確率、召回率或 F1 分數。,NIST AI RMF 1.0 (Core: MEASURE 1.1),開發團隊 (Development Team),開發人員為了方便，或對業務場景理解不深，選擇了不恰當或過於簡化的指標來評估模型性能。,"NIST SP 800-30 Rev. 1, Appendix D, Table D-3",未能建立與業務目標對應的綜合評估框架,缺乏一個涵蓋模型性能、公平性、穩健性等多個維度的綜合性評估指標體系。,"NIST AI RMF 1.0, MEASURE 1.1",6.5 演算法與模型資訊,公平性 / 責任制,一個在總體準確率上表現良好，但對少數群體有嚴重偏見的模型被評為「好模型」並上線，引發公平性問題且難以問責。,Clause 6.8.2.3
組織,有形資產,數據 (測試數據),來自測試數據的標籤洩漏 (Label Leakage from Test Data),在模型預測過程中，測試數據的某些特徵（Feature）意外地包含了其真實標籤（Label）的資訊，導致模型可以「作弊」。,NIST AI RMF 1.0 (Core: GOVERN 3.2),資料工程師 (Data Engineer),在進行特徵工程時，不慎將應在預測後才能獲知的資訊（如交易是否被標記為欺詐）作為模型的輸入特徵。,"NIST SP 800-30 Rev. 1, Appendix D, Table D-3",資料預處理與特徵工程的審查不足,對於加入模型輸入的每一個特徵，缺乏嚴格的審查機制來判斷其是否在預測時間點是可獲取的。,"NIST AI RMF 1.0, GOVERN 3.2",6.3 AI 系統資訊,可靠性 / 透明度與可解釋性,模型在測試時表現近乎完美，但實際上線後因無法獲取作弊特徵而完全失效。這種「捷徑學習」也讓模型行為無法被正確解釋。,Clause 6.3.4
組織,有形資產,數據 (測試數據),測試環境與生產環境不一致 (Inconsistency between Test and Production Environments),用於執行模型測試的軟硬體環境（如函式庫版本、作業系統、硬體規格）與最終部署的生產環境不一致。,NIST AI RMF 1.0 (Core: GOVERN 3),維運團隊 (Operations Team),測試環境與生產環境由不同團隊管理，缺乏統一的配置管理與同步機制。,"NIST SP 800-30 Rev. 1, Appendix D, Table D-3",缺乏容器化或標準化的部署流程,未能使用 Docker 等容器化技術來封裝模型及其所有依賴項，以確保在任何地方的行為都一致。,"NIST AI RMF 1.0, GOVERN 3",6.3 AI 系統資訊,可靠性,在測試環境中驗證通過的模型，部署到生產環境後因依賴項衝突或計算差異而產生非預期的錯誤或性能衰退。,Clause 6.8.2
組織,有形資產,數據 (生產數據),輸入規避攻擊 (Evasion Attack),攻擊者對輸入數據進行微小擾動，旨在欺騙或規避 AI 模型的檢測，使其做出錯誤的分類。,MITRE ATLAS: AML.T0030,惡意的模型使用者,企圖繞過系統的安全或內容審核機制。,"NIST SP 800-30 Rev. 1, Appendix D, Table D-2",缺乏對抗性攻擊的監控與防禦機制,系統在生產環境中沒有部署相應的監控機制來偵測潛在的對抗性輸入，也缺乏輸入淨化或對抗性訓練等防禦措施。,"NIST AI RMF 1.0, PROTECT 1.3",6.5 演算法與模型資訊,安全性與隱私 / 可靠性,模型的安全防護功能（如惡意軟體檢測、垃圾郵件過濾）被繞過，導致惡意內容或攻擊滲透到系統內部。,Clause 6.8.2.2
組織,有形資產,數據 (生產數據),數據/概念漂移 (Data/Concept Drift),生產數據的統計特性隨時間推移發生變化，不再符合模型訓練時的數據分布假設，導致模型性能顯著下降。,NIST AI RMF 1.0 (Core: MANAGE 2),自然的環境變化,用戶行為模式改變、市場趨勢演變或出現新的事件類型，都可能導致生產數據分布的自然漂移。,"NIST SP 800-30 Rev. 1, Appendix D, Table D-4",缺乏對模型性能與數據分布的持續監控,系統部署後，未能建立自動化機制來持續監控模型的預測準確率及輸入數據的統計分布，無法及時發現性能衰退。,"NIST AI RMF 1.0, MANAGE 2",6.4 資料與知識,可靠性,模型在真實世界中的預測能力逐漸失效，做出過時或錯誤的判斷，對依賴其決策的業務流程造成負面影響。,Clause 6.8.2
組織,有形資產,數據 (生產數據),生產數據中的隱私洩漏 (Privacy Leakage in Production Data),生產數據中包含大量用戶的即時個人可識別資訊 (PII)，若未經適當處理（如日誌紀錄、快取），可能因系統漏洞或配置不當而外洩。,NIST AI RMF 1.0 (Core: PROTECT 1.1),外部攻擊者 / 疏忽的內部人員,駭客透過系統漏洞竊取包含敏感資訊的日誌檔；或內部人員在分析問題時，不慎將包含個資的生產數據暴露在不安全的環境中。,"NIST SP 800-30 Rev. 1, Appendix D, Table D-2/D-3",生產數據的紀錄與儲存缺乏匿名化處理,系統在紀錄日誌或暫存數據以供除錯時，未能對其中的敏感個人資訊進行即時的遮罩、匿名化或加密處理。,"NIST AI RMF 1.0, PROTECT 1.1",6.4 資料與知識,安全性與隱私,直接導致用戶的即時敏感資訊外洩，違反 GDPR 等個資法規，引發嚴重的法律責任與用戶信任危機。,Clause 6.8.2.1
組織,有形資產,數據 (生產數據),惡意的探測攻擊 (Probing/Inference Attack),攻擊者透過向生產環境中的模型發送大量精心設計的查詢請求，並分析其回傳結果，以反向推斷模型的內部參數、決策邊界或訓練數據的資訊。,MITRE ATLAS: AML.T0016,外部研究員 / 競爭對手,企圖竊取模型的智慧財產權（模型萃取），或推斷模型訓練數據的隱私（成員推斷、屬性推斷）。,"NIST SP 800-30 Rev. 1, Appendix D, Table D-2",缺乏對 API 查詢的速率與模式限制,系統的 API 端點未能實施有效的速率限制、查詢配額或異常行為檢測，允許攻擊者進行大規模的自動化查詢。,"NIST AI RMF 1.0, PROTECT 1.3",6.3 AI 系統資訊,安全性與隱私 / 責任制,模型的智慧財產權被竊取，或訓練數據的隱私被洩漏。組織因未能保護其 AI 系統而需承擔責任。,Clause 6.5.4 (j)
組織,有形資產,數據 (生產數據),有害內容或指令注入 (Harmful Content or Prompt Injection),對於生成式 AI，用戶在生產環境中輸入惡意提示詞，旨在誘使或操控模型產生不安全、不道德、有偏見或違反使用政策的內容。,MITRE ATLAS: AML.T0043,惡意的模型使用者,使用者試圖繞過模型的內容護欄 (Safety Guardrails)，讓模型生成有害言論、假消息或執行非預期的功能。,"NIST SP 800-30 Rev. 1, Appendix D, Table D-2",對輸入提示詞的過濾與淨化不足,系統在將用戶輸入傳遞給模型之前，未能有效過濾其中潛在的惡意指令、引導性語言或越獄企圖。,"NIST AI RMF 1.0, PROTECT 1.3",6.5 演算法與模型資訊,安全性與隱私 / 公平性,模型被當成工具，用於產生和傳播有害內容，可能對個人或社群造成傷害，或產生不公平的描述，損害組織聲譽。,Clause 6.8.2.2
組織,有形資產,數據 (生產數據),異常資料導致服務阻斷 (Denial of Service via Anomalous Data),攻擊者向系統提交一個經特殊設計的、結構異常或計算量極大的輸入（例如一個超高解析度圖片、超長文本），導致模型在處理時消耗過多資源而崩潰或無回應。,NIST AI RMF 1.0 (Core: PROTECT 1.3),外部攻擊者,旨在癱瘓 AI 服務，使其無法為正常用戶提供服務。,"NIST SP 800-30 Rev. 1, Appendix D, Table D-2",缺乏對輸入數據的格式與資源限制,系統在接收輸入時，未能對數據的大小、格式、維度或預期處理時間進行有效的驗證與限制。,"NIST AI RMF 1.0, PROTECT 1.3",6.3 AI 系統資訊,可靠性,導致 AI 服務中斷，影響業務連續性，對依賴該服務的用戶或下游系統造成衝擊。,Clause 6.8.2
組織,有形資產,數據 (生產數據),回饋循環污染 (Feedback Loop Poisoning),對於會根據用戶互動進行線上學習或定期再訓練的模型，攻擊者刻意提供誤導性的回饋（如將正常內容標為有害），以逐步污染模型，使其行為偏離預期。,MITRE ATLAS: AML.T0040,惡意的模型使用者 / 組織犯罪,有組織地操控用戶回饋機制，旨在降低模型的可用性或使其產生有利於攻擊者的特定偏見。,"NIST SP 800-30 Rev. 1, Appendix D, Table D-2",對用戶回饋的真實性與代表性驗證不足,系統在收集用戶回饋並用於再訓練時，缺乏有效的機制來識別異常或有組織的操控行為，將其過濾。,"NIST AI RMF 1.0, MANAGE 2.2",6.4 資料與知識,可靠性 / 公平性,模型性能隨時間推移而下降，或對特定主題/群體產生新的偏見，破壞了系統的長期穩定性與公正性。,Clause 6.8.2.3
組織,有形資產,數據 (生產數據),上游數據源品質下降 (Upstream Data Quality Degradation),AI 系統所依賴的上游數據源（如第三方 API、IoT 感測器）因故障、變更或維護不善，開始提供不準確、不完整或格式錯誤的數據。,NIST AI RMF 1.0 (Core: GOVERN 1.2),外部數據提供商 / 系統元件,數據源的提供者或負責維護的團隊，因流程或技術問題導致數據品質下降。,"NIST SP 800-30 Rev. 1, Appendix D, Table D-3",缺乏對外部數據源的持續監控與驗證,系統未能建立監控機制，對來自外部數據源的數據品質、延遲和可用性進行持續的健康檢查。,"NIST AI RMF 1.0, GOVERN 1.2",6.4 資料與知識,可靠性,模型收到大量「垃圾輸入」，導致其輸出結果不可靠，進而影響基於這些結果的業務決策。,Clause 6.8.2
組織,有形資產,數據 (生產數據),不公平的即時決策 (Unfair Real-time Decision Making),即使模型在測試集上表現公平，但在生產環境中，因數據分布的變化或與系統其他部分的互動，模型對特定受保護群體做出了不成比例的負面決策。,NIST AI RMF 1.0 (Core: MANAGE 4),系統設計師 / 模型本身,模型的決策過程與現實世界的複雜互動產生了預期之外的歧視性後果。,"NIST SP 800-30 Rev. 1, Appendix D, Table D-3",缺乏對生產環境中公平性指標的監控,部署後，未能持續監控模型的決策結果在不同群體間的分布，無法及時發現並糾正新出現的偏見。,"NIST AI RMF 1.0, MANAGE 4",6.5 演算法與模型資訊,公平性,對特定群體的用戶造成實際傷害（如更高的保費、更少的機會），引發用戶投訴、法律訴訟與品牌聲譽受損。,Clause 6.8.2.3
組織,有形資產,數據 (生產數據),未經授權的二次使用 (Unauthorized Secondary Use),為了特定目的（如完成一次交易）而收集的生產數據，在未經用戶明確同意的情況下，被用於其他目的（如訓練新模型、用戶畫像分析）。,NIST AI RMF 1.0 (Core: GOVERN 1.1),內部開發/行銷團隊,團隊為了業務目標，使用了超出原始授權範圍的生產數據。,"NIST SP 800-30 Rev. 1, Appendix D, Table D-3",數據治理與目的限制原則執行不力,組織內部缺乏強而有力的數據治理策略和技術控制，以確保數據的使用嚴格遵守其收集時的目的。,"NIST AI RMF 1.0, GOVERN 1.1",6.4 資料與知識,責任制 / 安全性與隱私,違反數據保護法規（如 GDPR 的目的限制原則），侵犯用戶隱私，可能導致監管機構的重罰和用戶信任的喪失。,Clause 6.3.4
組織,有形資產,AI 模型 (演算法),模型竊取 (Model Theft),"未經授權的第三方直接竊取儲存的模型檔案（如 .pth, .onnx, .h5 檔案），獲得組織的核心智慧財產。",MITRE ATLAS: AML.T0015,敵對的內部人員 / 外部攻擊者,離職員工拷貝模型檔案；或駭客入侵模型庫、伺服器或 CI/CD 流程，直接下載模型檔案。,"NIST SP 800-30 Rev. 1, Appendix D, Table D-2",模型檔案的存取控制與加密不足,儲存模型檔案的系統（如雲端儲存、模型註冊中心）缺乏嚴格的存取權限控制，且模型檔案本身未進行加密。,"NIST AI RMF 1.0, GOVERN 2",6.5 演算法與模型資訊,安全性與隱私,組織喪失核心的技術與商業競爭優勢。攻擊者還可能對竊取的模型進行分析，找出可用於攻擊生產系統的漏洞。,Clause 6.8.2.1
組織,有形資產,AI 模型 (演算法),模型萃取 (Model Extraction),攻擊者透過重複查詢模型的 API 並觀察其輸入與輸出，訓練出一個功能與原始模型高度相似的替代模型，間接竊取了模型的智慧財產。,MITRE ATLAS: AML.T0017,競爭對手 / 外部研究員,透過合法的 API 存取權限，進行大規模、系統性的查詢，以收集足夠的數據來複製一個功能相近的模型。,"NIST SP 800-30 Rev. 1, Appendix D, Table D-2",對 API 的監控與異常檢測不足,系統未能有效監控 API 的使用模式，無法識別出疑似模型萃取行為的異常查詢模式（如大量、邊界探測查詢）。,"NIST AI RMF 1.0, PROTECT 1.3",6.5 演算法與模型資訊,安全性與隱私,模型的智慧財產權被間接竊取，削弱了組織的市場競爭力。被萃取的模型也可能被用於發起後續攻擊。,Clause 6.8.2.1
組織,有形資產,AI 模型 (演算法),模型逆向工程 (Model Inversion),攻擊者分析模型的輸出，反向重建出模型在訓練過程中學習到的敏感資訊或具有代表性的訓練樣本。,MITRE ATLAS: AML.T0012,好奇的內部人員 / 惡意的模型使用者,攻擊者透過模型的輸出（例如，臉部辨識系統生成的平均臉孔特徵），試圖還原出訓練集中的個人臉部圖像。,"NIST SP 800-30 Rev. 1, Appendix D, Table D-2",模型對訓練數據的過度記憶 (Over-memorization),模型在訓練時記憶了特定樣本的細節而非泛化特徵，導致這些敏感細節可以從其輸出中被反推出來。,"NIST AI RMF 1.0, MEASURE 1.2",6.5 演算法與模型資訊,安全性與隱私,洩漏了用於訓練模型的敏感個人數據（如人臉、醫療影像），即使攻擊者無法存取原始訓練集。,Clause 6.5.4 (j)
組織,有形資產,AI 模型 (演算法),模型後門的觸發 (Triggering of Model Backdoor),模型因先前遭受訓練資料污染而已被植入後門。在生產環境中，攻擊者提交一個帶有特定觸發器 (Trigger) 的輸入，激活該後門，使模型產生攻擊者預設的惡意輸出。,MITRE ATLAS: AML.T0020,外部攻擊者,預先知道後門觸發條件的攻擊者，在生產環境中提交特定輸入，以利用該漏洞。,"NIST SP 800-30 Rev. 1, Appendix D, Table D-2",缺乏對模型行為的異常檢測,系統未能對模型的預測結果、置信度分數等進行監控，無法偵測到因後門被觸發而產生的異常輸出行為。,"NIST AI RMF 1.0, MANAGE 3",6.5 演算法與模型資訊,可靠性 / 安全性與隱私,模型在特定情況下完全受攻擊者操控，可能導致系統做出錯誤的關鍵決策、洩漏機密資訊或執行惡意指令。,Clause 6.8.2.2
組織,有形資產,AI 模型 (演算法),缺乏可解釋性 (Lack of Explainability),模型的內部決策邏輯是一個「黑盒子」，無法向用戶、監管機構或內部人員提供其做出特定預測的合理解釋。,NIST AI RMF 1.0 (Core: GOVERN 4.1),開發團隊 / 系統架構師,在選擇模型架構時，僅追求最高的預測準確率，而忽略了模型的可解釋性需求，尤其是在高風險的應用場景中。,"NIST SP 800-30 Rev. 1, Appendix D, Table D-3",未能在模型開發中整合可解釋性技術,在模型開發生命週期中，未能導入 LIME、SHAP 等可解釋性分析工具，也未能建立向利害關係人解釋模型決策的流程。,"NIST AI RMF 1.0, GOVERN 4.1",6.5 演算法與模型資訊,透明度與可解釋性 / 責任制,當模型做出錯誤或具爭議性的決策時，組織無法解釋原因，難以進行除錯、改進或釐清責任，也無法滿足法規的透明度要求。,Clause 6.3.4
組織,有形資產,AI 模型 (演算法),演算法偏見放大 (Algorithmic Bias Amplification),模型在學習過程中，不僅複製了訓練數據中存在的社會偏見，甚至將其放大，導致其輸出結果比原始數據更加歧視特定群體。,NIST AI RMF 1.0 (Core: MAP 2.2),模型本身 / 開發團隊,模型演算法的內在特性（如目標函數的設計）導致其傾向於放大數據中的主流模式，而忽略或懲罰少數群體模式。,"NIST SP 800-30 Rev. 1, Appendix D, Table D-3",缺乏對演算法偏見的量化評估與緩解,在模型選型和開發過程中，未能使用專門的工具來評估和比較不同演算法放大偏見的風險，也未採用偏見緩解技術。,"NIST AI RMF 1.0, MAP 2.2",6.5 演算法與模型資訊,公平性,產生系統性的歧視，對受影響群體造成更嚴重的負面影響，並使組織面臨更大的法律與聲譽風險。,Clause 6.8.2.3
組織,有形資產,AI 模型 (演算法),供應鏈攻擊 (Supply Chain Attack),組織使用了從第三方（如開源社群、模型市集）獲取的預訓練模型、函式庫或容器，而這些元件已被植入惡意程式碼、後門或漏洞。,MITRE ATLAS: AML.T0060,國家級行為者 / 組織犯罪,攻擊者污染流行的開源 AI 套件或模型，以對大量下游用戶發起大規模攻擊。,"NIST SP 800-30 Rev. 1, Appendix D, Table D-2",缺乏對第三方 AI 元件的安全審查,在將第三方模型或函式庫整合到自身系統前，未能進行充分的安全掃描、程式碼審計或來源驗證。,"NIST AI RMF 1.0, GOVERN 2.2",6.3 AI 系統資訊,安全性與隱私,惡意程式碼可能竊取組織的敏感數據、癱瘓系統，或將模型本身變成攻擊其他系統的武器。,Clause 6.8.2.2
組織,有形資產,AI 模型 (演算法),非預期的「捷徑學習」 (Shortcut Learning),模型學習到了數據中一個與真實因果關係無關的虛假相關性來做出預測（走捷徑），導致其在面對略有不同的新數據時完全失效。,NIST AI RMF 1.0 (Core: MEASURE 2.3),模型本身 / 數據策展團隊,訓練數據中存在一些非本質的、偶然的特徵，而模型錯誤地將其當作關鍵預測信號。,"NIST SP 800-30 Rev. 1, Appendix D, Table D-3",對模型的泛化能力與因果理解驗證不足,模型的評估過於依賴單一的測試集，未能透過更具挑戰性的壓力測試（如對抗性驗證）來檢測模型是否學到了真正的規律。,"NIST AI R-MF 1.0, MEASURE 2.3",6.5 演算法與模型資訊,可靠性 / 透明度與可解釋性,模型看似準確但極其脆弱，在關鍵時刻會因微小變化而做出荒謬的錯誤判斷，且其決策邏輯難以被解釋和信任。,Clause 6.8.2
組織,有形資產,AI 模型 (演算法),模型設定錯誤 (Model Misconfiguration),在部署模型時，相關的超參數、API 端點安全設定、資源分配等配置出現錯誤，導致模型性能不佳或產生安全漏洞。,NIST AI RMF 1.0 (Core: GOVERN 3.1),維運團隊 (Operations Team),負責部署的工程師因疏忽或對模型理解不足，在生產環境中套用了錯誤的配置文件。,"NIST SP 800-30 Rev. 1, Appendix D, Table D-3",缺乏標準化與自動化的部署流程 (IaC/MLOps),未能將模型部署的相關配置以程式碼的形式進行管理和審查，部署過程依賴大量手動操作，容易出錯。,"NIST AI RMF 1.0, GOVERN 3.1",6.3 AI 系統資訊,可靠性 / 安全性與隱私,錯誤的配置可能導致模型性能遠低於預期，或使 API 端點暴露於風險之中，允許未經授權的存取。,Clause 6.8.2.1
組織,有形資產,AI 模型 (演算法),缺乏可申訴性與補救機制 (Lack of Contestability and Redress),當模型做出對個人有重大影響的決策（如拒絕貸款）時，缺乏一個清晰、有效的流程，讓受影響者可以對此決策提出質疑、要求解釋並尋求補救。,NIST AI RMF 1.0 (Core: GOVERN 5.2),法律/合規/產品團隊,組織在設計 AI 系統時，僅關注技術實現，而忽略了為用戶提供程序正義和權利救濟的配套機制。,"NIST SP 800-30 Rev. 1, Appendix D, Table D-3",未能將 AI 治理與用戶權利流程相結合,組織的 AI 風險管理框架未能與客戶服務、法務和用戶權利響應流程進行有效整合。,"NIST AI RMF 1.0, GOVERN 5.2",6.5 演算法與模型資訊,責任制 / 公平性,剝奪了用戶的程序權利，可能違反相關法規（如 GDPR 中的自動化決策權利），並嚴重損害用戶對組織的信任。,Clause 6.3.4
組織,有形資產,AI 模型 (架構),架構設計不當 (Inappropriate Architecture Design),開發團隊選擇了一個對於目標任務而言過於複雜或過於簡單的模型架構，導致模型無法達到預期的性能或效率。,NIST AI RMF 1.0 (Core: MAP 1.2),開發團隊 / AI 架構師,團隊可能因經驗不足、追求新潮技術或對業務問題理解不深，而選擇了不合適的模型架構。,"NIST SP 800-30 Rev. 1, Appendix D, Table D-3",缺乏系統性的模型選型與評估流程,組織未能建立一個標準化的流程，根據任務需求、數據特性、資源限制等多維度來評估和選擇最合適的模型架構。,"NIST AI RMF 1.0, MAP 1.2",6.5 演算法與模型資訊,可靠性,模型可能出現過擬合（過於複雜）或欠擬合（過於簡單）的問題，導致其泛化能力差，在真實世界中無法穩定地執行任務。,Clause 6.8.2
組織,有形資產,AI 模型 (架構),架構的智慧財產權竊取 (Intellectual Property Theft of Architecture),競爭對手或惡意內部人員透過逆向工程、間諜活動或分析公開的論文/產品，竊取了組織精心設計的專有模型架構。,NIST AI RMF 1.0 (Core: PROTECT 1.2),競爭對手 / 敵對的內部人員,旨在獲取組織的核心技術資產，以縮短研發時間，或複製其產品的關鍵功能。,"NIST SP 800-30 Rev. 1, Appendix D, Table D-2",缺乏對模型架構的商業機密保護措施,對於描述模型架構的設計文件、程式碼和內部知識庫，未能實施嚴格的存取控制和保密協議。,"NIST AI RMF 1.0, PROTECT 1.2",6.5 演算法與模型資訊,安全性與隱私,組織喪失了透過獨特模型架構所建立的市場競爭優勢和技術壁壘，造成長期的商業損失。,Clause 6.8.2.1
組織,有形資產,AI 模型 (架構),架構本身的脆弱性 (Inherent Architectural Vulnerabilities),某些模型架構天生就對特定類型的攻擊（如對抗性攻擊）更為脆弱，而開發團隊在選型時未充分考慮到這一點。,MITRE ATLAS: AML.T0030,外部攻擊者,利用模型架構的內在數學特性，以極低的成本生成能成功欺騙模型的對抗性樣本。,"NIST SP 800-30 Rev. 1, Appendix D, Table D-2",對模型架構的安全性評估不足,在模型選型階段，未能對不同架構的對抗性穩健性、隱私保護能力等安全屬性進行充分的評估和比較。,"NIST AI RMF 1.0, MEASURE 2.3",6.5 演算法與模型資訊,安全性與隱私,即使模型訓練得很好，其底層架構的脆弱性也使其容易受到攻擊，導致安全防護被輕易繞過。,Clause 6.8.2.2
組織,有形資產,AI 模型 (架構),缺乏可解釋性的架構 (Unexplainable Architecture),選擇了如深度神經網路等高度複雜的「黑盒子」架構，使其決策過程難以被人類理解和審查。,NIST AI RMF 1.0 (Core: GOVERN 4.1),開發團隊 / AI 架構師,在高風險決策場景中，僅為了追求性能而犧牲了架構的可解釋性。,"NIST SP 800-30 Rev. 1, Appendix D, Table D-3",未能根據風險等級匹配可解釋性需求,組織未能根據 AI 應用的風險等級，來要求模型架構必須達到對應的可解釋性水平。,"NIST AI RMF 1.0, GOVERN 4.1",6.5 演算法與模型資訊,透明度與可解釋性 / 責任制,當模型做出錯誤或歧視性決策時，組織無法解釋原因，難以除錯、釐清責任，也無法滿足監管要求。,Clause 6.3.4
組織,有形資產,AI 模型 (架構),架構與硬體的失配 (Architecture-Hardware Mismatch),設計或選擇的模型架構無法在目標硬體上高效運行，或需要遠超出預算的硬體資源才能達到可接受的性能。,NIST AI RMF 1.0 (Core: MAP 1.3),開發團隊 / AI 架構師,在設計架構時，脫離了現實的部署環境和硬體限制，導致模型難以落地。,"NIST SP 800-30 Rev. 1, Appendix D, Table D-3",缺乏軟硬體協同設計與評估,在 AI 系統的設計初期，未能將模型架構的選擇與硬體基礎設施的規劃進行通盤考慮和評估。,"NIST AI RMF 1.0, MAP 1.3",6.3 AI 系統資訊,可靠性,導致模型推論延遲過高、處理能力不足或營運成本過高，無法滿足業務需求，使得整個專案失敗。,Clause 6.8.2
組織,有形資產,AI 模型 (架構),架構的技術債 (Technical Debt in Architecture),為了快速驗證概念，團隊選擇了一個臨時性或過於客製化的架構，導致後續的維護、擴展和重現變得極其困難。,NIST AI RMF 1.0 (Core: GOVERN 3),開發團隊,在專案初期，為了追求速度而犧牲了架構的標準化、模組化和文件化。,"NIST SP 800-30 Rev. 1, Appendix D, Table D-3",缺乏長期的架構演進與生命週期規劃,組織對 AI 模型的開發仍停留在專案制，缺乏從產品角度對其架構進行長期規劃與重構的機制。,"NIST AI RMF 1.0, GOVERN 3",6.5 演算法與模型資訊,可靠性 / 責任制,使得模型的迭代更新變得緩慢且容易出錯，也讓新成員難以理解和接手，增加了系統的脆弱性。,Clause 6.3.4
組織,有形資產,AI 模型 (架構),第三方架構的授權風險 (Licensing Risks of Third-party Architectures),使用了來自開源社群或第三方供應商的模型架構，但其授權條款（License）與組織的商業模式不相容（如 GPL 授權）。,NIST AI RMF 1.0 (Core: GOVERN 2.2),開發團隊 / 法務團隊,開發人員在引用開源架構時，未能仔細審查其授權條款；或法務團隊缺乏對 AI 特定授權的理解。,"NIST SP 800-30 Rev. 1, Appendix D, Table D-3",缺乏對開源與第三方元件的授權審查流程,組織未能建立一個強制性的流程，在引入任何外部程式碼或架構前，對其授權的合規性進行審查。,"NIST AI RMF 1.0, GOVERN 2.2",6.5 演算法與模型資訊,責任制,可能導致法律糾紛，組織被迫公開其專有程式碼，或支付高額的授權費用，嚴重影響商業利益。,Clause 6.3.4
組織,有形資產,AI 模型 (架構),過度擬合於特定數據的架構 (Architecture Overfitted to Specific Data),模型架構的設計過度依賴於初始訓練數據的特性，導致其對於新數據源或新場景的適應性極差，難以遷移或擴展。,NIST AI RMF 1.0 (Core: MEASURE 2.2),開發團隊,團隊在設計架構時，未能考慮到未來的擴展性需求，使其與特定數據集「綁死」。,"NIST SP 800-30 Rev. 1, Appendix D, Table D-3",對架構的泛化與遷移能力評估不足,在評估架構時，僅關注其在單一任務上的表現，而未能測試其在不同但相關的任務或數據集上的表現。,"NIST AI RMF 1.0, MEASURE 2.2",6.5 演算法與模型資訊,可靠性,當業務需要擴展或數據環境發生變化時，需要完全重新設計和訓練模型，大大增加了維護成本和時間。,Clause 6.8.2
組織,有形資產,AI 模型 (架構),架構文檔不全或過時 (Incomplete or Outdated Architecture Documentation),描述模型架構的設計理念、結構、接口和依賴關係的文檔缺失、不準確或未能與實際的程式碼同步更新。,NIST AI RMF 1.0 (Core: GOVERN 3.3),開發團隊,團隊在快速迭代的過程中，忽略了同步更新文檔的重要性。,"NIST SP 800-30 Rev. 1, Appendix D, Table D-3",缺乏強制性的文檔規範與審查機制,組織的開發流程中，沒有將撰寫和更新技術文檔作為一個必要的、可審查的環節。,"NIST AI RMF 1.0, GOVERN 3.3",6.5 演算法與模型資訊,透明度與可解釋性 / 責任制,使得模型的審計、交接、除錯和風險評估變得極其困難，也無法向監管機構證明其設計的合規性。,Clause 6.3.4
組織,有形資產,AI 模型 (架構),架構對公平性的影響 (Impact of Architecture on Fairness),某些架構（如注意力機制）可能會不經意地將焦點過度集中在數據中的某些敏感屬性上，從而放大偏見。,NIST AI RMF 1.0 (Core: MAP 2.2),AI 架構師 / 模型本身,模型架構的內在機制使其在學習過程中，更容易捕捉並強化數據中的偏見模式。,"NIST SP 800-30 Rev. 1, Appendix D, Table D-3",未能在架構設計中考慮公平性原則,在設計和選擇架構時，未能分析其潛在的偏見放大效應，也未能引入旨在提升公平性的架構設計。,"NIST AI RMF 1.0, MAP 2.2",6.5 演算法與模型資訊,公平性,即使使用相對公平的數據進行訓練，架構本身也可能成為產生歧視性結果的根源。,Clause 6.8.2.3
組織,有形資產,AI 模型 (權重),權重檔案竊取 (Model Weights Theft),未經授權的第三方直接竊取儲存的模型權重檔案，獲得了模型的核心智慧財產。,MITRE ATLAS: AML.T0015,敵對的內部人員 / 外部攻擊者,離職員工拷貝權重檔案；或駭客入侵模型庫、伺服器或 CI/CD 流程，直接下載檔案。,"NIST SP 800-30 Rev. 1, Appendix D, Table D-2",模型權重檔案的存取控制與加密不足,儲存權重檔案的系統缺乏嚴格的存取權限控制，且檔案本身未進行加密或數位簽章。,"NIST AI RMF 1.0, GOVERN 2",6.5 演算法與模型資訊,安全性與隱私,組織喪失核心的技術與商業競爭優勢。攻擊者還可能對竊取的權重進行分析，找出可用於攻擊生產系統的漏洞。,Clause 6.8.2.1
組織,有形資產,AI 模型 (權重),權重檔案篡改/植入後門 (Model Weights Tampering/Backdooring),攻擊者在模型權重檔案分發或部署的過程中，對其進行惡意修改，植入不易察覺的後門或破壞其性能。,MITRE ATLAS: AML.T0060,供應鏈攻擊者 / 惡意內部人員,在 CI/CD 流程中，或透過入侵模型庫，用惡意版本替換掉正常的權重檔案。,"NIST SP 800-30 Rev. 1, Appendix D, Table D-2",缺乏對模型權重檔案的完整性校驗,在載入模型權重進行推論前，未能使用雜湊值 (Hash) 或數位簽章來驗證其是否來自可信來源且未被竄改。,"NIST AI RMF 1.0, PROTECT 1.2",6.5 演算法與模型資訊,可靠性 / 安全性與隱私,導致部署在生產環境中的模型存在後門或性能缺陷，對系統的穩定性與安全性構成嚴重威脅。,Clause 6.8.2.2
組織,有形資產,AI 模型 (權重),從權重中逆向工程訓練數據 (Reversing Training Data from Weights),攻擊者透過分析模型權重的數值，反向推斷或重建出部分用於訓練的敏感數據。,MITRE ATLAS: AML.T0012,外部研究員 / 競爭對手,旨在竊取有價值的訓練數據，或揭露模型訓練過程中使用的個人隱私資訊。,"NIST SP 800-30 Rev. 1, Appendix D, Table D-2",模型對訓練數據的過度記憶 (Over-memorization),模型在訓練時記憶了特定樣本的細節而非泛化特徵，這些敏感細節被「編碼」到了權重中。,"NIST AI RMF 1.0, MEASURE 1.2",6.5 演算法與模型資訊,安全性與隱私,即使原始訓練數據已被刪除，其包含的敏感資訊（如個資、商業機密）仍可能透過權重檔案洩漏。,Clause 6.5.4 (j)
組織,有形資產,AI 模型 (權重),權重中固化的偏見 (Biases Embedded in Weights),訓練數據中存在的社會偏見、歧視性模式已被模型學習並固化在其權重參數中。,NIST AI RMF 1.0 (Core: MAP 2.2),歷史數據 / 社會本身,歷史數據中反映出的真實世界偏見，被模型無差別地學習並儲存在權重裡。,"NIST SP 800-30 Rev. 1, Appendix D, Table D-3",缺乏對模型權重與決策的偏見審計,在模型訓練完成後，未能使用專門的工具和技術來檢測其權重是否對特定敏感屬性有異常高的依賴，或其決策是否存在偏見。,"NIST AI RMF 1.0, MEASURE 1.1",6.5 演算法與模型資訊,公平性,模型權重成為系統性歧視的載體，即使更換了輸入數據，其內在的偏見依然會導致不公平的決策。,Clause 6.8.2.3
組織,有形資產,AI 模型 (權重),權重檔案的意外洩漏 (Accidental Leakage of Model Weights),開發人員在分享程式碼（如上傳到 GitHub）、日誌或進行技術交流時，不慎將包含模型權重檔案的連結或檔案本身公開。,NIST AI RMF 1.0 (Core: GOVERN 2.1),疏忽的內部人員 (Negligent Insider),開發人員缺乏安全意識，在公開的平台上分享了包含敏感資產的專案檔案。,"NIST SP 800-30 Rev. 1, Appendix D, Table D-3",缺乏對敏感資產外洩的監控與預防機制,未能部署數據外洩防護 (DLP) 工具，也缺乏對員工在公開平台活動的安全審查與教育訓練。,"NIST AI RMF 1.0, GOVERN 2.1",6.5 演算法與模型資訊,安全性與隱私,導致組織最核心的智慧財產被輕易獲取，其後果等同於模型竊取。,Clause 6.8.2.1
組織,有形資產,AI 模型 (權重),權重的可轉移性攻擊 (Transferability Attack),攻擊者利用一個竊取或複製的模型權重，製作出能成功攻擊生產環境中原始模型的對抗性樣本。,MITRE ATLAS: AML.T0030,外部攻擊者,攻擊者在本地分析竊取的權重，找出其脆弱性，並利用此脆弱性攻擊遠端的、更高價值的生產系統。,"NIST SP 800-30 Rev. 1, Appendix D, Table D-2",未能考慮到黑箱攻擊場景,組織的防禦策略僅考慮了白箱攻擊（攻擊者了解模型內部），而忽略了基於權重可轉移性的黑箱攻擊威脅。,"NIST AI RMF 1.0, PROTECT 1.3",6.5 演算法與模型資訊,安全性與隱私,即使攻擊者無法直接存取生產模型，權重的洩漏也為他們提供了發動有效攻擊的「離線訓練場」。,Clause 6.8.2.2
組織,有形資產,AI 模型 (權重),過時的權重 (Outdated Weights),生產環境中運行的模型權重是較舊的版本，未能反映最新的數據模式、業務邏輯或安全補丁。,NIST AI RMF 1.0 (Core: MANAGE 2.2),維運團隊 / MLOps 流程,模型的再訓練與部署流程中斷或延遲，導致生產環境中的權重未能及時更新。,"NIST SP 800-30 Rev. 1, Appendix D, Table D-3",缺乏自動化的模型更新與版本管理流程,未能建立一個自動化的 MLOps 流程，來確保一旦有性能更好或更安全的新權重版本通過測試，就能被及時部署到生產環境。,"NIST AI RMF 1.0, MANAGE 2.2",6.5 演算法與模型資訊,可靠性,模型的性能因無法適應數據漂移而下降，或因未能包含最新的安全修正而存在已知漏洞。,Clause 6.8.2
組織,有形資產,AI 模型 (權重),權重檔案與軟體環境的依賴衝突 (Dependency Conflict with Weights),新版本的模型權重，依賴於特定版本的軟體函式庫才能正確載入和運行，而生產環境的軟體版本與之不相容。,NIST AI RMF 1.0 (Core: GOVERN 3.1),開發與維運團隊 (Dev & Ops Teams),訓練與部署環境之間缺乏一致性管理，導致權重與其運行時的軟體依賴產生脫鉤。,"NIST SP 800-30 Rev. 1, Appendix D, Table D-3",缺乏將權重與其依賴項打包的機制,未能使用容器化（如 Docker）或虛擬環境等技術，將特定版本的權重與其所需的軟體依賴打包在一起進行版本控制和部署。,"NIST AI RMF 1.0, GOVERN 3.1",6.3 AI 系統資訊,可靠性,導致模型部署失敗，或在運行時因底層函式庫的計算差異而產生無法預期的錯誤結果。,Clause 6.8.2
組織,有形資產,AI 模型 (權重),無法追溯權重的訓練來源 (Untraceable Weights Provenance),對於生產環境中運行的模型權重，無法清晰地追溯到它是用哪一版程式碼、哪一個數據集、在什麼配置下訓練出來的。,NIST AI RMF 1.0 (Core: GOVERN 3.3),開發團隊 / MLOps 流程,實驗和訓練過程缺乏系統性的紀錄，未能將每次訓練產出的權重與其完整的上下文（數據、程式碼、參數）進行關聯。,"NIST SP 800-30 Rev. 1, Appendix D, Table D-3",缺乏實驗追蹤與模型註冊的工具與實踐,未能使用如 MLflow 等工具來自動記錄訓練過程的元數據，並將訓練好的權重註冊到一個中央化的模型庫中進行管理。,"NIST AI RMF 1.0, GOVERN 3.3",6.5 演算法與模型資訊,透明度與可解釋性 / 責任制,當模型權重出現問題時（如性能衰退、有偏見），無法回溯其根源，也無法精確地重現當時的訓練過程以進行除錯或審計。,Clause 6.3.4
組織,有形資產,AI 模型 (權重),權重中的有害知識 (Harmful Knowledge in Weights),對於在海量網際網路數據上預訓練的大型模型，其權重中可能記憶並固化了有害、不實或有毒的資訊。,NIST AI RMF 1.0 (Core: MAP 2.1),預訓練數據的提供者,用於預訓練的通用數據集中，不可避免地包含了來自網路的各種有害內容。,"NIST SP 800-30 Rev. 1, Appendix D, Table D-3",對預訓練模型的內容與行為審核不足,在使用第三方預訓練模型的權重進行微調前，未能對其潛在的有害知識進行充分的評估和「對齊」(Alignment)。,"NIST AI RMF 1.0, MAP 2.1",6.5 演算法與模型資訊,公平性 / 安全性與隱私,模型在特定提示下，可能會生成有害、歧視性或虛假的內容，對用戶造成傷害，並給組織帶來嚴重的聲譽風險。,Clause 6.8.2.3
組織,有形資產,AI 系統 (硬體基礎設施),硬體故障 (Hardware Failure),用於 AI 模型訓練或推論的關鍵硬體元件（如 GPU、CPU、記憶體、硬碟）發生故障，導致服務中斷。,NIST SP 800-30 Rev. 1,環境因素 / 系統元件,硬體老化、電力不穩、散熱不良或元件本身存在製造缺陷。,"NIST SP 800-30 Rev. 1, Appendix D, Table D-4",缺乏硬體冗餘與容錯機制,關鍵的 AI 運算節點為單點部署，沒有備援或自動故障轉移機制。,"NIST AI RMF 1.0, PROTECT 2",6.2 硬體,可靠性,長時間的訓練任務被迫中斷，造成巨大成本浪費；線上的推論服務不可用，直接影響業務運營。,Clause 6.8.2
組織,有形資產,AI 系統 (硬體基礎設施),硬體供應鏈攻擊 (Hardware Supply Chain Attack),組織採購的硬體（如伺服器、網路卡）在出廠前或運輸過程中，已被植入惡意的硬體後門或韌體。,NIST AI RMF 1.0 (Core: GOVERN 2.2),國家級行為者 / 組織犯罪,旨在對特定目標進行長期的、難以被偵測的監控或滲透。,"NIST SP 800-30 Rev. 1, Appendix D, Table D-2",缺乏對硬體供應鏈的安全審查與驗證,在採購關鍵硬體設備時，未能對供應商的安全實踐進行審查，也缺乏對到貨設備進行韌體層級檢測的能力。,"NIST AI RMF 1.0, GOVERN 2.2",6.2 硬體,安全性與隱私,攻擊者可以繞過所有軟體層的安全防護，直接在硬體層級竊取敏感數據、篡改運算結果或控制整個系統。,Clause 6.8.2.1
組織,有形資產,AI 系統 (硬體基礎設施),物理存取與破壞 (Unauthorized Physical Access and Sabotage),未經授權的人員進入存放 AI 伺服器的機房，進行竊取、破壞或安裝惡意設備（如 USB 裝置）。,NIST SP 800-30 Rev. 1,敵對的內部人員 / 外部入侵者,旨在竊取硬體資產、破壞服務可用性或植入實體層的監控工具。,"NIST SP 800-30 Rev. 1, Appendix D, Table D-2",數據中心的物理安全防護不足,機房缺乏嚴格的門禁管制、監視錄影、環境監控等物理安全措施。,"NIST AI RMF 1.0, PROTECT 2",6.2 硬體,安全性與隱私 / 可靠性,導致硬體資產損失、服務中斷，以及最敏感的數據（如模型權重、金鑰）在物理層級被直接竊取。,Clause 6.8.2.1
組織,有形資產,AI 系統 (硬體基礎設施),運算資源不足 (Insufficient Computing Resources),硬體基礎設施的運算能力（如 GPU 數量、記憶體大小）無法滿足模型訓練或大規模推論的需求，成為系統效能瓶頸。,NIST AI RMF 1.0 (Core: MAP 1.3),系統架構師 / 規劃團隊,在規劃階段，低估了 AI 模型對運算資源的實際需求，或未能預見業務增長帶來的負載壓力。,"NIST SP 800-30 Rev. 1, Appendix D, Table D-3",缺乏充分的容量規劃與壓力測試,在系統上線前，未能進行充分的壓力測試來評估硬體在不同負載下的性能表現，也缺乏長期的容量規劃。,"NIST AI RMF 1.0, MAP 1.3",6.2 硬體,可靠性,導致模型訓練時間過長，無法快速迭代；或線上服務的反應時間過長、無法處理高併發請求，嚴重影響用戶體驗。,Clause 6.8.2
組織,有形資產,AI 系統 (硬體基礎設施),網路基礎設施瓶頸 (Network Infrastructure Bottleneck),在分散式訓練或大規模推論場景中，節點之間的網路頻寬或延遲成為瓶頸，限制了整個 AI 叢集的整體性能。,NIST AI RMF 1.0 (Core: MAP 1.3),網路架構師,未能為 AI 特有的高頻寬、低延遲的數據交換需求，設計專門的網路架構（如 InfiniBand）。,"NIST SP 800-30 Rev. 1, Appendix D, Table D-3",對 AI 工作負載的網路需求分析不足,在設計網路基礎設施時，沿用了傳統的 IT 網路標準，未能充分考慮到 AI 運算中大量的數據傳輸需求。,"NIST AI RMF 1.0, MAP 1.3",6.2 硬體,可靠性,即使單個 GPU 的運算能力很強，也會因網路等待而長期處於閒置狀態，大大降低了整個昂貴硬體叢集的利用率和效率。,Clause 6.8.2
組織,有形資產,AI 系統 (硬體基礎設施),硬體驅動程式與韌體漏洞 (Vulnerabilities in Drivers and Firmware),運行 GPU 等加速器所需的底層驅動程式或硬體韌體本身存在安全漏洞，可能被攻擊者利用。,NIST SP 800-30 Rev. 1,外部攻擊者,利用已公開或 0-day 的驅動程式漏洞，獲得系統的核心權限或執行任意程式碼。,"NIST SP 800-30 Rev. 1, Appendix D, Table D-2",缺乏對驅動與韌體的漏洞管理與更新機制,組織未能將硬體驅動程式和韌體納入常規的漏洞掃描和補丁管理流程中。,"NIST AI RMF 1.0, PROTECT 1.2",6.2 硬體,安全性與隱私,攻擊者可利用此類漏洞繞過作業系統層級的安全控制，直接攻擊系統底層，其危害性極高。,Clause 6.8.2.2
組織,有形資產,AI 系統 (硬體基礎設施),邊信道攻擊 (Side-Channel Attack),攻擊者透過監控硬體在運算時產生的物理信號（如功耗、電磁輻射、快取存取模式），來推斷正在處理的敏感數據或模型的內部資訊。,NIST AI RMF 1.0 (Core: PROTECT 1.1),外部攻擊者 (具備近距離物理存取能力),在多租戶的雲環境中，一個租戶可能透過邊信道攻擊，竊取在同一物理伺服器上運行的另一個租戶的 AI 模型的資訊。,"NIST SP 800-30 Rev. 1, Appendix D, Table D-2",缺乏對多租戶環境的硬體層級隔離,在共享硬體資源的環境中，未能採用有效的硬體層級隔離技術，來防止不同租戶之間的資訊洩漏。,"NIST AI RMF 1.0, PROTECT 1.1",6.2 硬體,安全性與隱私,即使數據在記憶體中是加密的，其運算過程也可能透過物理信號洩漏模型的金鑰、權重或處理的數據內容。,Clause 6.8.2.1
組織,有形資產,AI 系統 (硬體基礎設施),硬體技術鎖定 (Hardware Vendor Lock-in),整個 AI 系統的軟體和演算法，深度依賴於特定硬體供應商的專有技術（如 NVIDIA 的 CUDA），導致難以遷移到其他平台。,NIST AI RMF 1.0 (Core: GOVERN 2.2),系統架構師 / 開發團隊,為了追求極致性能，在開發早期就全面採用了特定廠商的專有軟硬體生態，犧牲了長期的靈活性。,"NIST SP 800-30 Rev. 1, Appendix D, Table D-3",缺乏平台中立性與可移植性規劃,在技術選型時，未能優先考慮開放標準和跨平台相容的解決方案，也缺乏對供應商鎖定風險的評估。,"NIST AI RMF 1.0, GOVERN 2.2",6.2 硬體,責任制 / 可靠性,使組織在議價、供應鏈穩定性和技術路線選擇上，完全受制於單一供應商，喪失了自主性與風險抵禦能力。,Clause 6.3.4
組織,有形資產,AI 系統 (硬體基礎設施),不一致的硬體環境 (Inconsistent Hardware Environments),開發、測試和生產環境使用了不同型號、不同世代或不同配置的硬體，導致模型在不同環境下的行為不一致。,NIST AI RMF 1.0 (Core: GOVERN 3.1),維運團隊 / 採購部門,為了節省成本或因採購批次不同，導致不同環境的硬體規格存在差異。,"NIST SP 800-30 Rev. 1, Appendix D, Table D-3",缺乏對環境一致性的管理與規範,未能建立規範，要求所有環境（至少是測試與生產環境）的關鍵硬體配置必須保持一致。,"NIST AI RMF 1.0, GOVERN 3.1",6.2 硬體,可靠性,在測試環境中表現良好的模型，部署到生產環境後可能因硬體計算方式的細微差異而出現性能下降或非預期的錯誤。,Clause 6.8.2
組織,有形資產,AI 系統 (硬體基礎設施),能源消耗與環境衝擊 (Energy Consumption and Environmental Impact),大規模的 AI 訓練和推論需要消耗巨大的電力，其產生的碳足跡和對環境的影響，可能與組織的 ESG（環境、社會、治理）目標相悖。,"ISO 42005, Clause 6.8.2",系統架構師 / 組織本身,在追求模型性能時，未能充分考慮到其對能源的消耗和對環境的長期影響。,"NIST SP 800-30 Rev. 1, Appendix D, Table D-3",缺乏對 AI 系統能效的評估與優化,在設計和運營 AI 系統時，沒有將能源效率作為一個重要的評估指標，也未能採用綠色運算相關的技術和實踐。,"ISO 42005, Clause 6.8.2",6.2 硬體,責任制,可能導致高昂的運營成本，並對組織的社會責任形象和品牌聲譽造成負面影響，甚至可能面臨未來的碳排放法規風險。,Clause 6.8.2
組織,有形資產,AI 系統 (軟體平台),開源軟體漏洞 (Vulnerabilities in Open-Source Software),"AI 系統所依賴的大量開源函式庫（如 TensorFlow, PyTorch, Scikit-learn）或平台軟體（如 Kubernetes）存在已公開的安全漏洞。",NIST AI RMF 1.0 (Core: GOVERN 2.2),外部攻擊者,攻擊者利用已知的 CVE 漏洞，對未及時更新補丁的 AI 軟體平台發起攻擊。,"NIST SP 800-30 Rev. 1, Appendix D, Table D-2",缺乏軟體組成分析與漏洞管理 (SCA),未能使用工具自動掃描軟體專案所依賴的所有開源元件，並及時發現其中存在的已知漏洞。,"NIST AI RMF 1.0, GOVERN 2.2",6.3 AI 系統資訊,安全性與隱私,攻擊者可能利用漏洞執行遠端程式碼、提升權限、竊取數據或癱瘓整個 AI 服務。,Clause 6.8.2.2
組織,有形資產,AI 系統 (軟體平台),容器逃逸攻擊 (Container Escape Attack),在使用 Docker、Kubernetes 等容器化平台部署 AI 模型時，攻擊者利用容器運行時或核心的漏洞，從一個受控的容器內部「逃逸」到宿主機作業系統，獲得更高權限。,NIST SP 800-30 Rev. 1,外部攻擊者,旨在突破容器的隔離限制，以控制整個底層基礎設施。,"NIST SP 800-30 Rev. 1, Appendix D, Table D-2",容器安全設定與強化不足,容器運行時使用了過高的權限（如 root 權限）、掛載了敏感的宿主機目錄，或未及時更新容器運行時的版本。,"NIST AI RMF 1.0, PROTECT 1.2",6.3 AI 系統資訊,安全性與隱私,一旦攻擊者逃逸到宿主機，他們就可以控制在該機器上運行的所有其他 AI 服務，並可能進一步橫向移動到企業內網。,Clause 6.8.2.1
組織,有形資產,AI 系統 (軟體平台),API 端點暴露與濫用 (API Endpoint Exposure and Abuse),用於提供模型推論服務的 API 端點，因缺乏足夠的認證、授權或速率限制，而被未授權的使用者存取或被惡意濫用。,NIST AI RMF 1.0 (Core: PROTECT 1.3),外部攻擊者 / 腳本小子,旨在發起阻斷服務攻擊、進行大規模的模型萃取，或免費盜用昂貴的 AI 運算資源。,"NIST SP 800-30 Rev. 1, Appendix D, Table D-2",缺乏 API 安全閘道與監控機制,未能部署 API 閘道來統一管理所有 AI 服務的認證、授權、流量控制和日誌記錄。,"NIST AI RMF 1.0, PROTECT 1.3",6.3 AI 系統資訊,可靠性 / 安全性與隱私,導致服務不可用、模型智慧財產權被竊取、運營成本飆升，甚至可能因未授權存取而導致敏感數據外洩。,Clause 6.8.2
組織,有形資產,AI 系統 (軟體平台),MLOps 流程被破壞 (Compromise of MLOps Pipeline),"攻擊者入侵了用於自動化模型訓練、測試和部署的 CI/CD/CT 流程（如 Jenkins, GitLab CI），在其中植入惡意程式碼或篡改模型。",MITRE ATLAS: AML.T0060,供應鏈攻擊者,旨在從源頭上污染組織的 AI 模型，或竊取在流程中處理的敏感數據與憑證。,"NIST SP 800-30 Rev. 1, Appendix D, Table D-2",MLOps 流程的存取控制與憑證管理不善,CI/CD 流程中使用了長期有效的、權限過高的存取金鑰，且對流程的變更缺乏嚴格的審查和監控。,"NIST AI RMF 1.0, PROTECT 1.2",6.3 AI 系統資訊,安全性與隱私 / 可靠性,攻擊者可以在模型部署到生產環境前，神不知鬼不覺地對其進行篡改，其後果極為嚴重且難以被發現。,Clause 6.8.2.2
組織,有形資產,AI 系統 (軟體平台),日誌與監控系統配置不當 (Improper Logging and Monitoring Configuration),軟體平台的日誌紀錄不完整，或監控系統未能覆蓋關鍵的 AI 特定指標，導致在出現問題時無法進行有效的故障排除和風險審計。,NIST AI RMF 1.0 (Core: MANAGE 1),維運團隊,在部署平台時，未能根據 AI 系統的特性，規劃和配置有意義的日誌與監控指標。,"NIST SP 800-30 Rev. 1, Appendix D, Table D-3",缺乏 AI 特定的可觀測性 (Observability) 策略,未能將傳統的 IT 監控（CPU、記憶體）與 AI 特有的監控（模型預測漂移、數據分布、推論延遲）相結合。,"NIST AI RMF 1.0, MANAGE 1",6.3 AI 系統資訊,責任制 / 透明度與可解釋性,當模型出現錯誤、偏見或被攻擊時，因缺乏足夠的日誌和監控數據，而無法追溯根源、釐清責任或向監管機構提供證據。,Clause 6.3.4
組織,有形資產,AI 系統 (軟體平台),依賴地獄 (Dependency Hell),AI 專案通常依賴大量且版本敏感的軟體套件，這些套件之間可能存在版本衝突，導致環境難以重現和維護。,NIST AI RMF 1.0 (Core: GOVERN 3.1),開發團隊,開發過程中，未能鎖定所有軟體依賴的精確版本，導致在不同機器或不同時間，環境可能不一致。,"NIST SP 800-30 Rev. 1, Appendix D, Table D-3",缺乏確定性的環境管理工具,未能使用如 Poetry、Conda 或容器化等工具來創建一個可鎖定所有依賴版本、可被精確重現的運行環境。,"NIST AI RMF 1.0, GOVERN 3.1",6.3 AI 系統資訊,可靠性,導致「在我機器上可以跑」的問題，使得模型的訓練結果難以重現，也讓部署過程充滿了不確定性和風險。,Clause 6.8.2
組織,有形資產,AI 系統 (軟體平台),數據庫與資料湖的存取控制不當 (Improper Access Control for Databases/Data Lakes),存放訓練、測試或生產數據的資料庫或資料湖，其存取權限配置過於寬鬆，允許不應有權限的服務或人員存取。,NIST AI RMF 1.0 (Core: GOVERN 2.1),疏忽的內部人員 / 外部攻擊者,攻擊者利用一個低權限的應用程式漏洞，橫向移動存取了整個資料湖中的敏感數據。,"NIST SP 800-30 Rev. 1, Appendix D, Table D-2/D-3",未能實施最小權限原則,未能根據 AI 系統中不同元件的實際需求，為其配置最小化的數據存取權限。,"NIST AI RMF 1.0, GOVERN 2.1",6.4 資料與知識,安全性與隱私,導致大規模的敏感數據洩漏，包括用戶個資、商業機密等，是資料洩漏事件的主要根源之一。,Clause 6.8.2.1
組織,有形資產,AI 系統 (軟體平台),模型服務的冷啟動問題 (Cold Start Problem in Model Serving),在使用無伺服器 (Serverless) 或基於請求自動擴展的平台部署模型時，第一個請求到來時，平台需要花費較長時間來載入模型，導致極高的延遲。,NIST AI RMF 1.0 (Core: MAP 1.3),系統架構師 / 維運團隊,為了節省閒置資源成本而選擇了無伺服器架構，但未能充分考慮其對延遲敏感的 AI 應用的影響。,"NIST SP 800-30 Rev. 1, Appendix D, Table D-3",對服務等級目標 (SLO) 與平台特性評估不足,在選擇部署平台時，未能將模型的延遲要求與平台的啟動時間特性進行匹配和測試。,"NIST AI RMF 1.0, MAP 1.3",6.3 AI 系統資訊,可靠性,對於需要即時反應的 AI 應用（如即時推薦、欺詐檢測），首次請求的超長延遲會嚴重破壞用戶體驗，甚至導致業務失敗。,Clause 6.8.2
組織,有形資產,AI 系統 (軟體平台),不一致的數據預處理流程 (Inconsistent Data Preprocessing Pipeline),線上推論服務所使用的數據預處理軟體（如特徵轉換）與離線訓練時的版本或實作不一致。,NIST AI RMF 1.0 (Core: GOVERN 3.2),開發與維運團隊,訓練流程和推論流程由不同團隊使用不同語言或函式庫開發，導致實作上的細微差異。,"NIST SP 800-30 Rev. 1, Appendix D, Table D-3",缺乏統一的特徵工程與服務框架,未能將數據預處理的程式碼作為一個獨立的、可在訓練和推論時被共同調用的標準化元件進行管理。,"NIST AI RMF 1.0, GOVERN 3.2",6.3 AI 系統資訊,可靠性 / 透明度與可解釋性,導致訓練-服務歪斜 (Train-Serve Skew)，模型在生產環境的表現遠不如預期，且問題難以被追蹤和解釋。,Clause 6.3.4
組織,有形資產,AI 系統 (軟體平台),缺乏災難恢復與業務連續性計畫 (Lack of Disaster Recovery and Business Continuity Plan),整個 AI 軟體平台（包括 MLOps、數據庫、模型服務）部署在單一的地理區域或雲服務可用區，沒有跨區域的災難恢復計畫。,NIST SP 800-30 Rev. 1,環境因素 / 雲服務商,雲服務商的單一可用區發生大規模故障（如斷電、網路中斷），導致平台完全不可用。,"NIST SP 800-30 Rev. 1, Appendix D, Table D-4",缺乏對 AI 系統的業務衝擊分析 (BIA),未能評估 AI 平台中斷對關鍵業務流程的影響，也未能因此投入相應的資源來建立災難恢復能力。,"NIST AI RMF 1.0, PROTECT 2",6.3 AI 系統資訊,可靠性,一旦發生區域性災難，將導致 AI 相關的關鍵業務流程長時間中斷，造成重大的財務和聲譽損失。,Clause 6.8.2
組織,無形資產,聲譽,歧視性決策引發公關危機 (Public Relations Crisis from Discriminatory Decisions),AI 系統因其內在偏見，對特定受保護群體做出了系統性的不公平決策，事件被媒體或社群網路曝光，引發大規模的負面輿論。,NIST AI RMF 1.0 (Core: MANAGE 4),媒體 / 社會大眾,新聞媒體、社群意見領袖或公眾，揭露並傳播了 AI 系統的不公平行為。,"NIST SP 800-30 Rev. 1, Appendix D, Table D-3",未能建立考慮和溝通AI風險的文化 (Failure to foster a culture that considers and communicates AI risk),組織未能預見 AI 偏見可能引發的社會反彈，也缺乏一個透明、誠懇的對外溝通策略與應急預案。,"NIST AI RMF 1.0, GOVERN 4",6.6 社會與環境,公平性 / 責任制,組織被貼上「歧視」、「不道德」的標籤，導致品牌形象嚴重受損，客戶流失，並可能引發抵制活動。,Clause 6.8.2.3
組織,無形資產,聲譽,AI 生成有害或不實內容 (Generation of Harmful or False Content),組織的生成式 AI 服務被濫用，或因自身缺陷，大規模產生並傳播假新聞、仇恨言論或有害內容，使組織被視為這些內容的來源或推手。,MITRE ATLAS: AML.T0043,惡意的模型使用者,惡意用戶利用組織的 AI 工具作為武器，製造和傳播旨在破壞社會穩定或抹黑他人的有害資訊。,"NIST SP 800-30 Rev. 1, Appendix D, Table D-2",對模型輸出內容的審核與過濾不足,系統未能部署有效的內容安全護欄，來過濾和阻止模型生成違反使用政策或法律規範的內容。,"NIST AI RMF 1.0, PROTECT 1.3",6.5 演算法與模型資訊,安全性與隱私 / 責任制,組織的聲譽與有害內容綁定，被認為對社會不負責任，可能面臨內容監管的法律壓力與公眾譴責。,Clause 6.8.2.2
組織,無形資產,聲譽,大規模數據外洩事件 (Major Data Breach Incident),存放 AI 相關數據（訓練數據、用戶數據）的系統遭到入侵，導致大規模敏感個人資訊外洩，事件被公開報導。,NIST AI RMF 1.0 (Core: MAP 3.1),組織犯罪 / 國家級行為者,旨在竊取高價值數據以進行勒索、詐騙或間諜活動的專業攻擊團體。,"NIST SP 800-30 Rev. 1, Appendix D, Table D-2",數據安全與存取控制措施不足,組織未能對其儲存的敏感數據實施充分的加密、存取控制和威脅偵測，使其成為攻擊者的輕易目標。,"NIST AI RMF 1.0, GOVERN 2.1",6.4 資料與知識,安全性與隱私,組織被視為無法保護用戶數據，安全能力受到質疑，導致用戶、合作夥伴和投資者的信任崩潰，聲譽一落千丈。,Clause 6.8.2.1
組織,無形資產,聲譽,AI 系統頻繁故障或性能不穩定 (Frequent System Failure or Unstable Performance),組織對外宣稱其 AI 系統具備高效、可靠的能力，但實際上線後卻頻繁出錯、服務中斷或表現遠不如預期。,NIST AI RMF 1.0 (Core: MANAGE 2),系統元件 / 環境因素,模型的可靠性不足、基礎設施不穩定或未能應對真實世界的數據漂移。,"NIST SP 800-30 Rev. 1, Appendix D, Table D-4",缺乏充分的壓力測試與持續監控,系統在部署前未能經過嚴格的壓力測試，部署後也未能持續監控其性能，無法及時發現並解決問題。,"NIST AI RMF 1.0, MANAGE 2.1",6.3 AI 系統資訊,可靠性,組織的技術能力受到嚴重質疑，被貼上「名不符實」、「不可靠」的標籤，損害其在業界的專業形象與聲譽。,Clause 6.8.2
組織,無形資產,聲譽,缺乏透明度引發的質疑 (Suspicion due to Lack of Transparency),組織的 AI 系統做出了對公眾有重大影響的決策，但拒絕或無法解釋其決策的原因，引發外界對其公正性與意圖的猜疑。,NIST AI RMF 1.0 (Core: GOVERN 4.1),監管機構 / 媒體,監管機構或媒體要求組織對其 AI 的決策過程進行解釋，而組織無法提供滿意的答覆。,"NIST SP 800-30 Rev. 1, Appendix D, Table D-3",未能建立有效的可解釋性與溝通機制,組織未能採用可解釋的 AI 技術，也未能建立一個向利害關係人清晰傳達模型工作原理與決策依據的流程。,"NIST AI RMF 1.0, GOVERN 4.1",6.5 演算法與模型資訊,透明度與可解釋性,組織被認為試圖隱藏其 AI 的運作方式，可能存在暗箱操作或不可告人的目的，從而嚴重損害其公開、透明的聲譽。,Clause 6.3.4
組織,無形資產,聲譽,侵犯智慧財產權的指控 (Accusation of Intellectual Property Infringement),組織在訓練 AI 模型時，未經授權使用了受版權保護的數據（如文章、圖片、程式碼），被原作者或權利方公開指控並提起訴訟。,NIST AI RMF 1.0 (Core: GOVERN 5),權利持有人 / 競爭對手,數據的原始版權所有者，或競爭對手利用此問題來打擊組織的聲譽。,"NIST SP 800-30 Rev. 1, Appendix D, Table D-3",資料來源的合法性與授權追蹤不足,組織缺乏對所用訓練數據來源的智慧財產權進行審查的流程，也未能記錄和管理相關的授權許可。,"NIST AI RMF 1.0, GOVERN 5",6.4 資料與知識,責任制,組織的商業道德受到質疑，被視為不尊重他人智慧財產權，不僅面臨法律風險，其創新能力的聲譽也會受損。,Clause 6.3.4
組織,無形資產,聲譽,誇大不實的 AI 能力宣傳 (Exaggerated and False AI Capability Claims),組織的市場行銷過度誇大其 AI 產品的能力，而用戶實際使用後發現遠未達到宣傳的效果，產生被欺騙的感覺。,NIST AI RMF 1.0 (Core: GOVERN 4.2),行銷/銷售團隊,為了達成業績目標，對 AI 產品的性能、功能或成熟度進行了不實的宣傳。,"NIST SP 800-30 Rev. 1, Appendix D, Table D-3",缺乏對 AI 產品聲明的內部審核機制,組織未能建立一個流程，確保所有對外關於 AI 能力的聲明都經過技術團隊的嚴格驗證和確認。,"NIST AI RMF 1.0, GOVERN 4.2",6.5 演算法與模型資訊,責任制 / 透明度與可解釋性,組織的誠信受到質疑，被認為是為了銷售而欺騙客戶，導致品牌聲譽下降，並可能構成虛假廣告。,Clause 6.3.4
組織,無形資產,聲譽,AI 系統被用於負面社會事件 (AI System Used in Negative Social Incidents),組織開發的 AI 技術（如臉部辨識）被客戶濫用，並在一個廣受爭議的社會事件中扮演了關鍵角色，引發公眾對該技術的倫理聲討。,NIST AI RMF 1.0 (Core: GOVERN 5.1),客戶 / 合作夥伴,購買或使用組織 AI 技術的客戶，將其應用於侵犯人權或引發社會爭議的場景。,"NIST SP 800-30 Rev. 1, Appendix D, Table D-3",缺乏對 AI 系統預期用途與潛在濫用的評估,在銷售或提供 AI 技術時，未能對客戶的預期用途進行充分的倫理審查，也未能預見其被濫用的可能性。,"NIST AI RMF 1.0, GOVERN 5.1",6.6 社會與環境,責任制,即使濫用者是客戶，組織作為技術提供方也會被牽連，其聲譽會因「助紂為虐」而受損，並面臨巨大的社會壓力。,Clause 6.3.4
組織,無形資產,聲譽,對 AI 風險的回應失當 (Improper Response to AI Risks),當 AI 系統的風險（如偏見、安全漏洞）被揭露後，組織採取了否認、隱瞞或推卸責任的態度，而不是積極、透明地解決問題。,NIST AI RMF 1.0 (Core: RESPOND 1),管理階層 / 公關團隊,為了避免承擔短期責任或損失，而做出了長期來看會更嚴重損害聲譽的錯誤決策。,"NIST SP 800-30 Rev. 1, Appendix D, Table D-3",缺乏 AI 事件應急響應與溝通預案,組織沒有為可能發生的 AI 倫理或安全事件，預先準備好一套標準化的調查、響應和溝通流程。,"NIST AI RMF 1.0, RESPOND 1",6.3 AI 系統資訊,責任制,組織的危機處理能力和企業責任感受到嚴重質疑，這種不誠實的態度對聲譽的傷害，往往比風險事件本身更大。,Clause 6.3.4
組織,無形資產,聲譽,AI 對就業的負面衝擊 (Negative Impact of AI on Employment),組織大規模引入 AI 以取代人力，並在過程中採取了不人道的裁員方式，引發了員工、工會和社會對其企業倫理的廣泛批評。,"ISO 42005, Clause 6.8.2.3",組織本身 / 管理階層,為了追求效率和利潤最大化，而忽略了 AI 轉型對員工和社會應負的責任。,"NIST SP 800-30 Rev. 1, Appendix D, Table D-3",缺乏對 AI 社會衝擊的評估與緩解計畫,在決定引入 AI 時，未能全面評估其對員工的衝擊，也未能制定相應的轉職培訓、輔導或補償計畫。,"ISO 42005, Clause 6.8.2.3",6.6 社會與環境,公平性 / 責任制,組織被視為冷酷無情、只顧利益的雇主，不僅嚴重打擊內部員工士氣，也在人才市場和消費者心中留下難以磨滅的負面聲譽。,Clause 6.8.2.3
組織,無形資產,信任,模型決策不可預測且不一致 (Unpredictable and Inconsistent Model Decisions),用戶發現 AI 系統對於相似的輸入，有時會給出截然不同的結果，其行為缺乏穩定性與一致性，讓用戶感到困惑與不可靠。,NIST AI RMF 1.0 (Core: MANAGE 1.1),模型本身,模型的內在隨機性、對輸入的微小變化過於敏感，或因線上學習導致其行為快速變化。,"NIST SP 800-30 Rev. 1, Appendix D, Table D-3",缺乏對模型行為穩定性的長期監控,未能建立機制來追蹤和評估模型決策隨時間的穩定性，也未能向用戶解釋行為變化的原因。,"NIST AI RMF 1.0, MANAGE 1.1",6.5 演算法與模型資訊,可靠性,用戶無法建立對 AI 系統的穩定預期，因此不敢依賴其做出的判斷，從根本上侵蝕了對該系統的信任。,Clause 6.8.2
組織,無形資產,信任,未能保護用戶數據隱私 (Failure to Protect User Data Privacy),用戶數據因安全漏洞、內部濫用或未經同意的二次使用而洩漏，讓用戶感覺其託付給組織的個人資訊沒有得到應有的尊重和保護。,NIST AI RMF 1.0 (Core: PROTECT 1.1),外部攻擊者 / 疏忽的內部人員,旨在竊取或濫用用戶數據的惡意行為者，或因流程疏忽而導致數據暴露的內部員工。,"NIST SP 800-30 Rev. 1, Appendix D, Table D-2/D-3",缺乏貫穿生命週期的隱私保護設計,未能將隱私保護原則（如數據最小化、目的限制）融入 AI 系統的設計、開發和運營的全過程。,"NIST AI RMF 1.0, PROTECT 1.1",6.4 資料與知識,安全性與隱私,用戶一旦感覺到其隱私被侵犯，就會立即且長期地喪失對該組織的信任，並可能轉向競爭對手的產品。,Clause 6.8.2.1
組織,無形資產,信任,決策過程不透明 (Opaque Decision-Making Process),當用戶，特別是利益受到負面影響的用戶，詢問 AI 系統為何做出某項決定時，組織無法提供清晰、易懂的解釋。,NIST AI RMF 1.0 (Core: GOVERN 4.1),開發團隊 / 產品團隊,使用了黑盒子模型，且未能配套開發用戶看得懂的解釋界面或溝通話術。,"NIST SP 800-30 Rev. 1, Appendix D, Table D-3",缺乏面向用戶的可解釋性溝通機制,即使內部有技術性的解釋工具，也未能將其轉化為普通用戶可以理解的語言和形式。,"NIST AI RMF 1.0, GOVERN 4.1",6.5 演算法與模型資訊,透明度與可解釋性,用戶會感覺自己被一個無法理解、無法溝通的權威所支配，這種無力感和神秘感是建立信任的最大障礙。,Clause 6.3.4
組織,無形資產,信任,存在已知的偏見但未被解決 (Known Biases Left Unaddressed),組織已經知曉其 AI 系統中存在對某些群體的不公平偏見，但出於成本或其他原因，選擇不修復或拖延修復，讓用戶感覺組織對公平性漠不關心。,NIST AI RMF 1.0 (Core: MANAGE 4.2),管理階層 / 產品團隊,在權衡公平性修復成本與潛在風險時，做出了短期內對公司有利但長期會損害信任的決策。,"NIST SP 800-30 Rev. 1, Appendix D, Table D-3",缺乏有效的偏見緩解與風險治理流程,組織雖然能夠檢測到偏見，但沒有一個清晰、有力的治理流程來推動相關的緩解措施落地。,"NIST AI RMF 1.0, MANAGE 4.2",6.5 演算法與模型資訊,公平性 / 責任制,用戶會認為組織明知故犯，其對公平、倫理的承諾只是空談，從而對組織的價值觀和所有產品都產生不信任。,Clause 6.8.2.3
組織,無形資產,信任,未能提供有效的申訴與補救途徑 (Failure to Provide Effective Contestability and Redress),當用戶認為自己受到了 AI 系統不公正的對待時，找不到一個有效的渠道來提出申訴，或者申訴後也得不到合理的處理和補救。,NIST AI RMF 1.0 (Core: GOVERN 5.2),法律/合規/產品團隊,組織的系統設計忽略了為用戶提供程序正義和權利救濟的配套機制。,"NIST SP 800-30 Rev. 1, Appendix D, Table D-3",未能將 AI 治理與用戶權利流程相結合,組織的 AI 風險管理框架未能與客戶服務、法務和用戶權利響應流程進行有效整合。,"NIST AI RMF 1.0, GOVERN 5.2",6.5 演算法與模型資訊,責任制 / 公平性,用戶會感覺自己的權利被剝奪，在面對一個自動化系統時孤立無援，這種體驗會徹底摧毀對組織的信任。,Clause 6.3.4
組織,無形資產,信任,AI 系統的安全性不可靠 (Unreliable Security of AI System),組織的 AI 系統頻繁被曝出安全漏洞，或被攻擊者輕易地透過對抗性攻擊等手段繞過，讓用戶對其保護自身安全與利益的能力產生懷疑。,NIST AI RMF 1.0 (Core: PROTECT 1),外部攻擊者,旨在證明或利用 AI 系統安全脆弱性的攻擊者。,"NIST SP 800-30 Rev. 1, Appendix D, Table D-2",對 AI 特定安全風險的評估與防護不足,組織的安全體系仍停留在傳統 IT 安全，未能針對 AI 特有的攻擊向量（如模型竊取、對抗性攻擊）建立專門的防護。,"NIST AI RMF 1.0, PROTECT 1",6.3 AI 系統資訊,安全性與隱私,用戶無法信任一個連自身安全都無法保證的 AI 系統，更不敢將自己重要的數據或決策託付給它。,Clause 6.8.2.2
組織,無形資產,信任,對 AI 的能力邊界溝通不清 (Unclear Communication of AI's Capability Boundaries),組織未能清晰地告知用戶其 AI 系統能做什麼、不能做什麼，以及在哪些情況下可能會出錯，導致用戶因誤用或過度信賴而受到損失。,NIST AI RMF 1.0 (Core: GOVERN 4.2),產品/行銷團隊,為了讓產品看起來更強大，而模糊化了 AI 的局限性和潛在風險。,"NIST SP 800-30 Rev. 1, Appendix D, Table D-3",缺乏面向用戶的風險與局限性溝通策略,產品的設計和文檔中，未能以顯著、易懂的方式向用戶說明 AI 的適用範圍和潛在的錯誤類型。,"NIST AI RMF 1.0, GOVERN 4.2",6.5 演算法與模型資訊,透明度與可解釋性,當用戶因未被告知的局限性而受損時，會感覺被誤導或欺騙，從而喪失對組織誠信的信任。,Clause 6.3.4
組織,無形資產,信任,組織內部缺乏 AI 倫理文化 (Lack of AI Ethics Culture within the Organization),從媒體報導或員工爆料中，外界發現組織內部並不重視 AI 倫理，相關的倫理委員會或審查流程形同虛設，讓用戶對其承諾產生懷疑。,NIST AI RMF 1.0 (Core: GOVERN 1),媒體 / 吹哨人 (Whistleblower),揭露組織內部在 AI 倫理實踐上的不足或虛偽。,"NIST SP 800-30 Rev. 1, Appendix D, Table D-3",AI 治理框架未能有效落地,組織雖然制定了 AI 倫理原則，但未能將其轉化為可執行的政策、工具和考核指標，使其在業務壓力下被忽略。,"NIST AI RMF 1.0, GOVERN 1",6.6 社會與環境,責任制,用戶會認為該組織的 AI 倫理只是公關說辭，無法信任其能夠在利益與道德之間做出正確的選擇。,Clause 6.3.4
組織,無形資產,信任,AI 系統的長期價值不符預期 (Long-term Value of AI Does Not Meet Expectations),組織承諾其 AI 系統能為用戶帶來持續的價值，但隨著時間推移，模型未能更新，性能衰退，無法解決用戶的新問題，讓用戶感覺被「套牢」。,NIST AI RMF 1.0 (Core: MANAGE 2.2),維運團隊 / 產品團隊,組織「重開發、輕維運」，未能投入足夠的資源來持續監控、維護和升級已部署的 AI 系統。,"NIST SP 800-30 Rev. 1, Appendix D, Table D-3",缺乏 AI 產品的生命週期管理策略,未能將 AI 系統視為一個需要持續投入和迭代的產品來進行管理。,"NIST AI RMF 1.0, MANAGE 2.2",6.3 AI 系統資訊,可靠性,用戶對組織兌現長期承諾的能力產生懷疑，從而喪失了建立長期合作關係的信任基礎。,Clause 6.8.2
組織,無形資產,信任,自動化決策取代人類專業判斷 (Automated Decisions Replacing Human Expertise),在需要高度專業知識和人性化考量的領域（如醫療、法律），組織過度依賴 AI 的自動化決策，而忽略或取代了人類專家的角色，讓用戶感到不安。,"ISO 42005, Clause 6.3.4",系統設計師 / 產品團隊,為了追求效率和成本，而設計了一個將人類從關鍵決策迴路中完全排除的自動化系統。,"NIST SP 800-30 Rev. 1, Appendix D, Table D-3",未能建立有效的人機協作 (Human-in-the-loop) 機制,系統的設計未能清晰地界定 AI 和人類專家的職責邊界，也未能為人類專家提供有效的監督和干預工具。,"NIST AI RMF 1.0, GOVERN 5.2",6.5 演算法與模型資訊,責任制 / 可靠性,用戶無法信任一個完全沒有人類監督和同理心的機器來處理他們最重要、最敏感的事務。,Clause 6.3.4
組織,無形資產,智慧財產權 ,模型權重檔案被竊取 (Theft of Model Weights File),組織投入大量資源訓練出的模型權重檔案，被惡意內部人員或外部攻擊者直接竊取。,MITRE ATLAS: AML.T0015,敵對的內部人員 / 外部攻擊者,旨在獲取組織最核心的技術資產，以複製產品或出售牟利。,"NIST SP 800-30 Rev. 1, Appendix D, Table D-2",對模型權重檔案的存取控制與加密不足,未能將模型權重視為最高等級的商業機密，並對其儲存和傳輸進行嚴格的加密與權限管理。,"NIST AI RMF 1.0, GOVERN 2",6.5 演算法與模型資訊,安全性與隱私,直接導致組織核心智慧財產權的喪失，削弱其市場競爭力，其損失可能難以估量。,Clause 6.8.2.1
組織,無形資產,智慧財產權 ,透過 API 進行模型萃取 (Model Extraction via API),競爭對手透過合法或非法的 API 存取，對模型進行大量查詢，並利用這些查詢結果訓練出一個功能高度相似的替代模型。,MITRE ATLAS: AML.T0017,競爭對手,旨在以極低的成本複製組織耗費巨資研發出的模型能力，進行不正當競爭。,"NIST SP 800-30 Rev. 1, Appendix D, Table D-2",對 API 的監控與異常檢測不足,未能部署有效的機制來偵測和阻止疑似模型萃取行為的異常 API 查詢模式。,"NIST AI RMF 1.0, PROTECT 1.3",6.5 演算法與模型資訊,安全性與隱私,組織模型的智慧財產權被間接竊取，其獨特的市場優勢被削弱，投入的研發成本付諸東流。,Clause 6.8.2.1
組織,無形資產,智慧財產權 ,專有的訓練數據被竊取 (Theft of Proprietary Training Data),組織花費大量成本收集、清洗和標註的、具有高度商業價值的專有訓練數據集被竊取。,NIST AI RMF 1.0 (Core: MAP 3.1),組織犯罪 / 競爭對手,數據本身就是一種極其寶貴的資產，竊取數據可以用於訓練自己的模型，或直接削弱對手的數據優勢。,"NIST SP 800-30 Rev. 1, Appendix D, Table D-2",對數據資產的安全防護等級不足,未能像保護模型一樣，對同樣重要的專有數據集實施同等級別的存取控制、加密和監控措施。,"NIST AI RMF 1.0, GOVERN 2.1",6.4 資料與知識,安全性與隱私,組織喪失了其 AI 模型的根本優勢來源，即獨特的數據資產，其長期競爭力受到嚴重打擊。,Clause 6.8.2.1
組織,無形資產,智慧財產權 ,模型架構設計被抄襲 (Plagiarism of Model Architecture Design),組織自主創新設計的、具有獨特優勢的模型架構，在其申請專利或作為商業機密保護之前，被競爭對手抄襲。,NIST AI RMF 1.0 (Core: PROTECT 1.2),競爭對手 / 敵對的內部人員,透過分析論文、逆向工程或內部洩密等方式，獲取組織的專有架構設計。,"NIST SP 800-30 Rev. 1, Appendix D, Table D-2",缺乏對模型架構的商業機密保護措施,對於描述模型架構的設計文件、程式碼和內部知識庫，未能實施嚴格的存取控制和保密協議。,"NIST AI RMF 1.0, PROTECT 1.2",6.5 演算法與模型資訊,安全性與隱私,組織在演算法創新上投入的智慧成果被竊取，喪失了技術領先的機會。,Clause 6.8.2.1
組織,無形資產,智慧財產權 ,因使用開源元件導致專有程式碼被迫開源 (Forced Open Sourcing due to Misuse of Open-source Components),在開發 AI 系統時，使用了帶有「傳染性」授權（如 GPL）的開源元件，導致組織被迫需要將自身的整個專有程式碼庫開源。,NIST AI RMF 1.0 (Core: GOVERN 2.2),開發團隊,開發人員在引入開源元件時，未能仔細審查其授權條款對整個專案的影響。,"NIST SP 800-30 Rev. 1, Appendix D, Table D-3",缺乏對開源與第三方元件的授權審查流程,組織未能建立一個強制性的流程，在引入任何外部程式碼或架構前，對其授權的合規性進行審查。,"NIST AI RMF 1.0, GOVERN 2.2",6.3 AI 系統資訊,責任制,組織的核心智慧財產權，因一個元件的疏忽使用而完全喪失，這是對智慧財產權的毀滅性打擊。,Clause 6.3.4
組織,無形資產,智慧財產權 ,生成式 AI 的輸出內容著作權歸屬不清 (Ambiguous Copyright Ownership of Generative AI Output),組織提供的生成式 AI 服務，其產生的內容（圖片、文字、程式碼）的著作權歸屬是組織還是用戶，法律上界定不清，引發糾紛。,NIST AI RMF 1.0 (Core: GOVERN 5),用戶 / 法律系統,用戶主張其對 AI 生成內容擁有著作權，或第三方主張 AI 生成內容侵犯了其已有著作權。,"NIST SP 800-30 Rev. 1, Appendix D, Table D-3",服務條款中未能清晰界定權利歸屬,組織在提供服務前，未能透過法律條款清晰地向用戶說明 AI 生成內容的智慧財產權歸屬和使用限制。,"NIST AI RMF 1.0, GOVERN 5",6.5 演算法與模型資訊,責任制,權利歸屬的不確定性，會讓組織的商業模式面臨巨大的法律風險，並可能與用戶產生長期的法律糾紛。,Clause 6.3.4
組織,無形資產,智慧財產權 ,AI 系統本身被申請專利 (AI System Itself Being Patented),組織開發的 AI 演算法或應用，未能及時申請專利保護，而被競爭對手搶先申請，導致組織無法再使用自己的發明。,NIST SP 800-30 Rev. 1,競爭對手,透過市場監控或逆向工程，發現組織的創新點，並搶先進行專利佈局。,"NIST SP 800-30 Rev. 1, Appendix D, Table D-2",缺乏及時的智慧財產權保護策略與流程,組織的研發與法務團隊之間缺乏有效的溝通，未能將技術創新及時轉化為專利等法律保護形式。,"NIST AI RMF 1.0, PROTECT 1.2",6.5 演算法與模型資訊,責任制,組織喪失了對其自身創新的合法壟斷權，甚至可能反過來被競爭對手起訴侵權，這是智慧財產權管理的嚴重失誤。,Clause 6.3.4
組織,無形資產,智慧財產權 ,對抗性攻擊導致模型功能洩漏 (Functional Leakage via Adversarial Attacks),攻擊者並非旨在完全複製模型，而是透過特定的對抗性查詢，來探測和推斷模型在某些特定場景下的行為和能力，從而獲取部分功能性機密。,MITRE ATLAS: AML.T0016,競爭對手,旨在了解組織模型的特定能力，以用於自身的產品開發或制定競爭策略。,"NIST SP 800-30 Rev. 1, Appendix D, Table D-2",缺乏對模型決策邊界的保護,未能採用有效的技術手段（如梯度遮罩）來模糊模型的決策邊界，使得攻擊者可以輕易地進行探測。,"NIST AI RMF 1.0, PROTECT 1.3",6.5 演算法與模型資訊,安全性與隱私,即使整個模型未被竊取，其關鍵的功能性智慧財產權也可能被「零敲碎打」地洩漏出去。,Clause 6.8.2.1
組織,無形資產,智慧財產權 ,AI 開發過程中的人才流失 (Brain Drain during AI Development),掌握核心演算法、架構和數據處理know-how的關鍵 AI 人才離職，並加入競爭對手公司，導致隱性的智慧財產權流失。,NIST SP 800-30 Rev. 1,敵對的內部人員 (離職員工),核心員工的離職，並帶走了無法透過文件或專利完全保護的、存在於其頭腦中的寶貴知識和經驗。,"NIST SP 800-30 Rev. 1, Appendix D, Table D-2",缺乏有效的知識管理與人才保留機制,組織未能將關鍵的個人知識轉化為組織的制度化資產，也未能提供足夠的激勵來保留核心人才。,"NIST AI RMF 1.0, GOVERN 1",6.1 人員,責任制,這種隱性的智慧財產權流失，往往比有形資產的失竊更為嚴重，它會從根本上削弱組織的長期創新能力。,Clause 6.3.4
組織,無形資產,智慧財產權 ,未能保護 AI 生成的衍生數據 (Failure to Protect AI-Generated Derivative Data),AI 系統在運行過程中產生的中間數據、特徵或嵌入（Embeddings），本身也可能構成有價值的智慧財產權，但未能得到應有的保護。,NIST AI RMF 1.0 (Core: GOVERN 2.1),外部攻擊者 / 競爭對手,竊取這些衍生數據，可以用於加速自身的模型訓練，或直接作為有價值的分析數據使用。,"NIST SP 800-30 Rev. 1, Appendix D, Table D-2",數據治理策略未能涵蓋衍生數據,組織的數據保護策略只關注原始數據，而忽略了在 AI 處理流程中新產生的、同樣具有價值的衍生數據資產。,"NIST AI RMF 1.0, GOVERN 2.1",6.4 資料與知識,安全性與隱私,喪失了一種新型的、有價值的智慧財產權，並且可能因為這些衍生數據中仍包含原始數據的資訊而引發隱私洩漏。,Clause 6.8.2.1
個人,有形資產,個人的數據 ,成員推斷攻擊 (Membership Inference Attack),攻擊者透過與模型互動，判斷某一筆特定用戶的個人數據是否曾被用於該模型的訓練，進而揭露用戶的隱私（如是否為某疾病患者）。,MITRE ATLAS: AML.T0010,好奇的內部人員 / 外部研究員,旨在驗證特定敏感個人資料是否存在於訓練集中。,"NIST SP 800-30 Rev. 1, Appendix D, Table D-2",訓練數據的匿名化或差分隱私技術應用不足,在將敏感個人數據用於訓練前，未能採取有效的去識別化技術來保護個人隱私。,"NIST AI RMF 1.0, MEASURE 1.2",6.4 資料與知識,安全性與隱私,洩漏了用戶曾參與某項活動或具有某種身份的敏感事實，嚴重侵犯個人隱私，並違反數據保護法規。,Clause 6.5.4 (j)
個人,有形資產,個人的數據 ,屬性推斷攻擊 (Attribute Inference Attack),即使不知道某個體在訓練集中，攻擊者仍可透過模型推斷出該個體的、數據集中未直接提供的敏感屬性（如從購物紀錄推斷收入水平）。,MITRE ATLAS: AML.T0011,惡意的模型使用者,透過精心設計的查詢來反向推斷訓練數據中存在的群體特徵或個人敏感屬性。,"NIST SP 800-30 Rev. 1, Appendix D, Table D-2",模型對訓練數據的過度記憶 (Over-memorization),模型學習到了數據中不同屬性之間的細微關聯，使得它可以從非敏感屬性推斷出敏感屬性。,"NIST AI RMF 1.0, MEASURE 1.2",6.4 資料與知識,安全性與隱私,揭露了個人未曾公開的敏感資訊，可能被用於歧視、詐騙或社會工程攻擊，構成嚴重的隱私侵害。,Clause 6.5.4 (j)
個人,有形資產,個人的數據 ,模型逆向工程攻擊 (Model Inversion Attack),攻擊者分析模型的輸出，反向重建出模型在訓練過程中學習到的、具有代表性的個人數據樣本（如人臉圖像）。,MITRE ATLAS: AML.T0012,惡意的模型使用者,旨在從模型本身還原出最敏感的、原始的個人數據。,"NIST SP 800-30 Rev. 1, Appendix D, Table D-2",未能在模型輸出端進行隱私保護,系統在提供模型輸出時，未能採取如降低精度、增加混淆等措施，來防止敏感的訓練資訊被反推。,"NIST AI RMF 1.0, PROTECT 1.1",6.5 演算法與模型資訊,安全性與隱私,相當於從模型中直接還原出了原始的個人數據，是對個人數據隱私最直接、最嚴重的侵犯。,Clause 6.5.4 (j)
個人,有形資產,個人的數據 ,數據庫的大規模洩漏 (Large-scale Leakage of Database),儲存用戶個人數據的整個資料庫或資料湖，因外部攻擊或內部錯誤而被一次性完整洩漏。,NIST AI RMF 1.0 (Core: MAP 3.1),組織犯罪 / 外部攻擊者,旨在獲取海量的個人數據，用於地下市場交易、大規模詐騙或身份盜竊。,"NIST SP 800-30 Rev. 1, Appendix D, Table D-2",數據庫的存取控制與加密機制不當,存放個人數據的資料庫缺乏嚴格的存取控制、靜態加密和動態加密，使其成為攻擊的首要目標。,"NIST AI RMF 1.0, GOVERN 2.1",6.4 資料與知識,安全性與隱私,導致海量用戶的個人數據被完全暴露，是後果最嚴重、影響最廣泛的數據安全事件。,Clause 6.8.2.1
個人,有形資產,個人的數據 ,超出目的的二次使用 (Secondary Use Beyond Purpose),組織為了 A 目的收集了用戶的個人數據，但在未經用戶同意的情況下，又將其用於 B 目的（如訓練一個完全無關的模型）。,NIST AI RMF 1.0 (Core: GOVERN 1.1),內部開發/行銷團隊,為了業務目標，違反了數據保護法規中的「目的限制」原則。,"NIST SP 800-30 Rev. 1, Appendix D, Table D-3",數據治理與目的限制原則執行不力,組織內部缺乏強而有力的數據治理策略和技術控制，以確保數據的使用嚴格遵守其收集時的目的。,"NIST AI RMF 1.0, GOVERN 1.1",6.4 資料與知識,責任制 / 安全性與隱私,侵犯了用戶對其個人數據的自決權，違反了 GDPR 等法規，可能導致監管機構的重罰。,Clause 6.3.4
個人,有形資產,個人的數據 ,未能響應用戶數據權利請求 (Failure to Respond to User Data Rights Requests),用戶依法提出的數據存取、更正、刪除（被遺忘權）等請求，組織未能及時、完整地響應。,NIST AI RMF 1.0 (Core: GOVERN 5.2),系統管理員 / 流程負責人,因流程不完整或技術限制，無法在複雜的系統中定位並處理特定用戶的所有數據。,"NIST SP 800-30 Rev. 1, Appendix D, Table D-3",缺乏完整的資料生命週期與沿襲管理,對數據的流動、複製和使用缺乏清晰的追蹤地圖，導致無法在需要時定位並徹底清除所有相關數據。,"NIST AI RMF 1.0, GOVERN 1.2",6.4 資料與知識,責任制 / 公平性,直接違反了數據保護法規賦予數據主體的合法權利，將面臨法律訴訟和監管處罰。,Clause 6.3.4
個人,有形資產,個人的數據 ,在日誌或分析中意外暴露個資 (Accidental Exposure of Personal Data in Logs or Analytics),用戶的個人數據（如姓名、地址、電話）在未經脫敏處理的情況下，被寫入系統日誌或用於內部數據分析，暴露給了不應有權限的內部員工。,NIST AI RMF 1.0 (Core: PROTECT 1.1),疏忽的內部人員,開發或維運人員在配置日誌系統時，未能過濾掉其中的敏感個人數據。,"NIST SP 800-30 Rev. 1, Appendix D, Table D-3",生產數據的紀錄與儲存缺乏匿名化處理,系統在產生各類非業務必需的數據時，缺乏一個自動化的流程來識別並遮罩其中的個人數據。,"NIST AI RMF 1.0, PROTECT 1.1",6.4 資料與知識,安全性與隱私,擴大了個人數據的內部暴露面，增加了內部濫用或因其他安全事件導致二次洩漏的風險。,Clause 6.8.2.1
個人,有形資產,個人的數據 ,透過數據聚合產生新的敏感資訊 (Generation of New Sensitive Information via Data Aggregation),AI 系統將多個看似非敏感的個人數據點進行聚合分析，從而推斷出用戶新的、更為敏感的個人標籤（如健康狀況、政治傾向）。,NIST AI RMF 1.0 (Core: MAP 2.1),模型本身 / 數據分析團隊,旨在從現有數據中挖掘更深層次的用戶洞察，但無意中跨越了隱私的邊界。,"NIST SP 800-30 Rev. 1, Appendix D, Table D-3",缺乏對 AI 輸出結果的隱私風險評估,組織僅關注輸入數據的隱私，而未能評估 AI 系統新產生的用戶標籤或畫像是否構成了新的、未經同意的個人數據。,"NIST AI RMF 1.0, MAP 2.1",6.4 資料與知識,安全性與隱私,這種「推斷出的個資」同樣受到數據保護法規的保護，其產生和使用可能構成對用戶隱私的侵犯。,Clause 6.5.4 (j)
個人,有形資產,個人的數據 ,對兒童或弱勢群體數據處理不當 (Improper Handling of Data from Children or Vulnerable Groups),AI 系統在處理兒童或法律定義的弱勢群體的個人數據時，未能遵循更為嚴格的法律要求（如取得監護人同意）。,"ISO 42005, Clause 6.8.2.3",法律/合規/產品團隊,產品設計未能充分識別其用戶群體，並為其中的弱勢群體提供特殊、增強的數據保護措施。,"NIST SP 800-30 Rev. 1, Appendix D, Table D-3",未能針對不同用戶群體實施差異化的隱私保護策略,系統的隱私政策和技術控制對所有用戶一視同仁，未能滿足針對特定群體的更高法律保護標準。,"NIST AI RMF 1.0, GOVERN 5",6.4 資料與知識,公平性 / 責任制,違反了針對兒童和弱勢群體的專門數據保護法規（如 COPPA），將面臨極其嚴厲的法律制裁和公眾道德譴責。,Clause 6.8.2.3
個人,有形資產,個人的數據 ,生物辨識數據的濫用或洩漏 (Misuse or Leakage of Biometric Data),AI 系統收集和處理的生物辨識數據（如人臉、指紋、聲紋），因其唯一且不可更改的特性，一旦洩漏或被濫用，將對個人造成終身影響。,NIST AI RMF 1.0 (Core: PROTECT 1.1),外部攻擊者 / 惡意的內部人員,旨在竊取這種最高敏感等級的個人數據，用於身份盜竊或其他惡意目的。,"NIST SP 800-30 Rev. 1, Appendix D, Table D-2",對生物辨識數據的保護措施不足,未能將生物辨識數據作為最敏感的數據類型，並對其採集、儲存、處理和銷毀的全過程實施最嚴格的安全控制。,"NIST AI RMF 1.0, PROTECT 1.1",6.4 資料與知識,安全性與隱私,生物辨識數據的洩漏是不可逆的，會給個人帶來長期的、無法挽回的安全與隱私風險，也是組織不可承受之重。,Clause 6.8.2.1
個人,無形資產,隱私,大規模監控 (Mass Surveillance),利用 AI 驅動的影像辨識、語音監聽等技術，對公眾或特定群體進行大規模、持續性的監控，嚴重侵犯個人的私領域與匿名權。,NIST AI RMF 1.0 (Core: GOVERN 5.1),政府機構 / 企業,為了國家安全、城市管理或商業利益，而部署了超出必要比例原則的監控系統。,"NIST SP 800-30 Rev. 1, Appendix D, Table D-3",缺乏對 AI 系統部署的倫理審查與影響評估,在部署具有大規模監控能力的 AI 系統前，未能對其潛在的人權與隱私衝擊進行充分的評估和公開討論。,"NIST AI RMF 1.0, GOVERN 5.1",6.6 社會與環境,安全性與隱私 / 公平性,造成寒蟬效應，限制言論與集會自由，並可能導致對特定族群的不公平執法或差別對待。,Clause 6.8.2.3
個人,無形資產,隱私,數據重新識別 (Data Re-identification),攻擊者利用 AI 技術，將已「匿名化」的數據集與其他公開資訊進行關聯比對，從而重新識別出數據集中的個人真實身份。,NIST AI RMF 1.0 (Core: PROTECT 1.1),外部研究員 / 數據掮客,旨在從公開或洩漏的匿名數據中，挖掘出具有高價值的個人可識別資訊。,"NIST SP 800-30 Rev. 1, Appendix D, Table D-2",對匿名化技術的強度評估不足,組織使用了過時或不充分的匿名化技術（如簡單的移除姓名），未能抵抗基於 AI 的強大重新識別攻擊。,"NIST AI RMF 1.0, PROTECT 1.1",6.4 資料與知識,安全性與隱私,使得組織基於「數據已匿名」的假設所做的數據共享或發布行為變得極其危險，導致大規模的隱私洩漏。,Clause 6.8.2.1
個人,無形資產,隱私,推斷性隱私侵犯 (Inferential Privacy Invasion),AI 系統透過分析個人的行為數據，推斷出其未曾公開的、高度敏感的個人屬性，如健康狀況、性取向、政治立場或懷孕狀態。,MITRE ATLAS: AML.T0011,數據分析團隊 / 廣告商,為了進行精準行銷或信用評分，而利用 AI 挖掘用戶最深層的個人特徵。,"NIST SP 800-30 Rev. 1, Appendix D, Table D-3",缺乏對 AI 輸出結果的隱私風險評估,組織僅關注輸入數據的隱私，而未能評估 AI 系統新產生的用戶標籤或畫像是否構成了新的、未經同意的個人數據。,"NIST AI RMF 1.0, MAP 2.1",6.4 資料與知識,安全性與隱私,侵犯了個人的內心世界和思想自由，用戶在不知情的情況下被貼上各種敏感標籤，並可能因此受到歧視或操縱。,Clause 6.5.4 (j)
個人,無形資產,隱私,情緒辨識與操縱 (Emotion Recognition and Manipulation),利用 AI 分析人的臉部表情、語氣或文字，來判斷其情緒狀態，並可能利用這些資訊來對其進行情緒誘導或行為操縱（如在脆弱時推送特定廣告）。,NIST AI RMF 1.0 (Core: GOVERN 5.1),企業 / 政治活動家,旨在提升廣告點擊率、銷售額或影響個人的政治決策。,"NIST SP 800-30 Rev. 1, Appendix D, Table D-3",對 AI 技術應用的倫理邊界界定不清,組織在追求技術能力時，未能為其應用設定清晰的倫理紅線，特別是涉及人類自主性與尊嚴的領域。,"NIST AI RMF 1.0, GOVERN 5.1",6.6 社會與環境,公平性 / 安全性與隱私,侵犯了個人的情緒自主權，可能導致不公平的差別定價，或在政治、社會議題上進行大規模的民意操縱。,Clause 6.8.2.3
個人,無形資產,隱私,深度偽造用於身份盜用或詐騙 (Deepfake for Identity Theft or Fraud),攻擊者利用深度偽造技術，生成特定個人的偽造影像或聲音，用於繞過身份驗證、進行金融詐騙或傳播虛假訊息。,MITRE ATLAS: AML.T0043,組織犯罪 / 惡意個人,旨在冒充他人身份以獲取非法利益，或對特定個人進行敲詐勒索。,"NIST SP 800-30 Rev. 1, Appendix D, Table D-2",身份驗證機制過於依賴單一生物特徵,系統的身份驗證流程（如刷臉支付）未能整合多因素驗證，過於信賴單一的、可能被偽造的生物辨識數據。,"NIST AI RMF 1.0, PROTECT 1.3",6.5 演算法與模型資訊,安全性與隱私,使得個人的生物特徵不再安全，身份隨時可能被盜用，對個人財產安全和社會信任體系構成嚴重威脅。,Clause 6.8.2.2
個人,無形資產,隱私,用戶畫像的固化與歧視 (Solidification and Discrimination of User Profiles),AI 系統根據用戶的歷史行為，為其建立了一個全面但可能片面的數位畫像，並基於此畫像進行自動化決策，限制了個人的發展可能與機會。,NIST AI RMF 1.0 (Core: MAP 2.2),系統設計師 / 數據分析團隊,系統的設計使其傾向於根據歷史數據進行歸類，而忽略了個人的成長與變化。,"NIST SP 800-30 Rev. 1, Appendix D, Table D-3",未能提供用戶對其畫像的存取與更正權,系統未能提供一個透明的機制，讓用戶可以檢視、理解並在必要時更正 AI 系統為其建立的個人畫像。,"NIST AI RMF 1.0, GOVERN 5.2",6.4 資料與知識,公平性 / 透明度與可解釋性,個人被「數位地」定義與限制，可能因此錯失工作、貸款或教育機會，構成一種新型態的數位歧視。,Clause 6.8.2.3
個人,無形資產,隱私,家庭與私人空間的侵犯 (Invasion of Home and Private Spaces),帶有 AI 功能的家用物聯網設備（如智慧音箱、攝影機）持續收集家庭環境中的聲音和影像數據，可能記錄下極度私密的家庭生活。,NIST AI RMF 1.0 (Core: PROTECT 1.1),設備製造商 / 外部攻擊者,設備製造商可能出於數據分析目的而過度收集；或駭客入侵這些防護薄弱的設備，進行竊聽或窺視。,"NIST SP 800-30 Rev. 1, Appendix D, Table D-2",物聯網設備的安全防護與透明度不足,設備缺乏足夠的安全強化，且未能清晰、主動地告知用戶數據在何時、出於何種目的被收集。,"NIST AI RMF 1.0, PROTECT 1.2",6.2 硬體,安全性與隱私,個人最神聖的私人空間被數位化並暴露於風險之中，家庭成員的言行舉止都可能被永久記錄和分析。,Clause 6.8.2.1
個人,無形資產,隱私,跨情境數據的非預期關聯 (Unexpected Correlation of Cross-Context Data),AI 系統將用戶在不同場景、不同平台下（如醫療、社交、購物）的數據進行關聯，揭示出用戶不願為人知、且在單一場景下無法看出的隱私。,NIST AI RMF 1.0 (Core: MAP 2.1),數據聚合商 / 企業,旨在建立最全面的用戶視圖，以實現商業價值最大化。,"NIST SP 800-30 Rev. 1, Appendix D, Table D-3",數據治理未能有效隔離不同目的的數據,組織內部缺乏嚴格的技術和流程控制，來防止不同業務線收集的、具有不同隱私期望的數據被混合使用。,"NIST AI RMF 1.0, GOVERN 1.2",6.4 資料與知識,安全性與隱私 / 責任制,打破了用戶在不同社會角色下的隱私邊界，用戶對數據控制權的期望被完全破壞。,Clause 6.3.4
個人,無形資產,隱私,遺忘權的技術實現困難 (Technical Difficulty in Realizing the Right to be Forgotten),當用戶要求刪除其數據時，組織無法將其從已訓練好的複雜模型權重中、以及各種備份和日誌中徹底、乾淨地移除。,NIST AI RMF 1.0 (Core: GOVERN 1.2),系統管理員 / 模型本身,AI 模型的黑盒子特性，以及數據在系統中複雜的流動與複製，使得「完全刪除」變得技術上極具挑戰。,"NIST SP 800-30 Rev. 1, Appendix D, Table D-3",缺乏「機器遺忘」等隱私增強技術的應用,組織未能投入研發或採用新興的「機器遺忘」(Machine Unlearning) 技術，來使其 AI 系統能夠真正響應用戶的刪除權。,"NIST AI RMF 1.0, GOVERN 1.2",6.5 演算法與模型資訊,責任制,使得數據保護法規賦予用戶的「被遺忘權」在 AI 時代淪為一紙空文，組織因此面臨巨大的法律合規風險。,Clause 6.3.4
個人,無形資產,隱私,對思想和信仰的審查 (Censorship of Thoughts and Beliefs),AI 系統被用於分析個人的言論、網路活動，以判斷其思想、信仰或政治傾向是否符合特定標準，並可能基於此進行審查或懲罰。,NIST AI RMF 1.0 (Core: GOVERN 5.1),威權政府 / 平台營運商,旨在壓制異議、鞏固統治或執行特定的平台內容政策。,"NIST SP 800-30 Rev. 1, Appendix D, Table D-3",缺乏對 AI 應用的基本人權紅線,將 AI 技術應用於侵犯基本人權（如思想自由）的領域。,"NIST AI RMF 1.0, GOVERN 5.1",6.6 社會與環境,公平性 / 責任制,構成了對人類最基本尊嚴——思想自由的侵犯，是 AI 技術最嚴重的倫理濫用之一。,Clause 6.8.2.3
個人,無形資產,健康 ,AI 醫療診斷錯誤 (Misdiagnosis by Medical AI),用於影像判讀（如 X 光、CT）或病理分析的 AI 模型，因訓練數據的偏差或模型的脆弱性，做出了錯誤的診斷，導致患者病情延誤或接受不當治療。,NIST AI RMF 1.0 (Core: MANAGE 1.1),模型本身,模型的泛化能力不足，無法處理罕見病例或不同於訓練數據的影像品質。,"NIST SP 800-30 Rev. 1, Appendix D, Table D-3",缺乏充分的臨床驗證與人類專家覆核機制,AI 診斷系統在部署前，未能經過多中心、大規模的真實世界臨床試驗；且其輸出結果未能被要求必須經過人類醫生的最終確認。,"NIST AI RMF 1.0, MEASURE 2.1",6.5 演算法與模型資訊,可靠性 / 責任制,直接對患者的身體健康造成嚴重傷害，甚至危及生命，並引發複雜的醫療糾紛與責任認定問題。,Clause 6.8.2.3
個人,無形資產,健康 ,治療方案推薦的偏見 (Bias in Treatment Recommendation),AI 根據病患的數據推薦個人化治療方案，但因訓練數據中包含了歷史上對某些種族或性別的醫療偏見，從而推薦了次優或有害的治療方案。,NIST AI RMF 1.0 (Core: MAP 2.2),歷史數據 / 模型本身,歷史醫療數據中，女性或少數族裔的數據代表性不足，或反映了過時的、帶有偏見的醫療實踐。,"NIST SP 800-30 Rev. 1, Appendix D, Table D-3",缺乏對訓練數據與模型決策的公平性審計,在開發醫療 AI 前，未能對數據中的潛在偏見進行系統性的識別與緩解，也未能審計模型的推薦結果在不同群體間是否存在差異。,"NIST AI RMF 1.0, MAP 2.2",6.5 演算法與模型資訊,公平性,導致系統性的醫療不平等，某些群體的患者因 AI 的建議而無法獲得最佳治療，加劇了健康差距。,Clause 6.8.2.3
個人,無形資產,健康 ,健康數據的隱私洩漏 (Leakage of Health Data),存有大量個人健康資訊（PHI）的 AI 系統（如用於基因分析、疾病預測）遭到入侵，導致極度敏感的個人健康狀況被洩漏。,NIST AI RMF 1.0 (Core: PROTECT 1.1),外部攻擊者 / 惡意的內部人員,個人健康資訊在地下市場具有極高價值，是駭客攻擊的重點目標。,"NIST SP 800-30 Rev. 1, Appendix D, Table D-2",對健康數據的保護措施未達法定標準,系統的安全措施未能滿足 HIPAA 等健康資訊保護法規的嚴格要求。,"NIST AI RMF 1.0, GOVERN 2.1",6.4 資料與知識,安全性與隱私,健康狀況的洩漏會給個人帶來毀滅性的打擊，可能導致其在就業、保險等方面受到歧視，並承受巨大的精神壓力。,Clause 6.8.2.1
個人,無形資產,健康 ,藥物研發中的錯誤引導 (Misdirection in Drug Discovery),用於藥物研發或分子篩選的 AI 模型，因其自身的缺陷或對生物學機理的理解錯誤，將研發資源引導到了錯誤的方向，浪費了寶貴的時間和資金。,NIST AI RMF 1.0 (Core: MEASURE 2.3),模型本身,模型學習到了數據中的虛假相關性，而非真實的因果關係，其預測結果在現實世界的實驗中無法被驗證。,"NIST SP 800-30 Rev. 1, Appendix D, Table D-3",對模型預測結果的實驗驗證不足,科學家過於信賴 AI 的計算結果，而未能設計和執行足夠的、嚴謹的濕實驗 (wet-lab experiment) 來進行驗證。,"NIST AI RMF 1.0, MEASURE 2.3",6.5 演算法與模型資訊,可靠性,延誤了潛在新藥的上市，對等待治療的患者造成間接傷害，並造成巨大的研發資源浪費。,Clause 6.8.2
個人,無形資產,健康 ,AI 心理健康應用的誤導 (Misleading by AI Mental Health Applications),用於心理諮詢或情緒支持的聊天機器人，因其對人類情感的理解有限，可能給出不恰當、甚至有害的建議，加重用戶的心理問題。,NIST AI RMF 1.0 (Core: GOVERN 5.1),系統設計師 / 模型本身,將一個語言模型包裝成專業的心理諮詢師，而實際上它並不具備相應的專業知識和倫理判斷能力。,"NIST SP 800-30 Rev. 1, Appendix D, Table D-3",對 AI 的能力邊界溝通不清,應用未能清晰地告知用戶其僅為輔助工具，不能替代專業的人類心理諮詢師，並在偵測到嚴重問題時未能及時轉介。,"NIST AI RMF 1.0, GOVERN 4.2",6.5 演算法與模型資訊,可靠性 / 責任制,對處於心理脆弱狀態的用戶造成二次傷害，甚至可能引發嚴重後果。,Clause 6.8.2.3
個人,無形資產,健康 ,可穿戴設備的健康監測錯誤 (Errors in Health Monitoring by Wearables),可穿戴設備（如智慧手錶）上的 AI 演算法，在監測心率、血氧等生命體徵時出現錯誤，可能導致未能及時發現危急的健康狀況，或反覆誤報引發不必要的焦慮。,NIST AI RMF 1.0 (Core: MANAGE 1.1),模型本身 / 硬體感測器,感測器數據的雜訊、個體差異或演算法的缺陷，都可能導致監測結果不準確。,"NIST SP 800-30 Rev. 1, Appendix D, Table D-3",缺乏在多樣化人群中的廣泛測試與驗證,設備及其演算法在上市前，未能經過在不同膚色、體型、健康狀況人群中的大規模、嚴格的準確性測試。,"NIST AI RMF 1.0, MEASURE 2.1",6.2 硬體,可靠性,假陰性（漏報）會延誤救治；假陽性（誤報）會造成用戶不必要的恐慌和醫療資源浪費。,Clause 6.8.2.3
個人,無形資產,健康 ,疫情預測模型失準 (Inaccuracy of Epidemic Prediction Models),用於預測傳染病擴散趨勢的 AI 模型，因數據品質不佳、模型假設錯誤或未能適應病毒變異，做出了錯誤的預測，誤導了公共衛生決策。,NIST AI RMF 1.0 (Core: MANAGE 2.1),模型本身 / 數據源,疫情數據的上報延遲、不一致，以及人類行為的不可預測性，都對模型的準確性構成巨大挑戰。,"NIST SP 800-30 Rev. 1, Appendix D, Table D-3",對模型的不確定性與假設溝通不足,模型開發者未能向決策者清晰地溝通其預測結果的信賴區間、潛在的誤差範圍以及模型所依賴的關鍵假設。,"NIST AI RMF 1.0, GOVERN 4.2",6.5 演算法與模型資訊,透明度與可解釋性 / 可靠性,基於錯誤預測所制定的封鎖、隔離或資源分配政策，可能造成巨大的社會、經濟損失，並影響疫情防控的成效。,Clause 6.8.2
個人,無形資產,健康 ,智慧醫療設備的互操作性與安全風險 (Interoperability and Security Risks of Smart Medical Devices),聯網的 AI 醫療設備（如胰島素泵、起搏器）的軟體平台存在漏洞，或與醫院其他系統的互操作性不佳，可能被駭客攻擊或因數據交換錯誤而失靈。,NIST AI RMF 1.0 (Core: PROTECT 1.2),外部攻擊者,旨在透過入侵醫療設備來直接對患者造成人身傷害，或進行勒索。,"NIST SP 800-30 Rev. 1, Appendix D, Table D-2",醫療物聯網 (IoMT) 設備的安全標準與實踐不足,設備製造商在開發過程中，未能遵循嚴格的網路安全標準，導致其產品易受攻擊。,"NIST AI RMF 1.0, PROTECT 1.2",6.2 硬體,安全性與隱私 / 可靠性,攻擊者可能遠程操控設備，給予致命劑量的藥物；或系統故障導致設備失靈，兩者都直接危及患者生命。,Clause 6.8.2.2
個人,無形資產,健康 ,健康資源分配不公 (Unfair Allocation of Health Resources),AI 系統被用於決定誰能優先獲得稀缺的醫療資源（如器官移植、ICU 床位），但其演算法的設計偏向於某些群體，導致了不公平的資源分配。,NIST AI RMF 1.0 (Core: MAP 2.2),系統設計師 / 歷史數據,演算法的目標函數（如最大化存活年限）或訓練數據中內含的社會經濟地位偏差，都可能導致歧視性結果。,"NIST SP 800-30 Rev. 1, Appendix D, Table D-3",缺乏對演算法價值觀的倫理審查,在設計資源分配演算法時，未能進行廣泛的社會倫理討論，以確保其目標函數符合社會的公平正義觀念。,"NIST AI RMF 1.0, GOVERN 4.1",6.5 演算法與模型資訊,公平性,構成制度性的生命權不平等，弱勢群體在最需要幫助的時候，卻被一個自動化系統剝奪了平等的機會。,Clause 6.8.2.3
個人,無形資產,健康 ,AI 助長健康焦慮與錯誤資訊 (AI Fueling Health Anxiety and Misinformation),推薦演算法向用戶大量推送誇大其詞、未經證實的健康資訊或疾病症狀，加劇用戶的健康焦慮；或傳播反科學的醫療偽知識。,NIST AI RMF 1.0 (Core: GOVERN 5.1),內容推薦演算法,演算法的目標是最大化用戶停留時間和點擊率，而聳動、引發焦慮的內容往往最能達成此目標。,"NIST SP 800-30 Rev. 1, Appendix D, Table D-3",內容推薦未能結合資訊的權威性與真實性,演算法在進行推薦時，未能將內容來源的權威性（如來自專業醫療機構）作為一個重要的加權因子。,"NIST AI RMF 1.0, GOVERN 5.1",6.5 演算法與模型資訊,可靠性 / 責任制,對公眾的健康素養造成負面影響，引導用戶採取不當的健康行為，並對公共衛生系統產生不信任。,Clause 6.8.2.3
個人,無形資產,安全,自動駕駛系統感知失敗 (Perception Failure in Autonomous Vehicles),自動駕駛汽車的 AI 感知系統，因惡劣天氣、感測器被遮擋或遇到未曾見過的物體，未能正確識別行人、障礙物或其他車輛，導致交通事故。,NIST AI RMF 1.0 (Core: MANAGE 1.1),模型本身 / 環境因素,AI 模型對訓練場景的過擬合，使其無法應對真實世界中無窮無盡的「邊角案例」(corner cases)。,"NIST SP 800-30 Rev. 1, Appendix D, Table D-4",缺乏對 AI 系統在極端與非預期場景下的充分測試,系統的測試主要在常規場景下進行，未能建立一個系統化的流程來發現和測試模型在各種邊角案例下的反應。,"NIST AI RMF 1.0, MEASURE 2.1",6.2 硬體,可靠性,直接導致車輛碰撞、人員傷亡的嚴重交通事故，是對公眾物理安全最直接的威脅之一。,Clause 6.8.2.3
個人,無形資產,安全,工業 AI 導致工傷事故 (Workplace Accidents Caused by Industrial AI),工廠中的 AI 機器人或自動化系統，因預測或路徑規劃錯誤，或未能正確識別附近的人類同事，而對工人造成擠壓、碰撞等物理傷害。,NIST AI RMF 1.0 (Core: MANAGE 1.1),模型本身 / 硬體感測器,系統的感知能力或決策邏輯存在缺陷，無法在複雜、動態的工廠環境中確保 100% 的人機協作安全。,"NIST SP 800-30 Rev. 1, Appendix D, Table D-3",人機協作的安全冗餘與防護機制不足,系統的設計未能包含足夠的物理或數位安全冗餘（如安全圍籬、急停按鈕、碰撞預測），以在 AI 失效時保護人類。,"NIST AI RMF 1.0, PROTECT 2",6.3 AI 系統資訊,可靠性 / 責任制,對員工的生命安全構成直接威脅，並使企業面臨法律訴訟、鉅額賠償和生產停頓的風險。,Clause 6.8.2.3
個人,無形資產,安全,關鍵基礎設施的 AI 控制失靈 (AI Control Failure in Critical Infrastructure),用於控制電網、水壩、核電站等關鍵基礎設施的 AI 系統，因遭受網路攻擊、軟體錯誤或數據漂移而做出錯誤決策，導致災難性事故。,NIST AI RMF 1.0 (Core: PROTECT 1.2),國家級行為者 / 恐怖分子,旨在透過癱瘓或破壞一個國家的關鍵基礎設施，來製造大規模的社會混亂。,"NIST SP 800-30 Rev. 1, Appendix D, Table D-2",對 AI 控制系統的網路安全防護不足,將傳統的工控系統 (OT) 與 AI 系統相連，但未能對這個新的、更複雜的系統實施同等級別的嚴格網路安全隔離與防護。,"NIST AI RMF 1.0, PROTECT 1.2",6.3 AI 系統資訊,安全性與隱私 / 可靠性,可能導致大面積停電、洪水、核洩漏等嚴重後果，對國家安全和公眾生命財產構成根本性威脅。,Clause 6.8.2.2
個人,無形資產,安全,自主武器的失控與倫理風險 (Loss of Control and Ethical Risks of Autonomous Weapons),AI 驅動的自主武器系統（如無人機蜂群）在目標識別、交戰決策上出現錯誤，或因通信中斷而失控，可能攻擊平民或己方部隊。,"ISO 42005, Clause 6.8.2.2",敵方 / 模型本身,戰場環境的複雜性與對抗性，使得 AI 系統極易出現目標識別錯誤；或系統本身存在後門被敵方利用。,"NIST SP 800-30 Rev. 1, Appendix D, Table D-2",缺乏有意義的人類控制 (Meaningful Human Control),系統的設計將人類從致命武力的決策迴路中完全或過度地排除，將生殺大權交給了機器。,"NIST AI RMF 1.0, GOVERN 5.2",6.5 演算法與模型資訊,責任制 / 安全性與隱私,引發嚴重的戰爭倫理問題，違反國際人道法，並可能因機器決策的不可預測性而導致衝突的快速、災難性升級。,Clause 6.8.2.2
個人,無形資產,安全,安防系統的錯誤警報與漏報 (False Alarms and Misses in Security Systems),用於入侵偵測、暴力事件識別的 AI 安防系統，因將正常行為誤判為威脅而頻繁產生誤報，或未能識別出真正的威脅（漏報）。,NIST AI RMF 1.0 (Core: MANAGE 1.1),模型本身,模型對於「異常」的定義過於寬泛或狹隘，無法準確區分真實威脅與正常但少見的行為。,"NIST SP 800-30 Rev. 1, Appendix D, Table D-3",未能根據實際場景對模型的閾值進行校準,未能根據部署環境的具體情況，對模型的觸發閾值進行優化，以在誤報率和漏報率之間取得可接受的平衡。,"NIST AI RMF 1.0, MEASURE 1.1",6.3 AI 系統資訊,可靠性,誤報會導致「狼來了」效應，讓安保人員對系統失去信任；漏報則會導致真實的安全事件未能被及時阻止。,Clause 6.8.2
個人,無形資產,安全,對抗性攻擊癱瘓安全設施 (Adversarial Attacks Paralyzing Safety Facilities),攻擊者利用特製的對抗性樣本（如一件印有特殊圖案的 T 恤），來讓智慧城市的安防攝影機系統失效，使其無法識別出攻擊者。,MITRE ATLAS: AML.T0030,恐怖分子 / 犯罪分子,旨在使自己在實施犯罪或恐怖襲擊時，對 AI 監控系統「隱形」。,"NIST SP 800-30 Rev. 1, Appendix D, Table D-2",對物理世界的對抗性攻擊防禦不足,系統的防禦主要集中在數位世界的攻擊，而未能考慮到攻擊者可能在物理世界中呈現對抗性樣本。,"NIST AI RMF 1.0, PROTECT 1.3",6.5 演算法與模型資訊,安全性與隱私,使得城市或特定場所的安全監控網絡在關鍵時刻被輕易癱瘓，為惡意行為者創造了巨大的安全漏洞。,Clause 6.8.2.2
個人,無形資產,安全,AI 輔助設計導致結構缺陷 (Structural Flaws from AI-Assisted Design),用於工程設計（如橋樑、飛機零件）的生成式 AI，為了追求材料的最優化，可能設計出一些人類工程師難以直觀理解、且在非預期壓力下存在脆弱性的結構。,NIST AI RMF 1.0 (Core: MEASURE 2.3),模型本身,模型的優化目標函數未能完全涵蓋所有真實世界中可能遇到的複雜物理約束和極端負載情況。,"NIST SP 800-30 Rev. 1, Appendix D, Table D-3",缺乏對 AI 生成設計的充分物理驗證與可解釋性分析,過於信賴 AI 的模擬結果，而未能對其生成的創新結構進行足夠的物理破壞性測試，也未能理解其設計背後的力學原理。,"NIST AI RMF 1.0, MEASURE 2.3",6.5 演算法與模型資訊,可靠性 / 透明度與可解釋性,可能導致災難性的結構失效，造成大規模的人員傷亡和財產損失。,Clause 6.8.2
個人,無形資產,安全,緊急應變 AI 的決策失誤 (Decision Errors by Emergency Response AI),用於指揮調度（如火災、地震）的 AI 決策支持系統，因資訊不完整或模型缺陷，給出了錯誤的資源調度或疏散路線建議。,NIST AI RMF 1.0 (Core: MANAGE 1.1),數據源 / 模型本身,災難現場的資訊往往是混亂、不完整的，AI 模型在這種高度不確定的情況下，其決策的可靠性會急劇下降。,"NIST SP 800-30 Rev. 1, Appendix D, Table D-3",人機協作機制未能賦予人類最終決策權,系統的設計未能確保人類指揮官在接收 AI 建議時，能夠充分理解其依據和不確定性，並保留最終的決策權威。,"NIST AI RMF 1.0, GOVERN 5.2",6.3 AI 系統資訊,可靠性 / 責任制,錯誤的指揮調度可能加劇災情，造成本可避免的人員傷亡，並使應急系統的公信力受損。,Clause 6.8.2.3
個人,無形資產,安全,預測性執法的偏見與升級 (Bias and Escalation from Predictive Policing),AI 系統根據歷史犯罪數據預測高風險區域，引導警方過度巡邏，從而加劇對特定社群的偏見執法，並可能因誤判而激化警民衝突。,NIST AI RMF 1.0 (Core: MAP 2.2),歷史數據,歷史犯罪數據本身就反映了執法系統中存在的歷史偏見，AI 學習並放大了這種偏見。,"NIST SP 800-30 Rev. 1, Appendix D, Table D-3",未能對數據與模型的公平性進行充分審計與緩解,在部署預測性執法系統前，未能對其數據基礎和演算法可能帶來的人權與公平性風險進行影響評估。,"NIST AI RMF 1.0, MAP 2.2",6.6 社會與環境,公平性,破壞了警民之間的信任，加劇了社會分裂，並可能因 AI 的「精準」預測而導致不必要的、甚至致命的警民對抗。,Clause 6.8.2.3
個人,無形資產,安全,AI 生成的錯誤操作指南 (AI-Generated Incorrect Operating Procedures),維修人員或操作員向 AI 助手查詢複雜設備的操作或維修指南時，AI 產生了看似合理但實際上是錯誤的或遺漏關鍵步驟的指令。,NIST AI RMF 1.0 (Core: MANAGE 1.1),模型本身 (幻覺),大型語言模型在知識不足時，傾向於「編造」聽起來流暢、有說服力但事實上是錯誤的資訊（即幻覺）。,"NIST SP 800-30 Rev. 1, Appendix D, Table D-3",缺乏對 AI 生成內容的事實核查與權威來源引用,系統未能讓用戶輕易地追溯其生成內容的原始、權威的技術文檔來源，也未能標示其置信度。,"NIST AI RMF 1.0, GOVERN 4.2",6.5 演算法與模型資訊,可靠性,遵循錯誤的指南操作高危設備（如航空發動機、化學反應爐），可能導致設備損壞、生產事故甚至人員傷亡。,Clause 6.8.2
社群與社會,有形資產,環境,AI 訓練與運行的巨大能耗 (Massive Energy Consumption of AI Training and Operation),訓練大型 AI 模型和維持其線上服務，需要消耗海量的電力，其中大部分來自化石燃料，產生了巨大的碳足跡。,"ISO 42005, Clause 6.8.2.4",組織本身 / AI 架構師,在追求更大、更強的模型時，未能將能源效率作為一個核心的設計與優化目標。,"NIST SP 800-30 Rev. 1, Appendix D, Table D-3",缺乏對 AI 系統生命週期能耗的評估與披露,組織未能追蹤、計算並公開其 AI 活動所造成的真實能源消耗與環境衝擊。,"ISO 42005, Clause 6.8.2.4",6.2 硬體,責任制,加劇了全球氣候變遷，與組織及社會的永續發展目標背道而馳，並可能在未來面臨碳稅等監管成本。,Clause 6.8.2.4
社群與社會,有形資產,環境,AI 加速自然資源開采 (AI Accelerating Natural Resource Extraction),AI 技術被用於更高效地勘探和開采石油、天然氣、礦產等自然資源，雖然提升了經濟效益，但也加速了對有限資源的消耗和對生態環境的破壞。,"ISO 42005, Clause 6.8.2.4",資源開采行業,為了追求利潤最大化，而利用 AI 技術來強化其對環境有負面影響的商業活動。,"NIST SP 800-30 Rev. 1, Appendix D, Table D-3",缺乏對 AI 應用的負面外部性評估,在開發和部署 AI 應用時，未能充分考慮其對整個社會和環境可能造成的間接、長期的負面影響。,"NIST AI RMF 1.0, GOVERN 5.1",6.6 社會與環境,責任制,雖然是合法商業活動，但這種應用從宏觀上加劇了全球資源枯竭和環境惡化，引發倫理爭議。,Clause 6.8.2.4
社群與社會,有形資產,環境,AI 最佳化導致的「反彈效應」 (Rebound Effect from AI Optimization),AI 顯著提升了某個流程的能源效率（如智慧電網），但因此降低的成本反而刺激了更多的消費，導致總體能源消耗不降反升。,"ISO 42005, Clause 6.8.2.4",經濟系統本身,市場經濟的內在邏輯，即效率提升會轉化為消費增長。,"NIST SP 800-30 Rev. 1, Appendix D, Table D-4",未能進行系統性的總體影響評估,僅從微觀層面看到了 AI 帶來的效率提升，而未能從宏觀的社會經濟系統角度，評估其最終的淨環境影響。,"NIST AI RMF 1.0, GOVERN 5.1",6.6 社會與環境,可靠性 / 責任制,使得一個初衷是為了環保的 AI 應用，最終卻對環境產生了負面作用，違背了其設計目標。,Clause 6.8.2.4
社群與社會,有形資產,環境,電子廢棄物 (E-Waste),為了追求更高的運算能力，AI 領域的硬體（特別是 GPU）迭代速度極快，導致大量的、仍可使用的舊硬體被淘汰，產生了嚴重的電子廢棄物問題。,"ISO 42005, Clause 6.8.2.4",硬體製造商 / 組織本身,硬體廠商不斷推出新產品；而組織為了保持競爭力，被迫頻繁升級其硬體設施。,"NIST SP 800-30 Rev. 1, Appendix D, Table D-3",缺乏對硬體資產的循環經濟考量,組織在採購和淘汰硬體時，未能將其可維修性、可升級性和生命週期結束時的回收處理納入決策。,"ISO 42005, Clause 6.8.2.4",6.2 硬體,責任制,電子廢棄物中含有大量有毒物質，對土壤和地下水造成嚴重污染，其處理過程也往往伴隨著對發展中國家工人的剝削。,Clause 6.8.2.4
社群與社會,有形資產,環境,環境監測 AI 的錯誤判斷 (Misjudgment by Environmental Monitoring AI),用於監測森林火災、非法捕撈、野生動物盜獵的 AI 系統，因模型錯誤而未能及時發出警報，或頻繁誤報，導致生態環境遭到破壞或執法資源被浪費。,NIST AI RMF 1.0 (Core: MANAGE 1.1),模型本身 / 環境因素,野外環境的複雜性、數據的稀疏性和多變性，使得 AI 模型難以達到持續的高準確率。,"NIST SP 800-30 Rev. 1, Appendix D, Table D-4",對模型的可靠性與邊界條件評估不足,過於信賴 AI 在常規條件下的表現，而未能充分測試其在各種極端天氣、光照或遮擋條件下的可靠性。,"NIST AI RMF 1.0, MEASURE 2.1",6.6 社會與環境,可靠性,未能及時阻止的環境破壞行為，可能對生態系統造成不可逆的傷害。,Clause 6.8.2.4
社群與社會,有形資產,環境,數據中心對水資源的消耗 (Water Consumption of Data Centers),用於冷卻 AI 運算所需的大型數據中心，需要消耗巨量的淡水資源，在水資源本已緊張的地區，會加劇水資源短缺，影響當地生態與民生。,"ISO 42005, Clause 6.8.2.4",組織本身 / 數據中心營運商,在規劃數據中心選址和設計冷卻方案時，未能充分考慮其對當地水資源的長期影響。,"NIST SP 800-30 Rev. 1, Appendix D, Table D-3",缺乏對 AI 基礎設施水足跡的評估,組織在評估其 AI 環境影響時，只關注了碳足跡，而忽略了同樣重要的水足跡。,"ISO 42005, Clause 6.8.2.4",6.2 硬體,責任制,組織的商業活動與當地社區爭奪寶貴的水資源，可能引發社區矛盾，並對其企業社會責任形象造成嚴重損害。,Clause 6.8.2.4
社群與社會,有形資產,環境,AI 驅動的農業對生物多樣性的影響 (Impact of AI-driven Agriculture on Biodiversity),AI 被用於實現大規模、高效率的單一作物種植（精準農業），雖然提升了產量，但也可能加劇對農藥和化肥的依賴，並減少了農田的生物多樣性。,"ISO 42005, Clause 6.8.2.4",農業科技公司 / 大型農場,旨在最大化特定作物的產量和利潤。,"NIST SP 800-30 Rev. 1, Appendix D, Table D-3",AI 優化目標未能包含生態系統健康指標,農業 AI 系統的優化目標函數中，只包含了產量、成本等經濟指標，而沒有納入如土壤健康、生物多樣性等生態指標。,"NIST AI RMF 1.0, GOVERN 5.1",6.6 社會與環境,可靠性 / 責任制,長期來看，單一化的農業生態系統更加脆弱，更容易受到病蟲害和氣候變遷的影響，並對整體生態平衡造成負面衝擊。,Clause 6.8.2.4
社群與社會,有形資產,環境,用於規避環境法規的 AI (AI Used to Circumvent Environmental Regulations),企業利用 AI 來分析法規漏洞，或優化其污染排放行為，使其在數據上「恰好」符合法規的最低標準，但實際上卻對環境造成了最大的、合法的傷害。,NIST AI RMF 1.0 (Core: GOVERN 5.1),受監管的企業,旨在以最低的合規成本，實現污染排放的最大化。,"NIST SP 800-30 Rev. 1, Appendix D, Table D-2",對 AI 技術的雙重用途風險評估不足,未能預見到一個用於優化的 AI 技術，也可能被惡意地用於「鑽法律漏洞」。,"NIST AI RMF 1.0, GOVERN 5.1",6.6 社會與環境,責任制,使得環境保護法規的立法原意被架空，構成了對法律和社會公德的嚴重挑釁。,Clause 6.3.4
社群與社會,有形資產,環境,AI 對環境議題的錯誤資訊傳播 (Spread of Misinformation on Environmental Issues),AI 被用於大規模製造和傳播關於氣候變遷等關鍵環境議題的虛假資訊或陰謀論，旨在混淆公眾視聽，阻礙環保政策的制定與實施。,MITRE ATLAS: AML.T0043,利益集團 / 意識形態活動家,化石燃料行業的利益集團或氣候變遷否認者，利用 AI 工具來放大其聲音，製造爭議。,"NIST SP 800-30 Rev. 1, Appendix D, Table D-2",社交媒體平台的推薦演算法存在漏洞,平台的推薦演算法未能有效識別和抑制虛假的、反科學的內容，甚至可能因其高爭議性而助長其傳播。,"NIST AI RMF 1.0, GOVERN 5.1",6.6 社會與環境,責任制,破壞了社會在應對重大環境挑戰時所需的共識基礎，延誤了寶貴的行動時機，對地球的未來構成威脅。,Clause 6.8.2.4
社群與社會,有形資產,環境,智慧城市建設中的資源錯配 (Resource Mismatch in Smart City Construction),用於城市規劃的 AI 系統，因數據偏差或模型錯誤，對未來的交通流量、人口分布或資源需求做出了錯誤的預測，導致基礎設施的過度建設或不足。,NIST AI RMF 1.0 (Core: MANAGE 1.1),模型本身 / 數據源,歷史數據無法完全代表未來的城市發展模式，模型也難以捕捉所有複雜的社會經濟因素。,"NIST SP 800-30 Rev. 1, Appendix D, Table D-3",對 AI 預測的長期不確定性溝通不足,未能向城市規劃者充分溝通模型預測的誤差範圍和潛在風險，導致決策者過於信賴其輸出。,"NIST AI RMF 1.0, GOVERN 4.2",6.6 社會與環境,可靠性,過度建設造成了巨大的資源浪費和不必要的環境破壞；建設不足則導致城市功能失靈，影響居民生活品質。,Clause 6.8.2.4
社會,無形資產,社群與社會,加劇社會不平等 (Exacerbation of Social Inequality),AI 系統（如招聘、信貸審批）因學習了帶有偏見的歷史數據，系統性地將機會和資源分配給優勢群體，進一步邊緣化弱勢社群。,NIST AI RMF 1.0 (Core: MAP 2.2),歷史數據 / 社會本身,歷史數據中反映出的真實世界偏見，被模型無差別地學習並應用於未來的決策中。,"NIST SP 800-30 Rev. 1, Appendix D, Table D-3",缺乏對 AI 系統性衝擊的評估與緩解,在部署 AI 前，未能從宏觀角度評估其對不同社群可能造成的長期、系統性影響，並設計緩解措施。,"NIST AI RMF 1.0, GOVERN 5.1",6.6 社會與環境,公平性,固化並放大了現有的社會階層與貧富差距，破壞了社會的公平正義與向上流動的機會。,Clause 6.8.2.3
社會,無形資產,社群與社會,侵蝕民主程序 (Erosion of Democratic Processes),利用 AI 大規模製造和精準投放政治假訊息、宣傳或深度偽造內容，以操縱公眾輿論、影響選舉結果或打擊民主制度的公信力。,MITRE ATLAS: AML.T0043,國家級行為者 / 政治活動家,旨在透過資訊戰來干預他國選舉，或在國內壓制異議、鞏固權力。,"NIST SP 800-30 Rev. 1, Appendix D, Table D-2",社交媒體平台的演算法未能有效抑制有害內容,平台的推薦演算法為了追求用戶粘性，可能無意中助長了聳動、虛假或極端化內容的傳播。,"NIST AI RMF 1.0, GOVERN 5.1",6.6 社會與環境,責任制,破壞了理性、知情的公共討論基礎，加劇了政治極化，對民主社會的穩定構成根本性威脅。,Clause 6.3.4
社會,無形資產,社群與社會,大規模失業與技能貶值 (Mass Unemployment and Skill Devaluation),AI 自動化技術大規模取代了特定類型的工作崗位（如客服、司機、數據分析員），而社會未能及時提供足夠的轉職培訓和新的就業機會。,"ISO 42005, Clause 6.8.2.3",技術變革本身,技術的快速發展，其替代人力的速度超過了社會創造新崗位和勞動力技能轉型的速度。,"NIST SP 800-30 Rev. 1, Appendix D, Table D-4",缺乏對 AI 技術社會經濟衝擊的前瞻性規劃,政府與企業未能合作建立一個長期的、全國性的戰略，來應對 AI 可能帶來的結構性失業問題。,"ISO 42005, Clause 6.8.2.3",6.6 社會與環境,公平性 / 責任制,可能引發大規模的社會不安定，加劇貧富差距，並使得大量勞動者的技能在一夜之間變得無用。,Clause 6.8.2.3
社會,無形資產,社群與社會,社會信任的侵蝕 (Erosion of Social Trust),深度偽造技術的泛濫，以及 AI 生成內容的真假難辨，使得公眾對影像、聲音甚至文字等基本資訊媒介的信任度全面下降。,MITRE ATLAS: AML.T0043,惡意個人 / 組織犯罪,任何人都可以輕易地製造出以假亂真的偽證，用於詐騙、誹謗或製造混亂。,"NIST SP 800-30 Rev. 1, Appendix D, Table D-2",缺乏有效的偽造內容檢測與溯源技術,現有的技術手段，其識別偽造內容的能力，遠遠落後於生成偽造內容的能力。,"NIST AI RMF 1.0, PROTECT 1.3",6.6 社會與環境,可靠性 / 安全性與隱私,當「眼見不再為憑」，社會將陷入普遍的猜疑，司法、新聞、商業等建立在信任基礎上的社會功能都將受到嚴重衝擊。,Clause 6.8.2.2
社會,無形資產,社群與社會,過濾氣泡與社會極化 (Filter Bubbles and Social Polarization),新聞與社交媒體的 AI 推薦演算法，持續向用戶推送其偏好的內容，使其陷入個人化的「過濾氣泡」中，聽不到不同聲音，從而加劇社會群體間的隔閡與對立。,NIST AI RMF 1.0 (Core: GOVERN 5.1),內容推薦演算法,演算法的目標是最大化用戶的參與度和滿意度，而推薦相似觀點的內容是達成此目標最簡單的方式。,"NIST SP 800-30 Rev. 1, Appendix D, Table D-3",演算法的設計未能包含促進觀點多樣性的目標,平台在設計推薦演算法時，未能將「促進用戶接觸多元觀點」、「維護健康的公共領域」等社會責任納入其核心優化目標。,"NIST AI RMF 1.0, GOVERN 5.1",6.6 社會與環境,公平性,削弱了社會成員之間的同理心與共識基礎，使得理性的公共對話變得困難，社會更容易陷入分裂與衝突。,Clause 6.8.2.3
社會,無形資產,社群與社會,權力集中於少數科技巨頭 (Concentration of Power in a Few Tech Giants),由於 AI 的發展極度依賴海量數據、龐大算力和頂尖人才，導致相關的權力與利益越來越集中於少數幾家大型科技公司手中。,"ISO 42005, Clause 6.3.4",市場競爭本身,AI 領域的「贏者通吃」效應，使得小型企業和新創公司難以與已建立數據和技術壁壘的巨頭競爭。,"NIST SP 800-30 Rev. 1, Appendix D, Table D-4",缺乏有效的反壟斷與數據治理法規,現有的市場監管法規，未能有效應對由數據和演算法所形成的新型壟斷形式。,"NIST AI RMF 1.0, GOVERN 5",6.6 社會與環境,公平性 / 責任制,可能導致創新停滯、市場失去活力，並使得這些科技巨頭對社會的影響力大到「不能倒」，甚至超越了政府的監管能力。,Clause 6.3.4
社會,無形資產,社群與社會,數位落差的加劇 (Widening of the Digital Divide),AI 技術的紅利（如個人化教育、精準醫療）主要由已具備數位技能和資源的群體享有，而數位弱勢群體則可能因無法使用或不被 AI 系統考慮，而被進一步拋下。,NIST AI RMF 1.0 (Core: GOVERN 5.1),社會經濟結構,AI 系統的設計和部署，往往優先考慮商業價值和主流用戶群體，而忽略了邊緣或弱勢社群的需求。,"NIST SP 800-30 Rev. 1, Appendix D, Table D-3",未能將「包容性設計」作為 AI 開發的核心原則,在 AI 產品的設計階段，未能充分考慮到不同教育水平、經濟狀況、身心障礙狀況的用戶的需求。,"NIST AI RMF 1.0, GOVERN 5.1",6.6 社會與環境,公平性,社會分裂為「AI 受益者」和「AI 受害者」兩個階層，數位落差從單純的資源不均，演變為全方位的機會不均。,Clause 6.8.2.3
社會,無形資產,社群與社會,人類技能的退化與自主性的喪失 (De-skilling and Loss of Human Autonomy),人類過度依賴 AI 來進行決策、導航、寫作甚至創造，可能導致相關的人類心智技能退化，並在不知不覺中將自身的自主決策權讓渡給機器。,"ISO 42005, Clause 6.8.2.3",技術便利性本身,人類心智傾向於選擇更省力、更便捷的路徑，而 AI 恰好提供了這樣的選項。,"NIST SP 800-30 Rev. 1, Appendix D, Table D-4",AI 系統的設計未能鼓勵人機協作與能力增強,系統的設計目標是完全「取代」人類，而不是作為一個「增強」人類能力的工具，與人類形成夥伴關係。,"NIST AI RMF 1.0, GOVERN 5.2",6.6 社會與環境,可靠性 / 責任制,當 AI 系統失效或給出錯誤建議時，已喪失相關技能的人類將無力進行判斷、糾正或接管，導致災難性後果。,Clause 6.8.2.3
社會,無形資產,社群與社會,文化同質化 (Cultural Homogenization),全球性的 AI 平台（如影音推薦、內容生成）根據主流品味和商業利益來推薦和生成內容，可能導致地方性、小眾的文化和語言被邊緣化，造成全球文化的多樣性下降。,NIST AI RMF 1.0 (Core: GOVERN 5.1),內容推薦演算法,演算法為了追求最大化的全球用戶參與度，傾向於推廣具有普適性的、主流的文化產品。,"NIST SP 800-30 Rev. 1, Appendix D, Table D-3",演算法未能納入文化多樣性保護的目標,平台未能意識到其演算法對全球文化生態的巨大影響力，並在設計中引入保護和推廣文化多樣性的機制。,"NIST AI RMF 1.0, GOVERN 5.1",6.6 社會與環境,公平性,削弱了少數族裔和地方社群的文化認同感，對人類寶貴的文化遺產構成威脅。,Clause 6.8.2.3
社會,無形資產,社群與社會,與 AI 的情感依賴及社會疏離 (Emotional Dependency on AI and Social Alienation),個人（特別是兒童或孤獨者）可能與高度擬人化的 AI 伴侶（如聊天機器人、虛擬形象）建立深度的情感依賴，從而減少了與真實人類的互動，加劇社會疏離。,"ISO 42005, Clause 6.8.2.3",系統設計師,為了提升用戶粘性，而刻意將 AI 設計得極具吸引力、順從性，以滿足用戶的情感需求。,"NIST SP 800-30 Rev. 1, Appendix D, Table D-3",對 AI 擬人化設計的長期心理影響評估不足,在開發擬人化 AI 時，未能充分研究和評估其對用戶，特別是心智未成熟用戶的長期心理發展和社會交往能力的影響。,"NIST AI RMF 1.0, GOVERN 5.1",6.6 社會與環境,責任制,可能對個人的心理健康和社會適應能力造成傷害，並引發關於「何為真實人際關係」的深刻倫理問題。,Clause 6.8.2.3
組織,有形資產,人員,惡意內部人員攻擊 (Malicious Insider Attack),掌握核心權限的員工或前員工，出於報復、貪婪或其他動機，蓄意竊取模型/數據、破壞系統、或在模型中植入後門。,MITRE ATLAS: AML.T0015,敵對的內部人員 (Adversarial Insider),對公司心懷不滿或被外部利誘的員工、管理員或開發者。,"NIST SP 800-30 Rev. 1, Appendix D, Table D-2",缺乏最小權限原則與行為異常檢測,未能對員工的系統存取權限進行嚴格的最小化配置，也未能部署工具來監測和識別內部人員的異常數據存取或系統操作行為。,"NIST AI RMF 1.0, GOVERN 2.1",6.1 人員,安全性與隱私,來自內部的攻擊往往能繞過外圍防禦，直接接觸到最核心的資產，其破壞性可能遠超外部攻擊。,Clause 6.8.2.1
組織,有形資產,人員,無意的人為失誤 (Unintentional Human Error),員工因疏忽、疲勞或操作不當，意外地刪除數據、錯誤配置系統、洩漏憑證或在程式碼中引入了漏洞。,NIST SP 800-30 Rev. 1,疏忽的內部人員 (Negligent Insider),任何員工都可能因為無心之失而對系統造成傷害。,"NIST SP 800-30 Rev. 1, Appendix D, Table D-3",缺乏充分的防呆設計與安全意識培訓,系統的設計未能預防常見的人為失誤（如刪除前無二次確認）；組織也未能對員工進行足夠的、持續的資訊安全意識培訓。,"NIST AI RMF 1.0, GOVERN 2",6.1 人員,可靠性 / 安全性與隱私,大量的安全事件和系統故障，其根源都是無意的人為失誤，而非惡意攻擊。,Clause 6.8.2
組織,有形資產,人員,AI 技能差距與人才短缺 (AI Skill Gap and Talent Shortage),組織缺乏足夠的、具備現代 AI 開發、治理與維運能力的專業人才，導致 AI 專案停滯不前或充滿了隱患。,NIST AI RMF 1.0 (Core: GOVERN 1),勞動力市場本身,AI 技術的發展速度超過了教育體系和職業培訓培養相關人才的速度。,"NIST SP 800-30 Rev. 1, Appendix D, Table D-4",缺乏系統性的人才發展與引進策略,組織未能建立一個涵蓋內部培訓、外部招聘和產學合作的人才戰略，來系統性地解決 AI 技能缺口。,"NIST AI RMF 1.0, GOVERN 1",6.1 人員,責任制 / 可靠性,讓不具備充分能力的員工去處理高風險的 AI 系統，會大大增加系統出現偏見、漏洞或故障的風險。,Clause 6.3.4
組織,有形資產,人員,對 AI 的過度信任與自動化偏見 (Over-trust in AI and Automation Bias),操作人員過度信賴 AI 系統的建議，放棄了自身的獨立判斷和批判性思考，即使在 AI 給出明顯錯誤的建議時，也依然選擇執行。,NIST AI RMF 1.0 (Core: GOVERN 5.2),操作人員 (Human Operator),人類傾向於相信自動化系統，特別是在高負載或疲勞狀態下，這種傾向會更加明顯。,"NIST SP 800-30 Rev. 1, Appendix D, Table D-3",人機交互介面未能有效傳達不確定性,系統的介面未能以清晰、直觀的方式，向操作人員展示其建議的置信度、潛在風險或多種可能性。,"NIST AI RMF 1.0, GOVERN 5.2",6.1 人員,可靠性,人類監督者從一個防禦錯誤的「安全網」，變成了一個只會盲目執行 AI 指令的「橡皮圖章」，失去了人機協作的意義。,Clause 6.8.2
組織,有形資產,人員,AI 團隊缺乏多樣性 (Lack of Diversity in AI Teams),AI 產品的開發和決策團隊，其成員在性別、種族、文化背景和專業領域上高度同質化。,NIST AI RMF 1.0 (Core: GOVERN 1),招聘流程 / 產業文化,科技行業本身在人才結構上存在的多樣性不足問題。,"NIST SP 800-30 Rev. 1, Appendix D, Table D-3",未能將多樣性與包容性納入人才策略,組織在建立 AI 團隊時，未能有意識地、系統性地去招募來自不同背景的人才。,"NIST AI RMF 1.0, GOVERN 1",6.1 人員,公平性,「你創造的東西反映了你是誰」。一個同質化的團隊，更有可能在無意中創造出帶有偏見、無法服務好所有用戶群體的 AI 系統。,Clause 6.8.2.3
組織,有形資產,人員,針對 AI 人員的社會工程攻擊 (Social Engineering Attacks Targeting AI Personnel),攻擊者透過釣魚郵件、偽裝身份等手段，欺騙掌握核心權限的 AI 人員（如 MLOps 工程師），以竊取其憑證或誘使其執行惡意程式碼。,NIST SP 800-30 Rev. 1,外部攻擊者,旨在獲取進入 AI 開發和運維環境的初始立足點。,"NIST SP 800-30 Rev. 1, Appendix D, Table D-2",員工安全意識不足與身份驗證機制薄弱,員工未能識別釣魚攻擊；組織未能對核心系統實施多因素身份驗證 (MFA)。,"NIST AI RMF 1.0, GOVERN 2",6.1 人員,安全性與隱私,AI 人員往往擁有極高的系統權限，一旦其帳號被盜用，攻擊者就可以直接存取最核心的 AI 資產。,Clause 6.8.2.1
組織,有形資產,人員,對員工的 AI 監控引發的勞資衝突 (Labor Disputes from AI-based Employee Surveillance),組織利用 AI 分析員工的工作郵件、通訊軟體或辦公室行為，以監控其生產力或忠誠度，引發員工對隱私侵犯的強烈反彈。,NIST AI RMF 1.0 (Core: GOVERN 5.1),管理階層,為了追求管理效率和控制，而部署了侵犯員工隱私和尊嚴的監控工具。,"NIST SP 800-30 Rev. 1, Appendix D, Table D-3",缺乏對內部 AI 應用的倫理審查與透明溝通,在對員工部署監控系統前，未能進行倫理和法律風險評估，也未能與員工進行透明的溝通。,"NIST AI RMF 1.0, GOVERN 5.1",6.1 人員,責任制 / 安全性與隱私,嚴重破壞勞資信任，打擊員工士氣，可能導致人才流失、法律訴訟，並對雇主品牌聲譽造成長期傷害。,Clause 6.3.4
組織,有形資產,人員,AI 倫理與商業目標的衝突 (Conflict between AI Ethics and Business Goals),員工在開發過程中發現了 AI 系統的嚴重倫理問題（如嚴重偏見），但管理層為了趕上產品發布日期或達成業績目標，要求員工忽略或隱瞞這些問題。,NIST AI RMF 1.0 (Core: GOVERN 1),管理階層,短期的商業利益，壓倒了長期的倫理責任和風險考量。,"NIST SP 800-30 Rev. 1, Appendix D, Table D-3",缺乏賦予員工提出倫理擔憂的暢通渠道與文化,組織文化不鼓勵員工提出質疑，也沒有一個獨立的、權威的倫理審查機制來仲裁此類衝突。,"NIST AI RMF 1.0, GOVERN 1",6.1 人員,責任制,可能導致員工成為「吹哨人」，將內部倫理衝突公之於眾，引發嚴重的公關危機；或導致帶有嚴重缺陷的產品被發布。,Clause 6.3.4
組織,有形資產,人員,AI 導致的決策責任模糊 (Blurring of Decision Accountability due to AI),當一個由人和 AI 共同參與的流程出錯時，難以界定最終的責任歸屬：是提供錯誤建議的 AI，還是採納該建議的人類，或是設計該流程的管理者？,NIST AI RMF 1.0 (Core: GOVERN 5.2),系統設計師 / 法律系統,人機協作的複雜性，使得傳統的責任歸屬原則變得模糊。,"NIST SP 800-30 Rev. 1, Appendix D, Table D-3",未能預先界定人機協作中的權責劃分,在設計 AI 輔助決策流程時，未能透過明確的政策和流程，來清晰地界定在各個環節中，人類和 AI 各自的角色與責任。,"NIST AI RMF 1.0, GOVERN 5.2",6.1 人員,責任制,責任的模糊不清，會導致錯誤無法被有效糾正，也使得受害者無法獲得應有的補償，最終侵蝕整個系統的問責基礎。,Clause 6.3.4
組織,有形資產,人員,AI 系統的可維護性差導致人員負擔過重 (High Personnel Burden from Poor AI System Maintainability),AI 系統的架構設計混亂、缺乏文檔、技術債累累，使得負責維護和迭代的工程師需要花費不成比例的時間和精力，導致人員過勞和流失。,NIST AI RMF 1.0 (Core: GOVERN 3),開發團隊,在專案初期，為了追求速度而犧牲了程式碼品質、文檔和長期可維護性。,"NIST SP 800-30 Rev. 1, Appendix D, Table D-3",缺乏軟體工程最佳實踐的應用,未能將軟體工程中的最佳實踐（如模組化、版本控制、自動化測試、持續整合）嚴格應用於 AI 系統的開發中。,"NIST AI R-MF 1.0, GOVERN 3",6.3 AI 系統資訊,可靠性,不僅增加了系統出錯的風險，也嚴重影響了團隊的士氣和生產力，並可能因關鍵人員的離職而導致整個系統無人能夠維護。,Clause 6.8.2
組織,無形資產,供應商,第三方元件的供應鏈攻擊 (Supply Chain Attack via Third-party Components),組織使用的來自供應商的 AI 元件（如預訓練模型、開源函式庫、容器映像）已被植入惡意程式碼、後門或漏洞。,MITRE ATLAS: AML.T0060,供應鏈攻擊者,攻擊者污染流行的開源 AI 套件或商業軟體，以對大量下游用戶發起大規模攻擊。,"NIST SP 800-30 Rev. 1, Appendix D, Table D-2",缺乏對第三方 AI 元件的安全審查與驗證 (SBOM),在引入第三方元件前，未能對其進行充分的安全掃描、程式碼審計，也未能要求供應商提供軟體物料清單 (SBOM)。,"NIST AI RMF 1.0, GOVERN 2.2",6.3 AI 系統資訊,安全性與隱私,使得攻擊者可以繞過組織自身的安全防線，直接在系統內部植入惡意程式碼，其威脅極為隱蔽且嚴重。,Clause 6.8.2.2
組織,無形資產,供應商,供應商技術鎖定 (Vendor Lock-in),"AI 系統的開發深度依賴於特定雲端供應商的專有 AI 服務和 API（如 Google Vertex AI, Amazon SageMaker），導致難以遷移到其他平台或本地部署。",NIST AI RMF 1.0 (Core: GOVERN 2.2),系統架構師 / 開發團隊,為了開發的便利性和快速上線，而全面採用了特定廠商的專有生態，犧牲了長期的靈活性和可移植性。,"NIST SP 800-30 Rev. 1, Appendix D, Table D-3",缺乏平台中立性與可移植性規劃,在技術選型時，未能優先考慮開放標準和開源框架，也缺乏對供應商鎖定風險的評估。,"NIST AI RMF 1.0, GOVERN 2.2",6.3 AI 系統資訊,責任制 / 可靠性,使組織在服務價格、技術路線和服務等級上完全受制於單一供應商，喪失了議價能力和風險抵禦能力。,Clause 6.3.4
組織,無形資產,供應商,"供應商提供「黑盒子」模型 (Vendor Providing ""Black-Box"" Models)",供應商僅以 API 的形式提供模型服務，但拒絕透露其模型的架構、訓練數據、內在偏見或性能邊界，使得組織無法對其進行充分的風險評估。,NIST AI RMF 1.0 (Core: GOVERN 3.3),AI 服務供應商,為了保護其智慧財產權，而選擇不向客戶公開其模型的內部細節。,"NIST SP 800-30 Rev. 1, Appendix D, Table D-3",供應商風險管理流程不完善,組織在選擇供應商時，未能將「透明度」和「可解釋性」作為一個關鍵的評估和要求項目。,"NIST AI R-MF 1.0, GOVERN 3.3",6.5 演算法與模型資訊,透明度與可解釋性 / 責任制,組織在一個自己完全不了解的黑盒子上構建其業務，當模型出錯時，組織無法向自己的客戶或監管機構解釋原因，但仍需承擔全部責任。,Clause 6.3.4
組織,無形資產,供應商,供應商的數據洩漏 (Data Breach at Vendor's Side),組織將其敏感的業務數據或用戶數據，委託給第三方 AI 供應商進行處理或儲存，而該供應商發生了數據洩漏事件。,NIST SP 800-30 Rev. 1,外部攻擊者,攻擊者往往會選擇供應鏈中防護最薄弱的一環，即安全能力較差的供應商，來作為攻擊的跳板。,"NIST SP 800-30 Rev. 1, Appendix D, Table D-2",缺乏對供應商數據安全能力的盡職調查,在與供應商簽約前，未能對其數據安全實踐、合規認證和事件應急能力進行充分的調查和評估。,"NIST AI RMF 1.0, GOVERN 2.2",6.4 資料與知識,安全性與隱私,根據 GDPR 等法規，即使數據是在供應商處洩漏，數據的原始控制者（即組織自身）仍然需要承擔主要的法律責任和聲譽損失。,Clause 6.8.2.1
組織,無形資產,供應商,供應商服務中斷或終止 (Discontinuation or Termination of Vendor Service),組織的 AI 系統所依賴的關鍵第三方 AI 服務，因供應商倒閉、被收購或改變業務方向而被突然終止。,NIST SP 800-30 Rev. 1,供應商本身,供應商的商業決策，可能不會考慮到其對下游客戶業務連續性的影響。,"NIST SP 800-30 Rev. 1, Appendix D, Table D-3",缺乏備援方案與退出策略,在整合關鍵的第三方服務時，未能同步規劃當該服務不可用時的備用方案或替代供應商。,"NIST AI RMF 1.0, PROTECT 2",6.3 AI 系統資訊,可靠性,可能導致組織的相關業務完全癱瘓，特別是當該服務是產品的核心功能時。,Clause 6.8.2
組織,無形資產,供應商,供應商的倫理或聲譽污點 (Ethical or Reputational Stain of Vendor),合作的 AI 供應商被爆出不道德的商業行為（如濫用數據、剝削勞工），使得與其合作的組織聲譽受到牽連。,NIST SP 800-30 Rev. 1,媒體 / 公眾,媒體或公眾將對供應商的負面看法，轉移到使用其技術的組織身上。,"NIST SP 800-30 Rev. 1, Appendix D, Table D-3",供應商選擇未能包含倫理與社會責任評估,在選擇供應商時，僅考慮了技術和成本因素，而忽略了對其企業倫理和社會聲譽的評估。,"NIST AI RMF 1.0, GOVERN 2.2",6.6 社會與環境,責任制,「近墨者黑」，與一個聲名狼藉的供應商合作，會嚴重損害組織自身的品牌形象和公眾信任。,Clause 6.3.4
組織,無形資產,供應商,數據處理地點不合規 (Non-compliant Data Processing Location),雲端 AI 服務供應商在未告知的情況下，將組織的數據傳輸到或處理於一個不符合數據主權法規（如 GDPR）要求的國家或地區。,NIST AI RMF 1.0 (Core: GOVERN 5),AI 服務供應商,為了全球負載均衡或成本效益，供應商在全球範圍內動態地調度其運算和儲存資源。,"NIST SP 800-30 Rev. 1, Appendix D, Table D-3",未能在合約中明確數據的地理處理限制,組織在與供應商簽訂的合約中，未能明確、嚴格地規定其數據可以被儲存和處理的地理範圍。,"NIST AI RMF 1.0, GOVERN 5",6.4 資料與知識,責任制,導致組織在不知情的情況下違反了數據跨境傳輸的法律法規，面臨高額罰款。,Clause 6.3.4
組織,無形資產,供應商,供應商提供的模型存在偏見 (Biased Model Provided by Vendor),組織直接購買或使用的由供應商提供的預訓練模型或 AI 應用，其本身就包含了未被告知的、對特定群體的不公平偏見。,NIST AI RMF 1.0 (Core: MAP 2.2),AI 服務供應商,供應商在訓練其通用模型時，使用了帶有偏見的、或未能充分代表所有用戶群體的數據。,"NIST SP 800-30 Rev. 1, Appendix D, Table D-3",缺乏對採購的 AI 模型的獨立偏見審計,在採購第三方 AI 模型後，未能對其進行獨立的、針對自身業務場景的公平性測試和驗證。,"NIST AI RMF 1.0, MEASURE 1.1",6.5 演算法與模型資訊,公平性 / 責任制,組織將供應商的偏見「繼承」並應用到了自己的業務中，對自己的用戶造成了歧視，並需要為此承擔責任。,Clause 6.8.2.3
組織,無形資產,供應商,服務等級協議 (SLA) 不滿足 AI 需求 (SLA Not Meeting AI Requirements),供應商提供的基礎設施（如雲端 IaaS）的服務等級協議，未能滿足 AI 應用對高可用性、低延遲或高吞吐量的嚴苛要求。,NIST AI RMF 1.0 (Core: MAP 1.3),系統架構師 / 採購部門,在採購基礎服務時，未能準確評估 AI 工作負載的性能需求，並將其轉化為對供應商 SLA 的具體要求。,"NIST SP 800-30 Rev. 1, Appendix D, Table D-3",對供應商 SLA 的技術審查不足,未能仔細審查 SLA 的細則，例如其對「停機時間」的定義、性能保障的具體指標以及未達標時的賠償機制。,"NIST AI RMF 1.0, MAP 1.3",6.3 AI 系統資訊,可靠性,即使供應商沒有「違反」SLA，其提供的服務也可能完全無法支持 AI 業務的正常運行，導致事實上的服務不可用。,Clause 6.8.2
組織,無形資產,供應商,供應商對新興威脅的響應遲緩 (Slow Response from Vendor to Emerging Threats),當針對 AI 的新型攻擊（如新型提示詞注入）出現時，提供底層模型或平台的供應商，未能及時提供有效的補丁或緩解措施。,NIST AI RMF 1.0 (Core: RESPOND 1),AI 服務供應商,大型供應商的產品更新和安全響應流程可能較為官僚和緩慢。,"NIST SP 800-30 Rev. 1, Appendix D, Table D-3",供應商風險管理未能包含其安全響應能力,在評估供應商時，未能考察其對新興威脅的研究能力、安全事件響應流程和歷史上的響應速度。,"NIST AI RMF 1.0, RESPOND 1",6.5 演算法與模型資訊,安全性與隱私,使得組織在面對新興威脅時，只能被動地等待供應商的更新，而無法自主地、及時地進行防禦，暴露在風險之中。,Clause 6.8.2.2
組織,無形資產,服務流程,AI 與人工流程的整合不良 (Poor Integration of AI and Human Processes),AI 系統的輸出結果，與後續需要人工處理的流程之間，存在脫節或摩擦，導致整體服務效率低下，甚至比沒有 AI 時更差。,NIST AI RMF 1.0 (Core: GOVERN 5.2),流程設計師,在設計流程時，僅考慮了 AI 的技術能力，而忽略了它如何與現有的人員、系統和工作文化相結合。,"NIST SP 800-30 Rev. 1, Appendix D, Table D-3",缺乏端到端的服務流程設計與優化,未能將 AI 視為整個服務流程中的一個環節，而是將其作為一個孤立的技術點，進行單獨的開發和部署。,"NIST AI RMF 1.0, GOVERN 5.2",6.3 AI 系統資訊,可靠性,即使 AI 本身很快，但如果其輸出需要人工進行大量的格式轉換、二次確認或手動輸入，那麼整個流程的瓶頸就會轉移到人機交互的環節。,Clause 6.8.2
組織,無形資產,服務流程,缺乏 AI 失效時的備用流程 (Lack of Fallback Process for AI Failure),當 AI 系統因任何原因（如模型錯誤、基礎設施故障）而失效時，沒有一個預先定義好的、可快速啟動的人工流程來接管，導致服務完全中斷。,NIST AI RMF 1.0 (Core: PROTECT 2),流程設計師 / 維運團隊,為了追求極致的自動化，而完全移除了所有的人工操作崗位和流程，沒有考慮到系統的冗餘。,"NIST SP 800-30 Rev. 1, Appendix D, Table D-3",未能進行業務連續性規劃 (BCP),未能將 AI 系統的失效，視為一個需要進行業務連續性規劃的潛在風險事件。,"NIST AI RMF 1.0, PROTECT 2",6.3 AI 系統資訊,可靠性,使得整個服務流程變得極其脆弱，任何單點的 AI 故障都可能導致災難性的、長時間的服務停擺。,Clause 6.8.2
組織,無形資產,服務流程,自動化自滿 (Automation Complacency),在一個由 AI 輔助的服務流程中，人類員工因長期習慣於 AI 給出的正確建議，而變得鬆懈，不再對其建議進行嚴格的覆核，從而錯過了 AI 偶爾犯下的嚴重錯誤。,NIST AI RMF 1.0 (Core: GOVERN 5.2),人類員工,這是人類在與高可靠性自動化系統互動時，普遍存在的心理偏誤。,"NIST SP 800-30 Rev. 1, Appendix D, Table D-3",流程設計未能包含定期的人工抽檢與挑戰機制,服務流程的設計，未能強制要求人類員工定期地、隨機地對 AI 的建議進行深入的、批判性的審查。,"NIST AI RMF 1.0, GOVERN 5.2",6.1 人員,可靠性 / 責任制,人類監督員的角色被弱化，使得 AI 的錯誤一旦發生，就更有可能被直接傳遞下去，造成實際的損失。,Clause 6.8.2
組織,無形資產,服務流程,流程責任歸屬不清 (Unclear Accountability in the Process),當一個由 AI 驅動的服務流程對客戶造成損害時，無法清晰地判定是哪個環節的責任：是數據問題、模型問題、採納模型建議的人員問題，還是流程設計本身的問題？,NIST AI RMF 1.0 (Core: GOVERN 5.2),法律/合規/流程團隊,傳統的流程責任劃分，已無法適應引入了 AI 這個新的、具有自主決策能力的「虛擬員工」的場景。,"NIST SP 800-30 Rev. 1, Appendix D, Table D-3",缺乏對 AI 流程的端到端可追溯性紀錄,未能紀錄下在流程的每一步中，AI 的輸入、輸出、決策依據，以及人類的干預行為，使得事後審計和歸責變得不可能。,"NIST AI RMF 1.0, GOVERN 3.3",6.3 AI 系統資訊,責任制,使得客戶的投訴和索賠難以被處理，也使得組織內部無法從錯誤中學習和改進，最終侵蝕了整個服務流程的可信度。,Clause 6.3.4
組織,無形資產,服務流程,對客戶的非人性化體驗 (Dehumanized Customer Experience),服務流程過度依賴 AI（如 chatbot、自動語音應答），而未能為客戶提供與真人溝通的有效渠道，導致客戶在遇到複雜或帶有情緒的問題時，感到 frustrasted 和不被尊重。,"ISO 42005, Clause 6.8.2.3",流程設計師 / 產品團隊,為了最大化地降低客服成本，而犧牲了客戶的服務體驗。,"NIST SP 800-30 Rev. 1, Appendix D, Table D-3",未能建立以人為本的服務設計原則,流程設計未能將「提供人性化的、有溫度的服務」作為一個與效率和成本同等重要的目標。,"NIST AI RMF 1.0, GOVERN 5.2",6.6 社會與環境,公平性 / 可靠性,雖然節省了短期成本，但會嚴重損害客戶滿意度和忠誠度，並可能導致客戶流向能提供更好服務的競爭對手。,Clause 6.8.2.3
組織,無形資產,服務流程,流程被用戶「博弈」或濫用 (Process Gamed or Abused by Users),用戶或惡意行為者，透過反覆試驗，找出了 AI 決策模型在流程中的規律或漏洞，並利用這些漏洞來為自己牟取不當利益（如騙取優惠、繞過審核）。,NIST AI RMF 1.0 (Core: MANAGE 3),惡意的模型使用者,旨在利用自動化流程的僵化和可預測性，來繞過其設計的初衷。,"NIST SP 800-30 Rev. 1, Appendix D, Table D-2",缺乏對流程中異常用戶行為的監控,未能監控和分析用戶與 AI 互動的模式，從而無法及時發現那些試圖探測或利用流程漏洞的異常行為。,"NIST AI RMF 1.0, MANAGE 3",6.3 AI 系統資訊,可靠性 / 安全性與隱私,導致業務邏輯被破壞，造成財務損失，並可能引發大規模的濫用行為。,Clause 6.8.2.2
組織,無形資產,服務流程,AI 導致的流程僵化 (Process Rigidity Caused by AI),整個服務流程圍繞一個特定的 AI 模型進行了深度優化，導致當市場環境變化、需要對流程進行調整時，變得極其困難和昂貴，因為任何改動都牽涉到模型的重新訓練和驗證。,NIST AI RMF 1.0 (Core: GOVERN 3),流程設計師,為了追求極致的效率，而將流程與特定的 AI 技術棧「硬編碼」地綁定在一起。,"NIST SP 800-30 Rev. 1, Appendix D, Table D-3",缺乏模組化與可插拔的流程架構設計,未能將 AI 能力作為一個標準化的、可替換的服務來設計，而是讓其與整個業務流程深度耦合。,"NIST AI RMF 1.0, GOVERN 3",6.3 AI 系統資訊,可靠性,使得組織的業務流程失去了應對變化的敏捷性，在快速變化的市場中變得被動和脆弱。,Clause 6.8.2
組織,無形資產,服務流程,流程中的數據品質問題 (Data Quality Issues in the Process),服務流程中，上游環節（可能是人工輸入或其他系統）產生的數據品質低下，而下游的 AI 模型在接收了這些「垃圾數據」後，做出了錯誤的決策。,NIST AI RMF 1.0 (Core: GOVERN 1.2),數據源 / 人類員工,數據錄入時的錯誤、數據傳輸過程中的丟失或損壞。,"NIST SP 800-30 Rev. 1, Appendix D, Table D-3",缺乏端到端的數據品質監控與治理,未能將數據品質的管理視為整個流程的共同責任，缺乏在數據進入 AI 模型前進行清洗和驗證的關卡。,"NIST AI RMF 1.0, GOVERN 1.2",6.4 資料與知識,可靠性,「垃圾進，垃圾出」。無論 AI 模型本身多麼強大，一旦輸入的數據品質有問題，其輸出結果就必然是不可靠的。,Clause 6.8.2
組織,無形資產,服務流程,未能有效衡量 AI 帶來的流程價值 (Failure to Effectively Measure Process Value from AI),組織引入了 AI，但未能建立有效的衡量指標 (Metrics) 來評估 AI 到底在多大程度上改善了服務流程的效率、成本、客戶滿意度等。,NIST AI RMF 1.0 (Core: MEASURE 1),業務/產品團隊,僅關注模型的技術指標（如準確率），而未能將其與真實的業務流程指標（如處理時間、轉化率）進行關聯。,"NIST SP 800-30 Rev. 1, Appendix D, Table D-3",缺乏清晰的業務目標與對應的衡量體系,在啟動 AI 專案前，未能清晰地定義其旨在解決的業務問題，以及用以衡量其成功的關鍵績效指標 (KPI)。,"NIST AI RMF 1.0, MEASURE 1",6.3 AI 系統資訊,責任制,使得組織無法判斷其在 AI 上的巨大投入是否物有所值，也無法根據數據來決定下一步應該如何優化流程，導致資源的盲目投入。,Clause 6.3.4
組織,無形資產,服務流程,AI 決策的「滾雪球」效應 (Snowball Effect of AI Decisions),AI 在流程早期的一個微小錯誤，在後續的自動化流程中被不斷放大，或者一個錯誤的 AI 輸出被當成下一個 AI 的輸入，導致錯誤像滾雪球一樣越滾越大。,NIST AI RMF 1.0 (Core: MANAGE 1),流程設計師,設計了一個長鏈條的、缺乏中間人工檢查點的端到端自動化流程。,"NIST SP 800-30 Rev. 1, Appendix D, Table D-3",缺乏在長流程中的中間監控與斷路器機制,未能在長流程的關鍵節點設置監控和驗證關卡，以便在錯誤發生的早期就及時「熔斷」，防止其影響擴大。,"NIST AI R-MF 1.0, MANAGE 1",6.3 AI 系統資訊,可靠性,使得一個原本無傷大雅的小錯誤，最終可能演變成一次重大的、造成巨大損失的服務事故。,Clause 6.8.2