#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
å¢å¼·ç‰ˆæ–‡æœ¬åˆ†é¡ç¤ºä¾‹ç¨‹å¼ v2.0
ä½¿ç”¨é å…ˆè¨ˆç®—çš„ embeddings æå‡ç›¸ä¼¼åº¦æ¯”å°çš„æº–ç¢ºæ€§å’Œæ•ˆèƒ½
"""

from text_classifier import TextClassifier, print_classification_result
from enhanced_similarity_analyzer import EnhancedSimilarityAnalyzer
import pandas as pd
import time

def enhanced_classify_and_compare_v2(input_text, csv_path='RA_data.csv'):
    """
    å¢å¼·ç‰ˆåˆ†é¡åŠŸèƒ½ v2.0ï¼šä½¿ç”¨é å…ˆè¨ˆç®—çš„ embeddings
    Args:
        input_text: è¼¸å…¥çš„è³‡ç”¢åç¨±
        csv_path: CSV è³‡æ–™æª”æ¡ˆè·¯å¾‘
    """
    print("="*80)
    print(f"ğŸš€ æ­£åœ¨åˆ†æè³‡ç”¢åç¨±: {input_text}")
    print("="*80)
    
    start_time = time.time()
    
    # åˆå§‹åŒ–åˆ†é¡å™¨å’Œå¢å¼·ç‰ˆç›¸ä¼¼åº¦åˆ†æå™¨
    classifier = TextClassifier(csv_path)
    enhanced_analyzer = EnhancedSimilarityAnalyzer(csv_path)
    
    # åˆå§‹åŒ–å¢å¼·ç‰ˆåˆ†æå™¨ï¼ˆè¼‰å…¥æˆ–å»ºç«‹ embeddingsï¼‰
    print("ğŸ”§ æ­£åœ¨åˆå§‹åŒ–å¢å¼·ç‰ˆç›¸ä¼¼åº¦åˆ†æç³»çµ±...")
    if not enhanced_analyzer.initialize():
        print("âŒ å¢å¼·ç‰ˆç³»çµ±åˆå§‹åŒ–å¤±æ•—ï¼Œæ”¹ç”¨åŸå§‹æ–¹æ³•")
        from similarity_analysis import SimilarityAnalyzer
        analyzer = SimilarityAnalyzer(csv_path)
        use_enhanced = False
    else:
        analyzer = enhanced_analyzer
        use_enhanced = True
        print("âœ… å¢å¼·ç‰ˆç³»çµ±åˆå§‹åŒ–æˆåŠŸ")
    
    init_time = time.time() - start_time
    
    # ç¬¬ä¸€æ¬¡åˆ†é¡ï¼ˆæ©Ÿå™¨å­¸ç¿’æ–¹æ³•ï¼‰
    print("\nğŸ¤– ç¬¬ä¸€æ¬¡åˆ†é¡åŸ·è¡Œä¸­ (å¹³å‡æ©Ÿç‡æ³•)...")
    print("-" * 50)
    ml_start = time.time()
    result1 = classifier.classify_text(input_text, method='average')
    print_classification_result(result1)
    ml_time1 = time.time() - ml_start
    
    # ç¬¬äºŒæ¬¡åˆ†é¡ï¼ˆæ©Ÿå™¨å­¸ç¿’æ–¹æ³•ï¼‰
    print("\nğŸ¤– ç¬¬äºŒæ¬¡åˆ†é¡åŸ·è¡Œä¸­ (æŠ•ç¥¨æ³•)...")
    print("-" * 50)
    ml_start = time.time()
    result2 = classifier.classify_text(input_text, method='voting')
    print_classification_result(result2)
    ml_time2 = time.time() - ml_start
    
    # æ¯”è¼ƒå…©æ¬¡åˆ†é¡çµæœ
    print("\nğŸ“Š æ©Ÿå™¨å­¸ç¿’åˆ†é¡çµæœæ¯”è¼ƒ:")
    print("-" * 50)
    print(f"ç¬¬ä¸€æ¬¡åˆ†é¡çµæœ (å¹³å‡æ©Ÿç‡æ³•): {result1['best_prediction']}")
    print(f"ç¬¬äºŒæ¬¡åˆ†é¡çµæœ (æŠ•ç¥¨æ³•):     {result2['best_prediction']}")
    
    if result1['best_prediction'] == result2['best_prediction']:
        print("âœ… å…©æ¬¡åˆ†é¡çµæœä¸€è‡´")
        ml_prediction = result1['best_prediction']
        ml_confidence = result1['sorted_probabilities'][0][1]['avg_probability']
    else:
        print("âš ï¸  å…©æ¬¡åˆ†é¡çµæœä¸åŒ")
        # é¸æ“‡å¹³å‡æ©Ÿç‡è¼ƒé«˜çš„çµæœ
        avg_prob1 = result1['sorted_probabilities'][0][1]['avg_probability']
        avg_prob2 = result2['sorted_probabilities'][0][1]['avg_probability']
        if avg_prob1 >= avg_prob2:
            ml_prediction = result1['best_prediction']
            ml_confidence = avg_prob1
            print(f"æ¡ç”¨ç¬¬ä¸€æ¬¡çµæœ: {ml_prediction} (æ©Ÿç‡: {avg_prob1:.3f})")
        else:
            ml_prediction = result2['best_prediction']
            ml_confidence = avg_prob2
            print(f"æ¡ç”¨ç¬¬äºŒæ¬¡çµæœ: {ml_prediction} (æ©Ÿç‡: {avg_prob2:.3f})")
    
    # é€²è¡Œå¢å¼·ç‰ˆç›¸ä¼¼åº¦åˆ†æ
    print(f"\nğŸ” {'å¢å¼·ç‰ˆ' if use_enhanced else 'æ¨™æº–ç‰ˆ'}ç›¸ä¼¼åº¦åˆ†æ:")
    print("-" * 50)
    
    similarity_start = time.time()
    similarity_results, processed_test = analyzer.analyze_similarity(input_text)
    similarity_time = time.time() - similarity_start
    
    # åŸºæ–¼ç›¸ä¼¼åº¦é æ¸¬é¡åˆ¥
    if use_enhanced and similarity_results:
        # ä½¿ç”¨å¢å¼·ç‰ˆé æ¸¬æ–¹æ³•
        similarity_prediction = enhanced_analyzer.get_best_category_prediction(
            similarity_results, method='weighted_avg'
        )
        confidence_info = enhanced_analyzer.analyze_confidence(similarity_results)
        
        print(f"\nğŸ¯ å¢å¼·ç‰ˆç›¸ä¼¼åº¦é æ¸¬çµæœ:")
        print(f"é æ¸¬é¡åˆ¥: ã€{similarity_prediction}ã€‘")
        print(f"ä¿¡å¿ƒåº¦: {confidence_info['confidence_desc']} ({confidence_info['top_similarity']:.3f})")
        print(f"é¡åˆ¥å…±è­˜: {'âœ… æ˜¯' if confidence_info['consensus'] else 'âš ï¸ å¦'}")
        
        similarity_confidence = confidence_info['top_similarity']
        
    elif similarity_results:
        # ä½¿ç”¨æ¨™æº–æ–¹æ³•
        similarity_prediction = similarity_results[0]['category']
        similarity_confidence = similarity_results[0]['similarity']
        print(f"\nğŸ¯ åŸºæ–¼æœ€ç›¸ä¼¼é …ç›®çš„åˆ†é¡çµæœ: {similarity_prediction}")
        print(f"æœ€ç›¸ä¼¼é …ç›®: {similarity_results[0]['asset_name']} (ç›¸ä¼¼åº¦: {similarity_confidence:.4f})")
    else:
        similarity_prediction = None
        similarity_confidence = 0
        print("\nâš ï¸  ç„¡æ³•æ‰¾åˆ°ç›¸ä¼¼é …ç›®")
    
    # èåˆé æ¸¬çµæœ
    print(f"\nğŸ”€ é æ¸¬çµæœèåˆ:")
    print("-" * 50)
    print(f"æ©Ÿå™¨å­¸ç¿’é æ¸¬: ã€{ml_prediction}ã€‘(ä¿¡å¿ƒåº¦: {ml_confidence:.3f})")
    if similarity_prediction:
        print(f"ç›¸ä¼¼åº¦é æ¸¬:   ã€{similarity_prediction}ã€‘(ä¿¡å¿ƒåº¦: {similarity_confidence:.3f})")
        
        # æ±ºå®šæœ€çµ‚é æ¸¬
        if ml_prediction == similarity_prediction:
            final_prediction = ml_prediction
            fusion_method = "ä¸€è‡´é æ¸¬"
            final_confidence = max(ml_confidence, similarity_confidence)
            print(f"âœ… å…©ç¨®æ–¹æ³•é æ¸¬ä¸€è‡´: ã€{final_prediction}ã€‘")
        else:
            # åŸºæ–¼ä¿¡å¿ƒåº¦é¸æ“‡
            if similarity_confidence > ml_confidence:
                final_prediction = similarity_prediction
                fusion_method = "ç›¸ä¼¼åº¦å„ªå…ˆ"
                final_confidence = similarity_confidence
                print(f"ğŸ”„ æ¡ç”¨ç›¸ä¼¼åº¦é æ¸¬: ã€{final_prediction}ã€‘(ä¿¡å¿ƒåº¦æ›´é«˜)")
            else:
                final_prediction = ml_prediction
                fusion_method = "æ©Ÿå™¨å­¸ç¿’å„ªå…ˆ"
                final_confidence = ml_confidence
                print(f"ğŸ”„ æ¡ç”¨æ©Ÿå™¨å­¸ç¿’é æ¸¬: ã€{final_prediction}ã€‘(ä¿¡å¿ƒåº¦æ›´é«˜)")
    else:
        final_prediction = ml_prediction
        fusion_method = "åƒ…æ©Ÿå™¨å­¸ç¿’"
        final_confidence = ml_confidence
        print(f"âš ï¸  åƒ…ä½¿ç”¨æ©Ÿå™¨å­¸ç¿’é æ¸¬: ã€{final_prediction}ã€‘")
    
    # é¡¯ç¤ºç›¸ä¼¼é …ç›®
    if similarity_results:
        print(f"\nğŸ“‹ æœ€ç›¸ä¼¼çš„è³‡ç”¢åç¨± (å‰10é …):")
        for i, result in enumerate(similarity_results[:10], 1):
            indicator = "ğŸ¯" if result['category'] == final_prediction else "  "
            print(f"{indicator}{i:2d}. ã€{result['category']}ã€‘{result['asset_name']}")
            print(f"      ç›¸ä¼¼åº¦: {result['similarity']:.4f}")
            if i <= 3:  # åªå°å‰3é …é¡¯ç¤ºè©³ç´°è³‡è¨Š
                print(f"      è™•ç†å¾Œ: {result['processed_text']}")
            print()
        
        # æŒ‰é¡åˆ¥åˆ†æ
        if use_enhanced:
            print(f"\nğŸ“ˆ å¢å¼·ç‰ˆé¡åˆ¥åˆ†æ:")
            print("-" * 50)
            enhanced_analyzer.print_category_analysis(similarity_results)
        else:
            print(f"\nğŸ“ˆ æŒ‰è³‡ç”¢é¡åˆ¥çš„æ¯”å°åˆ†æ:")
            print("-" * 50)
            analyzer.print_category_analysis(similarity_results)
        
        # åŒé¡åˆ¥é …ç›®
        same_category_items = [item for item in similarity_results 
                              if item['category'] == final_prediction]
        
        if same_category_items:
            print(f"\nğŸ¯ åŒé¡åˆ¥ã€{final_prediction}ã€‘ä¸­æœ€ç›¸ä¼¼çš„é …ç›®:")
            print("-" * 30)
            for i, item in enumerate(same_category_items[:5], 1):
                print(f"{i}. {item['asset_name']} (ç›¸ä¼¼åº¦: {item['similarity']:.4f})")
    
    # è¨ˆç®—ç¸½è™•ç†æ™‚é–“
    total_time = time.time() - start_time
    
    # ç¸½çµå ±å‘Š
    print("\n" + "="*80)
    print("ğŸ“Š å¢å¼·ç‰ˆåˆ†æç¸½çµå ±å‘Š")
    print("="*80)
    print(f"è¼¸å…¥è³‡ç”¢åç¨±:     {input_text}")
    print(f"è™•ç†å¾Œæ–‡æœ¬:       {processed_test}")
    print(f"æ©Ÿå™¨å­¸ç¿’é æ¸¬:     {ml_prediction} (ä¿¡å¿ƒåº¦: {ml_confidence:.3f})")
    if similarity_prediction:
        print(f"ç›¸ä¼¼åº¦é æ¸¬:       {similarity_prediction} (ä¿¡å¿ƒåº¦: {similarity_confidence:.3f})")
    print(f"æœ€çµ‚é æ¸¬çµæœ:     ã€{final_prediction}ã€‘")
    print(f"èåˆæ–¹æ³•:         {fusion_method}")
    print(f"æœ€çµ‚ä¿¡å¿ƒåº¦:       {final_confidence:.3f}")
    print(f"ä½¿ç”¨ç³»çµ±:         {'å¢å¼·ç‰ˆ Embedding' if use_enhanced else 'æ¨™æº–ç‰ˆ TF-IDF'}")
    
    # æ•ˆèƒ½çµ±è¨ˆ
    print(f"\nâ±ï¸  æ•ˆèƒ½çµ±è¨ˆ:")
    print(f"ç³»çµ±åˆå§‹åŒ–æ™‚é–“:   {init_time:.3f} ç§’")
    print(f"æ©Ÿå™¨å­¸ç¿’æ™‚é–“:     {ml_time1 + ml_time2:.3f} ç§’")
    print(f"ç›¸ä¼¼åº¦åˆ†ææ™‚é–“:   {similarity_time:.3f} ç§’") 
    print(f"ç¸½è™•ç†æ™‚é–“:       {total_time:.3f} ç§’")
    
    if similarity_results:
        print(f"è³‡æ–™åº«æ¯”å°é …ç›®:   {len(similarity_results)} é …")
        
        # ç³»çµ±è³‡è¨Š
        if use_enhanced:
            system_info = enhanced_analyzer.get_system_info()
            print(f"Embedding æ–¹æ³•:   {system_info.get('embedding_method', 'Unknown')}")
            if system_info.get('embedding_dimension'):
                print(f"èªç¾©å‘é‡ç¶­åº¦:     {system_info.get('embedding_dimension')}")
    
    # çµ±è¨ˆå„é¡åˆ¥çš„è³‡ç”¢æ•¸é‡
    if similarity_results:
        category_count = {}
        for item in similarity_results:
            cat = item['category']
            category_count[cat] = category_count.get(cat, 0) + 1
        
        print("\nå„é¡åˆ¥è³‡ç”¢çµ±è¨ˆ:")
        for category, count in sorted(category_count.items()):
            indicator = "ğŸ‘‘" if category == final_prediction else "  "
            print(f"{indicator} {category}: {count} é …")
    
    return {
        'input_text': input_text,
        'processed_text': processed_test,
        'ml_prediction': ml_prediction,
        'ml_confidence': ml_confidence,
        'similarity_prediction': similarity_prediction,
        'similarity_confidence': similarity_confidence,
        'final_prediction': final_prediction,
        'final_confidence': final_confidence,
        'fusion_method': fusion_method,
        'use_enhanced': use_enhanced,
        'classification_results': [result1, result2],
        'similarity_results': similarity_results,
        'processing_time': {
            'init_time': init_time,
            'ml_time': ml_time1 + ml_time2,
            'similarity_time': similarity_time,
            'total_time': total_time
        }
    }

def interactive_enhanced_classification_v2():
    """äº’å‹•å¼å¢å¼·åˆ†é¡åŠŸèƒ½ v2.0"""
    print("="*80)
    print("ğŸš€ å¢å¼·ç‰ˆè³‡ç”¢åˆ†é¡ç³»çµ± v2.0")
    print("="*80)
    print("æ–°åŠŸèƒ½ç‰¹è‰²:")
    print("âœ¨ é å…ˆè¨ˆç®—çš„èªç¾©å‘é‡ (Sentence-BERT)")
    print("âœ¨ å¢å¼·ç‰ˆç›¸ä¼¼åº¦æ¯”å°ç®—æ³•")
    print("âœ¨ æ™ºèƒ½é æ¸¬çµæœèåˆ")
    print("âœ¨ è©³ç´°çš„ä¿¡å¿ƒåº¦åˆ†æ")
    print("âœ¨ æ•ˆèƒ½å„ªåŒ–å’Œçµ±è¨ˆ")
    print("\nç³»çµ±åŠŸèƒ½:")
    print("1. åŸ·è¡Œé›™é‡æ©Ÿå™¨å­¸ç¿’åˆ†é¡")
    print("2. ä½¿ç”¨é å…ˆè¨ˆç®—çš„ embeddings é€²è¡Œç›¸ä¼¼åº¦åˆ†æ")
    print("3. æ™ºèƒ½èåˆå¤šç¨®é æ¸¬çµæœ")
    print("4. æä¾›è©³ç´°çš„åˆ†æå ±å‘Šå’Œæ•ˆèƒ½çµ±è¨ˆ")
    print("\nè¼¸å…¥ 'quit' æˆ– 'q' çµæŸç¨‹å¼")
    print("="*80)
    
    while True:
        user_input = input("\nè«‹è¼¸å…¥è¦åˆ†æçš„è³‡ç”¢åç¨±: ").strip()
        
        if user_input.lower() in ['quit', 'exit', 'é€€å‡º', 'q']:
            print("æ„Ÿè¬ä½¿ç”¨å¢å¼·ç‰ˆè³‡ç”¢åˆ†é¡ç³»çµ± v2.0ï¼")
            break
            
        if not user_input:
            print("è«‹è¼¸å…¥æœ‰æ•ˆçš„è³‡ç”¢åç¨±")
            continue
            
        try:
            result = enhanced_classify_and_compare_v2(user_input)
            
            # ç°¡è¦ç¸½çµ
            print(f"\nğŸ¯ å¿«é€Ÿç¸½çµ:")
            print(f"æœ€çµ‚é æ¸¬: ã€{result['final_prediction']}ã€‘")
            print(f"ä¿¡å¿ƒåº¦: {result['final_confidence']:.3f}")
            print(f"æ–¹æ³•: {result['fusion_method']}")
            print(f"è™•ç†æ™‚é–“: {result['processing_time']['total_time']:.3f} ç§’")
            
            # è©¢å•æ˜¯å¦ç¹¼çºŒ
            continue_choice = input("\næ˜¯å¦ç¹¼çºŒåˆ†æå…¶ä»–è³‡ç”¢? (y/n): ").strip().lower()
            if continue_choice in ['n', 'no', 'å¦', 'q']:
                print("æ„Ÿè¬ä½¿ç”¨ï¼")
                break
                
        except Exception as e:
            print(f"åˆ†ææ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
            print("è«‹æª¢æŸ¥è³‡æ–™æª”æ¡ˆæ˜¯å¦å­˜åœ¨ä¸”æ ¼å¼æ­£ç¢º")
            import traceback
            traceback.print_exc()

def batch_test_examples_v2():
    """æ‰¹æ¬¡æ¸¬è©¦ç¯„ä¾‹ v2.0"""
    print("="*80)
    print("ğŸ§ª å¢å¼·ç‰ˆæ‰¹æ¬¡æ¸¬è©¦")
    print("="*80)
    
    test_cases = [
        "MySQL è³‡æ–™åº«ç®¡ç†ç³»çµ±",
        "å‚™ä»½æª”æ¡ˆå’Œæ—¥èªŒè¨˜éŒ„", 
        "ç¶²è·¯ä¼ºæœå™¨è¨­å‚™",
        "ç³»çµ±ç®¡ç†å“¡æ¬Šé™",
        "é›²ç«¯å„²å­˜æœå‹™",
        "Windows ä½œæ¥­ç³»çµ±",
        "é˜²ç«ç‰†è¨­å‚™",
        "ERPç³»çµ±",
        "Oracle è³‡æ–™åº«",
        "Apache ç¶²é ä¼ºæœå™¨"
    ]
    
    results = []
    total_start_time = time.time()
    
    for i, test_case in enumerate(test_cases, 1):
        print(f"\nğŸ”¬ æ¸¬è©¦æ¡ˆä¾‹ {i}/{len(test_cases)}: {test_case}")
        print("="*60)
        
        result = enhanced_classify_and_compare_v2(test_case)
        results.append(result)
        
        if i < len(test_cases):
            input("\næŒ‰ Enter ç¹¼çºŒä¸‹ä¸€å€‹æ¸¬è©¦æ¡ˆä¾‹...")
    
    total_time = time.time() - total_start_time
    
    # æ‰¹æ¬¡çµæœç¸½çµ
    print("\n" + "="*80)
    print("ğŸ“Š å¢å¼·ç‰ˆæ‰¹æ¬¡æ¸¬è©¦çµæœç¸½çµ")
    print("="*80)
    
    print(f"{'åºè™Ÿ':<4} {'è¼¸å…¥è³‡ç”¢åç¨±':<20} {'æœ€çµ‚é æ¸¬':<10} {'ä¿¡å¿ƒåº¦':<8} {'èåˆæ–¹æ³•':<12} {'è™•ç†æ™‚é–“':<8}")
    print("-" * 80)
    
    total_processing_time = 0
    accurate_predictions = 0
    high_confidence_count = 0
    
    for i, result in enumerate(results, 1):
        processing_time = result['processing_time']['total_time']
        total_processing_time += processing_time
        
        if result['final_confidence'] >= 0.7:
            high_confidence_count += 1
        
        print(f"{i:<4} {result['input_text'][:18]:<20} "
              f"ã€{result['final_prediction']}ã€‘{'':<2} "
              f"{result['final_confidence']:.3f}{'':<4} "
              f"{result['fusion_method']:<12} "
              f"{processing_time:.3f}s")
    
    print("-" * 80)
    print(f"ğŸ“ˆ çµ±è¨ˆæ‘˜è¦:")
    print(f"  æ¸¬è©¦æ¡ˆä¾‹ç¸½æ•¸:     {len(results)}")
    print(f"  é«˜ä¿¡å¿ƒåº¦é æ¸¬:     {high_confidence_count} ({high_confidence_count/len(results)*100:.1f}%)")
    print(f"  å¹³å‡è™•ç†æ™‚é–“:     {total_processing_time/len(results):.3f} ç§’")
    print(f"  ç¸½è™•ç†æ™‚é–“:       {total_time:.3f} ç§’")
    print(f"  ä½¿ç”¨å¢å¼·ç‰ˆç³»çµ±:   {sum(1 for r in results if r['use_enhanced'])} æ¡ˆä¾‹")
    
    # èåˆæ–¹æ³•çµ±è¨ˆ
    fusion_methods = {}
    for result in results:
        method = result['fusion_method']
        fusion_methods[method] = fusion_methods.get(method, 0) + 1
    
    print(f"\nèåˆæ–¹æ³•åˆ†å¸ƒ:")
    for method, count in fusion_methods.items():
        print(f"  {method}: {count} æ¡ˆä¾‹ ({count/len(results)*100:.1f}%)")
    
    return results

def main():
    """ä¸»ç¨‹å¼ v2.0"""
    print("="*80)
    print("ğŸ¯ å¢å¼·ç‰ˆè³‡ç”¢åˆ†é¡èˆ‡æ¯”å°ç³»çµ± v2.0")
    print("="*80)
    print("ğŸ†• æ–°ç‰ˆæœ¬ç‰¹è‰²:")
    print("  â€¢ é å…ˆè¨ˆç®—çš„èªç¾©å‘é‡ (Sentence-BERT + TF-IDF)")
    print("  â€¢ æ™ºèƒ½é æ¸¬çµæœèåˆ")
    print("  â€¢ å¢å¼·ç‰ˆä¿¡å¿ƒåº¦åˆ†æ")
    print("  â€¢ è©³ç´°æ•ˆèƒ½çµ±è¨ˆ")
    print("="*80)
    print("è«‹é¸æ“‡åŸ·è¡Œæ¨¡å¼:")
    print("1. äº’å‹•å¼åˆ†é¡ (é€ä¸€è¼¸å…¥è³‡ç”¢åç¨±)")
    print("2. æ‰¹æ¬¡æ¸¬è©¦ (ä½¿ç”¨é è¨­æ¸¬è©¦æ¡ˆä¾‹)")
    print("3. å–®æ¬¡æ¸¬è©¦ (æ¸¬è©¦å–®ä¸€è³‡ç”¢åç¨±)")
    print("4. é‡å»º Embeddings (å¼·åˆ¶é‡æ–°è¨ˆç®—å‘é‡)")
    print("="*80)
    
    while True:
        choice = input("è«‹é¸æ“‡æ¨¡å¼ (1/2/3/4) æˆ–è¼¸å…¥ 'q' é€€å‡º: ").strip()
        
        if choice == '1':
            interactive_enhanced_classification_v2()
            break
        elif choice == '2':
            batch_test_examples_v2()
            break
        elif choice == '3':
            test_text = input("è«‹è¼¸å…¥è¦æ¸¬è©¦çš„è³‡ç”¢åç¨±: ").strip()
            if test_text:
                result = enhanced_classify_and_compare_v2(test_text)
                print(f"\nğŸ¯ å¿«é€Ÿç¸½çµ:")
                print(f"æœ€çµ‚é æ¸¬: ã€{result['final_prediction']}ã€‘")
                print(f"ä¿¡å¿ƒåº¦: {result['final_confidence']:.3f}")
                print(f"æ–¹æ³•: {result['fusion_method']}")
            break
        elif choice == '4':
            print("ğŸ”„ æ­£åœ¨é‡å»º Embeddings...")
            analyzer = EnhancedSimilarityAnalyzer()
            if analyzer.initialize(force_rebuild=True):
                print("âœ… Embeddings é‡å»ºå®Œæˆï¼")
            else:
                print("âŒ Embeddings é‡å»ºå¤±æ•—")
            break
        elif choice.lower() in ['q', 'quit', 'é€€å‡º']:
            print("æ„Ÿè¬ä½¿ç”¨ï¼")
            break
        else:
            print("è«‹è¼¸å…¥æœ‰æ•ˆçš„é¸é … (1/2/3/4/q)")

if __name__ == "__main__":
    main()